I191227 02:40:19.513214 1 util/log/clog.go:1196  [config] file created at: 2019/12/27 02:40:19
I191227 02:40:19.513214 1 util/log/clog.go:1196  [config] running on machine: ubuntu
I191227 02:40:19.513214 1 util/log/clog.go:1196  [config] binary: CockroachDB CCL v19.2.2 (x86_64-linux-gnu, built 2019/12/27 02:35:26, go1.12.6)
I191227 02:40:19.513214 1 util/log/clog.go:1196  [config] arguments: [./cockroach start --insecure --listen-addr=192.168.80.129:26257 --http-addr=192.168.80.129:8080 --store=/data/node1 --external-io-dir=/home/lvhui/drdb/csv --cache=.20 --max-sql-memory=.20]
I191227 02:40:19.513214 1 util/log/clog.go:1196  line format: [IWEF]yymmdd hh:mm:ss.uuuuuu goid file:line msg utf8=✓
I191227 02:40:19.513212 1 cli/start.go:1144  logging to directory /data/node1/logs
W191227 02:40:19.514552 1 cli/start.go:1182  RUNNING IN INSECURE MODE!

- Your cluster is open for any client that can access 192.168.80.129.
- Any user, even root, can log in without providing a password.
- Any user, connecting as root, can read or write any data in your cluster.
- There is no network encryption nor authentication, and thus no confidentiality.

Check out how to secure your cluster: https://www.cockroachlabs.com/docs/v19.2/secure-a-cluster.html
I191227 02:40:19.515221 1 server/status/recorder.go:599  available memory from cgroups (8.0 EiB) exceeds system memory 9.7 GiB, using system memory
I191227 02:40:19.515238 1 cli/start.go:1196  CockroachDB CCL v19.2.2 (x86_64-linux-gnu, built 2019/12/27 02:35:26, go1.12.6)
W191227 02:40:19.615992 1 cli/start.go:511  running 'cockroach start' without --join is deprecated.
Consider using 'cockroach start-single-node' or 'cockroach init' instead.
I191227 02:40:19.616440 1 server/status/recorder.go:599  available memory from cgroups (8.0 EiB) exceeds system memory 9.7 GiB, using system memory
I191227 02:40:19.616451 1 server/config.go:394  system total memory: 9.7 GiB
I191227 02:40:19.616481 1 server/config.go:396  server configuration:
max offset             500000000
cache size             1.9 GiB
SQL memory pool size   1.9 GiB
scan interval          10m0s
scan min idle time     10ms
scan max idle time     1s
event log enabled      true
I191227 02:40:19.616492 1 cli/start.go:1030  using local environment variables: COCKROACH_BACKGROUND_RESTART=1
I191227 02:40:19.616500 1 cli/start.go:1037  process identity: uid 1000 euid 1000 gid 1000 egid 1000
I191227 02:40:19.616558 1 cli/start.go:644  starting cockroach node
I191227 02:40:19.617033 22 storage/engine/rocksdb.go:622  opening rocksdb instance at "/data/node1/cockroach-temp724025394"
I191227 02:40:19.750749 22 server/server.go:928  [n?] monitoring forward clock jumps based on server.clock.forward_jump_check_enabled
I191227 02:40:19.752891 22 storage/engine/rocksdb.go:622  opening rocksdb instance at "/data/node1"
I191227 02:40:19.764652 22 server/config.go:502  [n?] 1 storage engine initialized
I191227 02:40:19.764659 22 server/config.go:505  [n?] RocksDB cache size: 1.9 GiB
I191227 02:40:19.764664 22 server/config.go:505  [n?] store 0: RocksDB, max size 0 B, max open file limit 10000
I191227 02:40:19.764839 22 server/server.go:1386  [n?] no stores bootstrapped and --join flag specified, awaiting init command or join with an already initialized node.
I191227 02:40:19.764854 22 server/server.go:1396  [n?] **** add additional nodes by specifying --join=192.168.80.129:26257
I191227 02:40:19.780171 22 server/node.go:326  [n?] **** cluster 81650c8a-3243-4b47-92c1-d7bbdd60ace0 has been created
I191227 02:40:19.780378 22 gossip/gossip.go:394  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"192.168.80.129:26257" > attrs:<> locality:<> ServerVersion:<major_val:19 minor_val:2 patch:0 unstable:0 > build_tag:"v19.2.2" started_at:1577414419780284351 cluster_name:"" sql_address:<network_field:"tcp" address_field:"192.168.80.129:26257" > 
W191227 02:40:19.801965 169 storage/store.go:1530  [n1,s1,r6/1:/Table/{SystemCon…-11}] could not gossip system config: [NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown
I191227 02:40:19.802297 22 server/node.go:431  [n1] initialized store [n1,s1]: disk (capacity=216 GiB, available=179 GiB, used=71 KiB, logicalBytes=11 KiB), ranges=24, leases=0, queries=0.00, writes=0.00, bytesPerReplica={p10=0.00 p25=0.00 p50=0.00 p75=0.00 p90=166.00 pMax=9955.00}, writesPerReplica={p10=0.00 p25=0.00 p50=0.00 p75=0.00 p90=0.00 pMax=0.00}
I191227 02:40:19.802335 22 storage/stores.go:240  [n1] read 0 node addresses from persistent storage
I191227 02:40:19.802396 22 server/node.go:645  [n1] connecting to gossip network to verify cluster ID...
I191227 02:40:19.802409 22 server/node.go:665  [n1] node connected via gossip and verified as part of cluster "81650c8a-3243-4b47-92c1-d7bbdd60ace0"
I191227 02:40:19.802437 22 server/node.go:512  [n1] node=1: started with [<no-attributes>=/data/node1] engine(s) and attributes []
I191227 02:40:19.802595 22 server/server.go:1514  [n1] starting http server at 192.168.80.129:8080 (use: 192.168.80.129:8080)
I191227 02:40:19.802606 22 server/server.go:1521  [n1] starting grpc/postgres server at 192.168.80.129:26257
I191227 02:40:19.802616 22 server/server.go:1522  [n1] advertising CockroachDB node at 192.168.80.129:26257
W191227 02:40:19.857038 169 storage/store.go:1530  [n1,s1,r6/1:/Table/{SystemCon…-11}] could not gossip system config: [NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown
I191227 02:40:19.992523 295 sql/event_log.go:130  [n1,intExec=optInToDiagnosticsStatReporting] Event: "set_cluster_setting", target: 0, info: {SettingName:diagnostics.reporting.enabled Value:true User:root}
I191227 02:40:20.001907 311 sql/event_log.go:130  [n1,intExec=set-setting] Event: "set_cluster_setting", target: 0, info: {SettingName:version Value:19.2 User:root}
I191227 02:40:20.008992 400 sql/event_log.go:130  [n1,intExec=disableNetTrace] Event: "set_cluster_setting", target: 0, info: {SettingName:trace.debug.enable Value:false User:root}
I191227 02:40:20.025653 642 sql/event_log.go:130  [n1,intExec=initializeClusterSecret] Event: "set_cluster_setting", target: 0, info: {SettingName:cluster.secret Value:678fe4de-7080-40b8-9e2c-c026a4e3c8c3 User:root}
I191227 02:40:20.030923 619 sql/event_log.go:130  [n1,intExec=create-default-db] Event: "create_database", target: 50, info: {DatabaseName:defaultdb Statement:CREATE DATABASE IF NOT EXISTS defaultdb User:root}
I191227 02:40:20.034905 593 sql/event_log.go:130  [n1,intExec=create-default-db] Event: "create_database", target: 51, info: {DatabaseName:postgres Statement:CREATE DATABASE IF NOT EXISTS postgres User:root}
I191227 02:40:20.051996 22 server/server.go:1590  [n1] done ensuring all necessary migrations have run
I191227 02:40:20.052045 22 server/server.go:1841  [n1] serving sql connections
I191227 02:40:20.052117 22 cli/start.go:803  [config] clusterID: 81650c8a-3243-4b47-92c1-d7bbdd60ace0
I191227 02:40:20.052135 22 cli/start.go:812  node startup completed:
CockroachDB node starting at 2019-12-27 02:40:20.052074005 +0000 UTC (took 0.6s)
build:               CCL v19.2.2 @ 2019/12/27 02:35:26 (go1.12.6)
webui:               http://192.168.80.129:8080
sql:                 postgresql://root@192.168.80.129:26257?sslmode=disable
RPC client flags:    ./cockroach <client cmd> --host=192.168.80.129:26257 --insecure
logs:                /data/node1/logs
temp dir:            /data/node1/cockroach-temp724025394
external I/O path:   /home/lvhui/drdb/csv
store[0]:            path=/data/node1
status:              initialized new cluster
clusterID:           81650c8a-3243-4b47-92c1-d7bbdd60ace0
nodeID:              1
I191227 02:40:20.054391 857 server/server_update.go:53  [n1] no need to upgrade, cluster already at the newest version
I191227 02:40:20.054974 859 sql/event_log.go:130  [n1] Event: "node_join", target: 1, info: {Descriptor:{NodeID:1 Address:192.168.80.129:26257 Attrs: Locality: ServerVersion:19.2 BuildTag:v19.2.2 StartedAt:1577414419780284351 LocalityAddress:[] ClusterName: SQLAddress:192.168.80.129:26257} ClusterID:81650c8a-3243-4b47-92c1-d7bbdd60ace0 StartedAt:1577414419780284351 LastUp:1577414419780284351}
I191227 02:40:21.940617 108 gossip/gossip.go:1531  [n1] node has connected to cluster via gossip
I191227 02:40:21.940733 108 storage/stores.go:259  [n1] wrote 0 node addresses to persistent storage
I191227 02:40:29.809722 80 server/status/runtime.go:498  [n1] runtime stats: 146 MiB RSS, 157 goroutines, 94 MiB/28 MiB/136 MiB GO alloc/idle/total, 14 MiB/18 MiB CGO alloc/total, 0.0 CGO/sec, 0.0/0.0 %(u/s)time, 0.0 %gc (9x), 29 KiB/26 KiB (r/w)net
I191227 02:40:39.805135 75 storage/store.go:2364  [n1,s1] sstables (read amplification = 0):
I191227 02:40:39.805331 75 storage/store.go:2365  [n1,s1] 
** Compaction Stats [default] **
Level    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Sum      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0
 Int      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0

** Compaction Stats [default] **
Priority    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Uptime(secs): 20.0 total, 20.0 interval
Flush(GB): cumulative 0.000, interval 0.000
AddFile(GB): cumulative 0.000, interval 0.000
AddFile(Total Files): cumulative 0, interval 0
AddFile(L0 Files): cumulative 0, interval 0
AddFile(Keys): cumulative 0, interval 0
Cumulative compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Interval compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Stalls(count): 0 level0_slowdown, 0 level0_slowdown_with_compaction, 0 level0_numfiles, 0 level0_numfiles_with_compaction, 0 stop for pending_compaction_bytes, 0 slowdown for pending_compaction_bytes, 0 memtable_compaction, 0 memtable_slowdown, interval 0 total count
estimated_pending_compaction_bytes: 0 B
I191227 02:40:39.809939 80 server/status/runtime.go:498  [n1] runtime stats: 156 MiB RSS, 157 goroutines, 104 MiB/19 MiB/136 MiB GO alloc/idle/total, 14 MiB/19 MiB CGO alloc/total, 93.6 CGO/sec, 0.7/1.4 %(u/s)time, 0.0 %gc (0x), 9.7 KiB/8.9 KiB (r/w)net
I191227 02:40:40.844175 1363 storage/replica_consistency.go:229  [n1,consistencyChecker,s1,r4/1:/System{/tsd-tse}] triggering stats recomputation to resolve delta of {ContainsEstimates:true LastUpdateNanos:1577414439874236544 IntentAge:0 GCBytesAge:0 LiveBytes:18168 LiveCount:-664 KeyBytes:-32119 KeyCount:-664 ValBytes:50287 ValCount:-664 IntentBytes:0 IntentCount:0 SysBytes:0 SysCount:0}
I191227 02:40:48.826101 1448 gossip/server.go:227  [n1] received initial cluster-verification connection from 192.168.80.129:26258
I191227 02:40:48.826720 1448 gossip/server.go:227  [n1] received initial cluster-verification connection from 192.168.80.129:26258
I191227 02:40:48.862584 24 storage/stores.go:259  [n1] wrote 1 node addresses to persistent storage
I191227 02:40:49.808155 80 server/status/runtime.go:498  [n1] runtime stats: 174 MiB RSS, 183 goroutines, 79 MiB/37 MiB/136 MiB GO alloc/idle/total, 14 MiB/19 MiB CGO alloc/total, 311.2 CGO/sec, 1.4/2.4 %(u/s)time, 0.0 %gc (1x), 166 KiB/166 KiB (r/w)net
W191227 02:40:49.983599 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:1 Category:METRICS Description:ranges.underreplicated Value:24}]}
I191227 02:40:59.812107 80 server/status/runtime.go:498  [n1] runtime stats: 175 MiB RSS, 180 goroutines, 88 MiB/30 MiB/136 MiB GO alloc/idle/total, 14 MiB/20 MiB CGO alloc/total, 35.5 CGO/sec, 0.7/1.7 %(u/s)time, 0.0 %gc (0x), 65 KiB/60 KiB (r/w)net
W191227 02:40:59.993477 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:1 Category:METRICS Description:ranges.underreplicated Value:24}]}
I191227 02:41:04.272909 2073 gossip/server.go:227  [n1] received initial cluster-verification connection from 192.168.80.129:26259
I191227 02:41:04.273715 2073 gossip/server.go:227  [n1] received initial cluster-verification connection from 192.168.80.129:26259
I191227 02:41:04.279239 24 storage/stores.go:259  [n1] wrote 2 node addresses to persistent storage
I191227 02:41:04.304579 284 storage/replica_command.go:1586  [n1,replicate,s1,r15/1:/Table/{19-20}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r15:/Table/{19-20} [(n1,s1):1, next=2, gen=0]
I191227 02:41:04.310383 284 storage/replica_raft.go:291  [n1,s1,r15/1:/Table/{19-20}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:04.369341 284 storage/store_snapshot.go:978  [n1,replicate,s1,r15/1:/Table/{19-20}] sending LEARNER snapshot f7d05183 at applied index 18
I191227 02:41:04.369434 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r15/1:/Table/{19-20}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 7, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.369918 2167 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r15/1:/Table/{19-20}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:04.381344 284 storage/replica_command.go:1586  [n1,replicate,s1,r15/1:/Table/{19-20}] change replicas (add [(n3,s3):2] remove []): existing descriptor r15:/Table/{19-20} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:04.384698 284 storage/replica_raft.go:291  [n1,s1,r15/1:/Table/{19-20}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:04.385692 284 storage/replica_command.go:1586  [n1,replicate,s1,r15/1:/Table/{19-20}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r15:/Table/{19-20} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:04.395178 284 storage/replica_raft.go:291  [n1,s1,r15/1:/Table/{19-20}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:04.397707 284 storage/store_snapshot.go:978  [n1,replicate,s1,r15/1:/Table/{19-20}] sending LEARNER snapshot 647a0b1a at applied index 22
I191227 02:41:04.397794 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r15/1:/Table/{19-20}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 11, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.398938 2197 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r15/1:/Table/{19-20}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:04.407410 284 storage/replica_command.go:1586  [n1,replicate,s1,r15/1:/Table/{19-20}] change replicas (add [(n2,s2):3] remove []): existing descriptor r15:/Table/{19-20} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:04.410027 284 storage/replica_raft.go:291  [n1,s1,r15/1:/Table/{19-20}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:04.413512 284 storage/replica_command.go:1586  [n1,replicate,s1,r20/1:/Table/2{4-5}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r20:/Table/2{4-5} [(n1,s1):1, next=2, gen=0]
I191227 02:41:04.416302 284 storage/replica_raft.go:291  [n1,s1,r20/1:/Table/2{4-5}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:04.418385 284 storage/store_snapshot.go:978  [n1,replicate,s1,r20/1:/Table/2{4-5}] sending LEARNER snapshot 0de006fa at applied index 18
I191227 02:41:04.418452 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r20/1:/Table/2{4-5}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 7, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.418970 2205 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r20/1:/Table/2{4-5}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:04.427244 284 storage/replica_command.go:1586  [n1,replicate,s1,r20/1:/Table/2{4-5}] change replicas (add [(n3,s3):2] remove []): existing descriptor r20:/Table/2{4-5} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:04.430062 284 storage/replica_raft.go:291  [n1,s1,r20/1:/Table/2{4-5}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:04.430944 284 storage/replica_command.go:1586  [n1,replicate,s1,r20/1:/Table/2{4-5}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r20:/Table/2{4-5} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:04.440386 284 storage/replica_raft.go:291  [n1,s1,r20/1:/Table/2{4-5}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:04.443793 284 storage/store_snapshot.go:978  [n1,replicate,s1,r20/1:/Table/2{4-5}] sending LEARNER snapshot ab66ce0a at applied index 22
I191227 02:41:04.443864 2244 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r20/1:/Table/2{4-5}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:04.443915 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r20/1:/Table/2{4-5}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 11, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.459637 284 storage/replica_command.go:1586  [n1,replicate,s1,r20/1:/Table/2{4-5}] change replicas (add [(n2,s2):3] remove []): existing descriptor r20:/Table/2{4-5} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:04.462707 284 storage/replica_raft.go:291  [n1,s1,r20/1:/Table/2{4-5}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:04.466163 284 storage/replica_command.go:1586  [n1,replicate,s1,r24/1:/{Table/28-Max}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r24:/{Table/28-Max} [(n1,s1):1, next=2, gen=0]
I191227 02:41:04.467893 284 storage/replica_raft.go:291  [n1,s1,r24/1:/{Table/28-Max}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:04.469656 284 storage/store_snapshot.go:978  [n1,replicate,s1,r24/1:/{Table/28-Max}] sending LEARNER snapshot b30b1129 at applied index 18
I191227 02:41:04.469730 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r24/1:/{Table/28-Max}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 7, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.469990 2247 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r24/1:/{Table/28-Max}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:04.477178 284 storage/replica_command.go:1586  [n1,replicate,s1,r24/1:/{Table/28-Max}] change replicas (add [(n3,s3):2] remove []): existing descriptor r24:/{Table/28-Max} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:04.480324 284 storage/replica_raft.go:291  [n1,s1,r24/1:/{Table/28-Max}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:04.481108 284 storage/replica_command.go:1586  [n1,replicate,s1,r24/1:/{Table/28-Max}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r24:/{Table/28-Max} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:04.488804 284 storage/replica_raft.go:291  [n1,s1,r24/1:/{Table/28-Max}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:04.490535 284 storage/store_snapshot.go:978  [n1,replicate,s1,r24/1:/{Table/28-Max}] sending LEARNER snapshot a8640570 at applied index 22
I191227 02:41:04.490611 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r24/1:/{Table/28-Max}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 11, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.491423 2231 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r24/1:/{Table/28-Max}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:04.499005 284 storage/replica_command.go:1586  [n1,replicate,s1,r24/1:/{Table/28-Max}] change replicas (add [(n2,s2):3] remove []): existing descriptor r24:/{Table/28-Max} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:04.502718 284 storage/replica_raft.go:291  [n1,s1,r24/1:/{Table/28-Max}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:04.503702 284 storage/replica_command.go:1586  [n1,replicate,s1,r4/1:/System{/tsd-tse}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r4:/System{/tsd-tse} [(n1,s1):1, next=2, gen=0]
I191227 02:41:04.505687 284 storage/replica_raft.go:291  [n1,s1,r4/1:/System{/tsd-tse}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:04.507145 284 storage/store_snapshot.go:978  [n1,replicate,s1,r4/1:/System{/tsd-tse}] sending LEARNER snapshot e0f7067d at applied index 47
I191227 02:41:04.507228 2307 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r4/1:/System{/tsd-tse}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:04.512614 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r4/1:/System{/tsd-tse}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 2000, log entries: 0, rate-limit: 8.0 MiB/sec, 0.01s
I191227 02:41:04.522917 284 storage/replica_command.go:1586  [n1,replicate,s1,r4/1:/System{/tsd-tse}] change replicas (add [(n3,s3):2] remove []): existing descriptor r4:/System{/tsd-tse} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:04.525538 284 storage/replica_raft.go:291  [n1,s1,r4/1:/System{/tsd-tse}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:04.526599 284 storage/replica_command.go:1586  [n1,replicate,s1,r4/1:/System{/tsd-tse}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r4:/System{/tsd-tse} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:04.535287 284 storage/replica_raft.go:291  [n1,s1,r4/1:/System{/tsd-tse}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:04.537198 284 storage/store_snapshot.go:978  [n1,replicate,s1,r4/1:/System{/tsd-tse}] sending LEARNER snapshot a11aba38 at applied index 51
I191227 02:41:04.537218 2324 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r4/1:/System{/tsd-tse}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:04.542974 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r4/1:/System{/tsd-tse}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 2004, log entries: 0, rate-limit: 8.0 MiB/sec, 0.01s
I191227 02:41:04.554006 284 storage/replica_command.go:1586  [n1,replicate,s1,r4/1:/System{/tsd-tse}] change replicas (add [(n2,s2):3] remove []): existing descriptor r4:/System{/tsd-tse} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:04.556442 284 storage/replica_raft.go:291  [n1,s1,r4/1:/System{/tsd-tse}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:04.557612 284 storage/replica_command.go:1586  [n1,replicate,s1,r17/1:/Table/2{1-2}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r17:/Table/2{1-2} [(n1,s1):1, next=2, gen=0]
I191227 02:41:04.559995 284 storage/replica_raft.go:291  [n1,s1,r17/1:/Table/2{1-2}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:04.561706 284 storage/store_snapshot.go:978  [n1,replicate,s1,r17/1:/Table/2{1-2}] sending LEARNER snapshot b5eb8534 at applied index 24
I191227 02:41:04.561783 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r17/1:/Table/2{1-2}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 12, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.562497 2331 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r17/1:/Table/2{1-2}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:04.569864 284 storage/replica_command.go:1586  [n1,replicate,s1,r17/1:/Table/2{1-2}] change replicas (add [(n3,s3):2] remove []): existing descriptor r17:/Table/2{1-2} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:04.572796 284 storage/replica_raft.go:291  [n1,s1,r17/1:/Table/2{1-2}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:04.573644 284 storage/replica_command.go:1586  [n1,replicate,s1,r17/1:/Table/2{1-2}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r17:/Table/2{1-2} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:04.582547 284 storage/replica_raft.go:291  [n1,s1,r17/1:/Table/2{1-2}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:04.584767 284 storage/store_snapshot.go:978  [n1,replicate,s1,r17/1:/Table/2{1-2}] sending LEARNER snapshot b67cad3f at applied index 28
I191227 02:41:04.584844 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r17/1:/Table/2{1-2}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 16, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.584876 2354 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r17/1:/Table/2{1-2}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:04.592601 284 storage/replica_command.go:1586  [n1,replicate,s1,r17/1:/Table/2{1-2}] change replicas (add [(n2,s2):3] remove []): existing descriptor r17:/Table/2{1-2} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:04.595849 284 storage/replica_raft.go:291  [n1,s1,r17/1:/Table/2{1-2}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:04.597085 284 storage/replica_command.go:1586  [n1,replicate,s1,r13/1:/Table/1{7-8}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r13:/Table/1{7-8} [(n1,s1):1, next=2, gen=0]
I191227 02:41:04.599531 284 storage/replica_raft.go:291  [n1,s1,r13/1:/Table/1{7-8}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:04.601325 284 storage/store_snapshot.go:978  [n1,replicate,s1,r13/1:/Table/1{7-8}] sending LEARNER snapshot 30dad49c at applied index 18
I191227 02:41:04.601376 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r13/1:/Table/1{7-8}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 7, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.601388 2349 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r13/1:/Table/1{7-8}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:04.626713 284 storage/replica_command.go:1586  [n1,replicate,s1,r13/1:/Table/1{7-8}] change replicas (add [(n3,s3):2] remove []): existing descriptor r13:/Table/1{7-8} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:04.633934 284 storage/replica_raft.go:291  [n1,s1,r13/1:/Table/1{7-8}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:04.635754 284 storage/replica_command.go:1586  [n1,replicate,s1,r13/1:/Table/1{7-8}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r13:/Table/1{7-8} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:04.644113 284 storage/replica_raft.go:291  [n1,s1,r13/1:/Table/1{7-8}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:04.646565 284 storage/store_snapshot.go:978  [n1,replicate,s1,r13/1:/Table/1{7-8}] sending LEARNER snapshot aac6bca5 at applied index 22
I191227 02:41:04.646625 2289 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r13/1:/Table/1{7-8}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:04.646636 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r13/1:/Table/1{7-8}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 11, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.654754 284 storage/replica_command.go:1586  [n1,replicate,s1,r13/1:/Table/1{7-8}] change replicas (add [(n2,s2):3] remove []): existing descriptor r13:/Table/1{7-8} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:04.657929 284 storage/replica_raft.go:291  [n1,s1,r13/1:/Table/1{7-8}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:04.659286 284 storage/replica_command.go:1586  [n1,replicate,s1,r14/1:/Table/1{8-9}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r14:/Table/1{8-9} [(n1,s1):1, next=2, gen=0]
I191227 02:41:04.661524 284 storage/replica_raft.go:291  [n1,s1,r14/1:/Table/1{8-9}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:04.662807 284 storage/store_snapshot.go:978  [n1,replicate,s1,r14/1:/Table/1{8-9}] sending LEARNER snapshot 31f86e89 at applied index 18
I191227 02:41:04.662859 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r14/1:/Table/1{8-9}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 7, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.662876 2317 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r14/1:/Table/1{8-9}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:04.669764 284 storage/replica_command.go:1586  [n1,replicate,s1,r14/1:/Table/1{8-9}] change replicas (add [(n3,s3):2] remove []): existing descriptor r14:/Table/1{8-9} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:04.672354 284 storage/replica_raft.go:291  [n1,s1,r14/1:/Table/1{8-9}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:04.672980 284 storage/replica_command.go:1586  [n1,replicate,s1,r14/1:/Table/1{8-9}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r14:/Table/1{8-9} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:04.683228 284 storage/replica_raft.go:291  [n1,s1,r14/1:/Table/1{8-9}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:04.685874 284 storage/store_snapshot.go:978  [n1,replicate,s1,r14/1:/Table/1{8-9}] sending LEARNER snapshot 7a06fb94 at applied index 22
I191227 02:41:04.685933 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r14/1:/Table/1{8-9}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 11, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.686060 2319 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r14/1:/Table/1{8-9}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:04.696607 284 storage/replica_command.go:1586  [n1,replicate,s1,r14/1:/Table/1{8-9}] change replicas (add [(n2,s2):3] remove []): existing descriptor r14:/Table/1{8-9} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:04.699291 284 storage/replica_raft.go:291  [n1,s1,r14/1:/Table/1{8-9}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:04.700398 284 storage/replica_command.go:1586  [n1,replicate,s1,r16/1:/Table/2{0-1}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r16:/Table/2{0-1} [(n1,s1):1, next=2, gen=0]
I191227 02:41:04.702620 284 storage/replica_raft.go:291  [n1,s1,r16/1:/Table/2{0-1}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:04.704752 2411 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r16/1:/Table/2{0-1}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:04.704803 284 storage/store_snapshot.go:978  [n1,replicate,s1,r16/1:/Table/2{0-1}] sending LEARNER snapshot a5dae47c at applied index 18
I191227 02:41:04.704872 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r16/1:/Table/2{0-1}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 7, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.713127 284 storage/replica_command.go:1586  [n1,replicate,s1,r16/1:/Table/2{0-1}] change replicas (add [(n3,s3):2] remove []): existing descriptor r16:/Table/2{0-1} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:04.715341 284 storage/replica_raft.go:291  [n1,s1,r16/1:/Table/2{0-1}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:04.716135 284 storage/replica_command.go:1586  [n1,replicate,s1,r16/1:/Table/2{0-1}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r16:/Table/2{0-1} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:04.725479 284 storage/replica_raft.go:291  [n1,s1,r16/1:/Table/2{0-1}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:04.727823 284 storage/store_snapshot.go:978  [n1,replicate,s1,r16/1:/Table/2{0-1}] sending LEARNER snapshot a6f6bc67 at applied index 22
I191227 02:41:04.727902 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r16/1:/Table/2{0-1}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 11, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.727918 2414 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r16/1:/Table/2{0-1}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:04.737019 284 storage/replica_command.go:1586  [n1,replicate,s1,r16/1:/Table/2{0-1}] change replicas (add [(n2,s2):3] remove []): existing descriptor r16:/Table/2{0-1} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:04.739814 284 storage/replica_raft.go:291  [n1,s1,r16/1:/Table/2{0-1}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:04.740889 284 storage/replica_command.go:1586  [n1,replicate,s1,r19/1:/Table/2{3-4}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r19:/Table/2{3-4} [(n1,s1):1, next=2, gen=0]
I191227 02:41:04.742919 284 storage/replica_raft.go:291  [n1,s1,r19/1:/Table/2{3-4}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:04.744611 284 storage/store_snapshot.go:978  [n1,replicate,s1,r19/1:/Table/2{3-4}] sending LEARNER snapshot ccc8a4c3 at applied index 20
I191227 02:41:04.744672 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r19/1:/Table/2{3-4}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 11, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.744689 2456 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r19/1:/Table/2{3-4}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:04.752325 284 storage/replica_command.go:1586  [n1,replicate,s1,r19/1:/Table/2{3-4}] change replicas (add [(n3,s3):2] remove []): existing descriptor r19:/Table/2{3-4} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:04.755015 284 storage/replica_raft.go:291  [n1,s1,r19/1:/Table/2{3-4}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:04.755838 284 storage/replica_command.go:1586  [n1,replicate,s1,r19/1:/Table/2{3-4}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r19:/Table/2{3-4} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:04.765308 284 storage/replica_raft.go:291  [n1,s1,r19/1:/Table/2{3-4}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:04.767310 284 storage/store_snapshot.go:978  [n1,replicate,s1,r19/1:/Table/2{3-4}] sending LEARNER snapshot 7e24917e at applied index 24
I191227 02:41:04.767389 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r19/1:/Table/2{3-4}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 15, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.767422 2519 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r19/1:/Table/2{3-4}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:04.775324 284 storage/replica_command.go:1586  [n1,replicate,s1,r19/1:/Table/2{3-4}] change replicas (add [(n2,s2):3] remove []): existing descriptor r19:/Table/2{3-4} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:04.778166 284 storage/replica_raft.go:291  [n1,s1,r19/1:/Table/2{3-4}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:04.779405 284 storage/replica_command.go:1586  [n1,replicate,s1,r23/1:/Table/2{7-8}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r23:/Table/2{7-8} [(n1,s1):1, next=2, gen=0]
I191227 02:41:04.781472 284 storage/replica_raft.go:291  [n1,s1,r23/1:/Table/2{7-8}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:04.783588 284 storage/store_snapshot.go:978  [n1,replicate,s1,r23/1:/Table/2{7-8}] sending LEARNER snapshot ed43741d at applied index 18
I191227 02:41:04.783645 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r23/1:/Table/2{7-8}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 7, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.783671 2532 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r23/1:/Table/2{7-8}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:04.792371 284 storage/replica_command.go:1586  [n1,replicate,s1,r23/1:/Table/2{7-8}] change replicas (add [(n3,s3):2] remove []): existing descriptor r23:/Table/2{7-8} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:04.795025 284 storage/replica_raft.go:291  [n1,s1,r23/1:/Table/2{7-8}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:04.795799 284 storage/replica_command.go:1586  [n1,replicate,s1,r23/1:/Table/2{7-8}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r23:/Table/2{7-8} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:04.807385 284 storage/replica_raft.go:291  [n1,s1,r23/1:/Table/2{7-8}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:04.809861 284 storage/store_snapshot.go:978  [n1,replicate,s1,r23/1:/Table/2{7-8}] sending LEARNER snapshot 6ca219cc at applied index 23
I191227 02:41:04.809936 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r23/1:/Table/2{7-8}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 11, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.810400 2568 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r23/1:/Table/2{7-8}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:04.817592 284 storage/replica_command.go:1586  [n1,replicate,s1,r23/1:/Table/2{7-8}] change replicas (add [(n2,s2):3] remove []): existing descriptor r23:/Table/2{7-8} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:04.821083 284 storage/replica_raft.go:291  [n1,s1,r23/1:/Table/2{7-8}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:04.822516 284 storage/replica_command.go:1586  [n1,replicate,s1,r11/1:/Table/1{5-6}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r11:/Table/1{5-6} [(n1,s1):1, next=2, gen=0]
I191227 02:41:04.825697 284 storage/replica_raft.go:291  [n1,s1,r11/1:/Table/1{5-6}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:04.828322 284 storage/store_snapshot.go:978  [n1,replicate,s1,r11/1:/Table/1{5-6}] sending LEARNER snapshot 3a0c1feb at applied index 18
I191227 02:41:04.828414 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r11/1:/Table/1{5-6}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 7, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.828525 2529 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r11/1:/Table/1{5-6}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:04.837687 284 storage/replica_command.go:1586  [n1,replicate,s1,r11/1:/Table/1{5-6}] change replicas (add [(n3,s3):2] remove []): existing descriptor r11:/Table/1{5-6} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:04.840878 284 storage/replica_raft.go:291  [n1,s1,r11/1:/Table/1{5-6}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:04.841713 284 storage/replica_command.go:1586  [n1,replicate,s1,r11/1:/Table/1{5-6}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r11:/Table/1{5-6} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:04.851870 284 storage/replica_raft.go:291  [n1,s1,r11/1:/Table/1{5-6}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:04.854211 284 storage/store_snapshot.go:978  [n1,replicate,s1,r11/1:/Table/1{5-6}] sending LEARNER snapshot 72d85654 at applied index 22
I191227 02:41:04.854232 2583 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r11/1:/Table/1{5-6}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:04.854310 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r11/1:/Table/1{5-6}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 11, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.862919 284 storage/replica_command.go:1586  [n1,replicate,s1,r11/1:/Table/1{5-6}] change replicas (add [(n2,s2):3] remove []): existing descriptor r11:/Table/1{5-6} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:04.866978 284 storage/replica_raft.go:291  [n1,s1,r11/1:/Table/1{5-6}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:04.868417 284 storage/replica_command.go:1586  [n1,replicate,s1,r8/1:/Table/1{2-3}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r8:/Table/1{2-3} [(n1,s1):1, next=2, gen=0]
I191227 02:41:04.870392 284 storage/replica_raft.go:291  [n1,s1,r8/1:/Table/1{2-3}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:04.871825 284 storage/store_snapshot.go:978  [n1,replicate,s1,r8/1:/Table/1{2-3}] sending LEARNER snapshot 117e62a7 at applied index 50
I191227 02:41:04.871952 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r8/1:/Table/1{2-3}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 72, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.872195 2589 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r8/1:/Table/1{2-3}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:04.880260 284 storage/replica_command.go:1586  [n1,replicate,s1,r8/1:/Table/1{2-3}] change replicas (add [(n3,s3):2] remove []): existing descriptor r8:/Table/1{2-3} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:04.882939 284 storage/replica_raft.go:291  [n1,s1,r8/1:/Table/1{2-3}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:04.883803 284 storage/replica_command.go:1586  [n1,replicate,s1,r8/1:/Table/1{2-3}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r8:/Table/1{2-3} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:04.892436 284 storage/replica_raft.go:291  [n1,s1,r8/1:/Table/1{2-3}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:04.894523 284 storage/store_snapshot.go:978  [n1,replicate,s1,r8/1:/Table/1{2-3}] sending LEARNER snapshot eda9becc at applied index 54
I191227 02:41:04.894595 2495 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r8/1:/Table/1{2-3}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:04.894651 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r8/1:/Table/1{2-3}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 76, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.903311 284 storage/replica_command.go:1586  [n1,replicate,s1,r8/1:/Table/1{2-3}] change replicas (add [(n2,s2):3] remove []): existing descriptor r8:/Table/1{2-3} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:04.906030 284 storage/replica_raft.go:291  [n1,s1,r8/1:/Table/1{2-3}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:04.907112 284 storage/replica_command.go:1586  [n1,replicate,s1,r5/1:/{Systemtse-Table/System…}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r5:/{Systemtse-Table/SystemConfigSpan/Start} [(n1,s1):1, next=2, gen=0]
I191227 02:41:04.909258 284 storage/replica_raft.go:291  [n1,s1,r5/1:/{Systemtse-Table/System…}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:04.910684 284 storage/store_snapshot.go:978  [n1,replicate,s1,r5/1:/{Systemtse-Table/System…}] sending LEARNER snapshot 4bbfea1c at applied index 19
I191227 02:41:04.910764 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r5/1:/{Systemtse-Table/System…}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 8, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.910768 2631 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r5/1:/{Systemtse-Table/System…}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:04.920505 284 storage/replica_command.go:1586  [n1,replicate,s1,r5/1:/{Systemtse-Table/System…}] change replicas (add [(n3,s3):2] remove []): existing descriptor r5:/{Systemtse-Table/SystemConfigSpan/Start} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:04.924279 284 storage/replica_raft.go:291  [n1,s1,r5/1:/{Systemtse-Table/System…}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:04.925282 284 storage/replica_command.go:1586  [n1,replicate,s1,r5/1:/{Systemtse-Table/System…}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r5:/{Systemtse-Table/SystemConfigSpan/Start} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:04.933876 284 storage/replica_raft.go:291  [n1,s1,r5/1:/{Systemtse-Table/System…}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:04.935677 284 storage/store_snapshot.go:978  [n1,replicate,s1,r5/1:/{Systemtse-Table/System…}] sending LEARNER snapshot fecea5b5 at applied index 23
I191227 02:41:04.935778 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r5/1:/{Systemtse-Table/System…}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 12, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.936474 2636 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r5/1:/{Systemtse-Table/System…}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:04.944726 284 storage/replica_command.go:1586  [n1,replicate,s1,r5/1:/{Systemtse-Table/System…}] change replicas (add [(n2,s2):3] remove []): existing descriptor r5:/{Systemtse-Table/SystemConfigSpan/Start} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:04.947950 284 storage/replica_raft.go:291  [n1,s1,r5/1:/{Systemtse-Table/System…}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:04.948949 284 storage/replica_command.go:1586  [n1,replicate,s1,r2/1:/System/NodeLiveness{-Max}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r2:/System/NodeLiveness{-Max} [(n1,s1):1, next=2, gen=0]
I191227 02:41:04.950956 284 storage/replica_raft.go:291  [n1,s1,r2/1:/System/NodeLiveness{-Max}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:04.952751 284 storage/store_snapshot.go:978  [n1,replicate,s1,r2/1:/System/NodeLiveness{-Max}] sending LEARNER snapshot 717a84ed at applied index 57
I191227 02:41:04.952822 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r2/1:/System/NodeLiveness{-Max}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 23, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.952859 2702 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r2/1:/System/NodeLiveness{-Max}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:04.977615 284 storage/replica_command.go:1586  [n1,replicate,s1,r2/1:/System/NodeLiveness{-Max}] change replicas (add [(n3,s3):2] remove []): existing descriptor r2:/System/NodeLiveness{-Max} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:04.980999 284 storage/replica_raft.go:291  [n1,s1,r2/1:/System/NodeLiveness{-Max}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:04.982281 284 storage/replica_command.go:1586  [n1,replicate,s1,r2/1:/System/NodeLiveness{-Max}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r2:/System/NodeLiveness{-Max} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:04.990432 284 storage/replica_raft.go:291  [n1,s1,r2/1:/System/NodeLiveness{-Max}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:04.992967 284 storage/store_snapshot.go:978  [n1,replicate,s1,r2/1:/System/NodeLiveness{-Max}] sending LEARNER snapshot 64dee2be at applied index 61
I191227 02:41:04.993094 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r2/1:/System/NodeLiveness{-Max}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 27, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:04.993127 2716 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r2/1:/System/NodeLiveness{-Max}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:05.002725 284 storage/replica_command.go:1586  [n1,replicate,s1,r2/1:/System/NodeLiveness{-Max}] change replicas (add [(n2,s2):3] remove []): existing descriptor r2:/System/NodeLiveness{-Max} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:05.006520 284 storage/replica_raft.go:291  [n1,s1,r2/1:/System/NodeLiveness{-Max}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:05.008266 284 storage/replica_command.go:1586  [n1,replicate,s1,r22/1:/Table/2{6-7}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r22:/Table/2{6-7} [(n1,s1):1, next=2, gen=0]
I191227 02:41:05.010806 284 storage/replica_raft.go:291  [n1,s1,r22/1:/Table/2{6-7}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:05.012573 284 storage/store_snapshot.go:978  [n1,replicate,s1,r22/1:/Table/2{6-7}] sending LEARNER snapshot 3e4b0702 at applied index 18
I191227 02:41:05.012668 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r22/1:/Table/2{6-7}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 7, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:05.013387 2744 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r22/1:/Table/2{6-7}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:05.021486 284 storage/replica_command.go:1586  [n1,replicate,s1,r22/1:/Table/2{6-7}] change replicas (add [(n3,s3):2] remove []): existing descriptor r22:/Table/2{6-7} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:05.023872 284 storage/replica_raft.go:291  [n1,s1,r22/1:/Table/2{6-7}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:05.024961 284 storage/replica_command.go:1586  [n1,replicate,s1,r22/1:/Table/2{6-7}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r22:/Table/2{6-7} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:05.034912 284 storage/replica_raft.go:291  [n1,s1,r22/1:/Table/2{6-7}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:05.037822 284 storage/store_snapshot.go:978  [n1,replicate,s1,r22/1:/Table/2{6-7}] sending LEARNER snapshot a4f9ab11 at applied index 22
I191227 02:41:05.037885 2734 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r22/1:/Table/2{6-7}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:05.037929 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r22/1:/Table/2{6-7}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 11, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:05.047979 284 storage/replica_command.go:1586  [n1,replicate,s1,r22/1:/Table/2{6-7}] change replicas (add [(n2,s2):3] remove []): existing descriptor r22:/Table/2{6-7} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:05.051069 284 storage/replica_raft.go:291  [n1,s1,r22/1:/Table/2{6-7}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:05.052126 284 storage/replica_command.go:1586  [n1,replicate,s1,r21/1:/Table/2{5-6}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r21:/Table/2{5-6} [(n1,s1):1, next=2, gen=0]
I191227 02:41:05.054077 284 storage/replica_raft.go:291  [n1,s1,r21/1:/Table/2{5-6}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:05.055408 284 storage/store_snapshot.go:978  [n1,replicate,s1,r21/1:/Table/2{5-6}] sending LEARNER snapshot 83aa01f3 at applied index 18
I191227 02:41:05.055462 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r21/1:/Table/2{5-6}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 7, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:05.055464 2753 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r21/1:/Table/2{5-6}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:05.063020 284 storage/replica_command.go:1586  [n1,replicate,s1,r21/1:/Table/2{5-6}] change replicas (add [(n3,s3):2] remove []): existing descriptor r21:/Table/2{5-6} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:05.065676 284 storage/replica_raft.go:291  [n1,s1,r21/1:/Table/2{5-6}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:05.066761 284 storage/replica_command.go:1586  [n1,replicate,s1,r21/1:/Table/2{5-6}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r21:/Table/2{5-6} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:05.075766 284 storage/replica_raft.go:291  [n1,s1,r21/1:/Table/2{5-6}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:05.077618 284 storage/store_snapshot.go:978  [n1,replicate,s1,r21/1:/Table/2{5-6}] sending LEARNER snapshot 83f71744 at applied index 22
I191227 02:41:05.077730 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r21/1:/Table/2{5-6}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 11, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:05.078003 2789 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r21/1:/Table/2{5-6}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:05.086302 284 storage/replica_command.go:1586  [n1,replicate,s1,r21/1:/Table/2{5-6}] change replicas (add [(n2,s2):3] remove []): existing descriptor r21:/Table/2{5-6} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:05.089093 284 storage/replica_raft.go:291  [n1,s1,r21/1:/Table/2{5-6}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:05.090355 284 storage/replica_command.go:1586  [n1,replicate,s1,r12/1:/Table/1{6-7}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r12:/Table/1{6-7} [(n1,s1):1, next=2, gen=0]
I191227 02:41:05.092362 284 storage/replica_raft.go:291  [n1,s1,r12/1:/Table/1{6-7}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:05.094115 284 storage/store_snapshot.go:978  [n1,replicate,s1,r12/1:/Table/1{6-7}] sending LEARNER snapshot 100ca277 at applied index 18
I191227 02:41:05.094168 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r12/1:/Table/1{6-7}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 7, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:05.094201 2607 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r12/1:/Table/1{6-7}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:05.101236 284 storage/replica_command.go:1586  [n1,replicate,s1,r12/1:/Table/1{6-7}] change replicas (add [(n3,s3):2] remove []): existing descriptor r12:/Table/1{6-7} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:05.103807 284 storage/replica_raft.go:291  [n1,s1,r12/1:/Table/1{6-7}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:05.104796 284 storage/replica_command.go:1586  [n1,replicate,s1,r12/1:/Table/1{6-7}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r12:/Table/1{6-7} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:05.113161 284 storage/replica_raft.go:291  [n1,s1,r12/1:/Table/1{6-7}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:05.115172 284 storage/store_snapshot.go:978  [n1,replicate,s1,r12/1:/Table/1{6-7}] sending LEARNER snapshot 8f26d3b8 at applied index 22
I191227 02:41:05.115267 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r12/1:/Table/1{6-7}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 11, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:05.115579 2810 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r12/1:/Table/1{6-7}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:05.123187 284 storage/replica_command.go:1586  [n1,replicate,s1,r12/1:/Table/1{6-7}] change replicas (add [(n2,s2):3] remove []): existing descriptor r12:/Table/1{6-7} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:05.126254 284 storage/replica_raft.go:291  [n1,s1,r12/1:/Table/1{6-7}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:05.127211 284 storage/replica_command.go:1586  [n1,replicate,s1,r1/1:/{Min-System/NodeL…}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r1:/{Min-System/NodeLiveness} [(n1,s1):1, next=2, gen=0]
I191227 02:41:05.129563 284 storage/replica_raft.go:291  [n1,s1,r1/1:/{Min-System/NodeL…}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:05.131040 284 storage/store_snapshot.go:978  [n1,replicate,s1,r1/1:/{Min-System/NodeL…}] sending LEARNER snapshot d74ba609 at applied index 159
I191227 02:41:05.131135 2851 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r1/1:/{Min-System/NodeL…}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:05.131177 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r1/1:/{Min-System/NodeL…}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 103, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:05.139140 284 storage/replica_command.go:1586  [n1,replicate,s1,r1/1:/{Min-System/NodeL…}] change replicas (add [(n3,s3):2] remove []): existing descriptor r1:/{Min-System/NodeLiveness} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:05.142109 284 storage/replica_raft.go:291  [n1,s1,r1/1:/{Min-System/NodeL…}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:05.143296 284 storage/replica_command.go:1586  [n1,replicate,s1,r1/1:/{Min-System/NodeL…}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r1:/{Min-System/NodeLiveness} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:05.145556 284 storage/replica_raft.go:291  [n1,s1,r1/1:/{Min-System/NodeL…}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:05.147422 284 storage/store_snapshot.go:978  [n1,replicate,s1,r1/1:/{Min-System/NodeL…}] sending LEARNER snapshot f56e42f4 at applied index 166
I191227 02:41:05.147524 2837 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r1/1:/{Min-System/NodeL…}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:05.147584 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r1/1:/{Min-System/NodeL…}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 110, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:05.155259 284 storage/replica_command.go:1586  [n1,replicate,s1,r1/1:/{Min-System/NodeL…}] change replicas (add [(n2,s2):3] remove []): existing descriptor r1:/{Min-System/NodeLiveness} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:05.158420 284 storage/replica_raft.go:291  [n1,s1,r1/1:/{Min-System/NodeL…}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:05.160188 284 storage/replica_command.go:1586  [n1,replicate,s1,r6/1:/Table/{SystemCon…-11}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r6:/Table/{SystemConfigSpan/Start-11} [(n1,s1):1, next=2, gen=0]
I191227 02:41:05.162461 284 storage/replica_raft.go:291  [n1,s1,r6/1:/Table/{SystemCon…-11}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:05.169562 284 storage/store_snapshot.go:978  [n1,replicate,s1,r6/1:/Table/{SystemCon…-11}] sending LEARNER snapshot 1af9f311 at applied index 55
I191227 02:41:05.169665 2861 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r6/1:/Table/{SystemCon…-11}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:05.169794 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r6/1:/Table/{SystemCon…-11}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 77, log entries: 0, rate-limit: 8.0 MiB/sec, 0.01s
I191227 02:41:05.180858 284 storage/replica_command.go:1586  [n1,replicate,s1,r6/1:/Table/{SystemCon…-11}] change replicas (add [(n3,s3):2] remove []): existing descriptor r6:/Table/{SystemConfigSpan/Start-11} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:05.183823 284 storage/replica_raft.go:291  [n1,s1,r6/1:/Table/{SystemCon…-11}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:05.184750 284 storage/replica_command.go:1586  [n1,replicate,s1,r6/1:/Table/{SystemCon…-11}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r6:/Table/{SystemConfigSpan/Start-11} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:05.193549 284 storage/replica_raft.go:291  [n1,s1,r6/1:/Table/{SystemCon…-11}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:05.195852 284 storage/store_snapshot.go:978  [n1,replicate,s1,r6/1:/Table/{SystemCon…-11}] sending LEARNER snapshot 2ae569e5 at applied index 59
I191227 02:41:05.196131 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r6/1:/Table/{SystemCon…-11}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 81, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:05.196753 2843 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r6/1:/Table/{SystemCon…-11}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:05.206340 284 storage/replica_command.go:1586  [n1,replicate,s1,r6/1:/Table/{SystemCon…-11}] change replicas (add [(n2,s2):3] remove []): existing descriptor r6:/Table/{SystemConfigSpan/Start-11} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:05.209560 284 storage/replica_raft.go:291  [n1,s1,r6/1:/Table/{SystemCon…-11}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:05.211419 284 storage/replica_command.go:1586  [n1,replicate,s1,r9/1:/Table/1{3-4}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r9:/Table/1{3-4} [(n1,s1):1, next=2, gen=0]
I191227 02:41:05.213828 284 storage/replica_raft.go:291  [n1,s1,r9/1:/Table/1{3-4}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:05.215326 284 storage/store_snapshot.go:978  [n1,replicate,s1,r9/1:/Table/1{3-4}] sending LEARNER snapshot ca28f745 at applied index 158
I191227 02:41:05.215677 2831 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r9/1:/Table/1{3-4}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:05.215742 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r9/1:/Table/1{3-4}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 397, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:05.223558 284 storage/replica_command.go:1586  [n1,replicate,s1,r9/1:/Table/1{3-4}] change replicas (add [(n3,s3):2] remove []): existing descriptor r9:/Table/1{3-4} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:05.227275 284 storage/replica_raft.go:291  [n1,s1,r9/1:/Table/1{3-4}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:05.228636 284 storage/replica_command.go:1586  [n1,replicate,s1,r9/1:/Table/1{3-4}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r9:/Table/1{3-4} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:05.239511 284 storage/replica_raft.go:291  [n1,s1,r9/1:/Table/1{3-4}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:05.241441 284 storage/store_snapshot.go:978  [n1,replicate,s1,r9/1:/Table/1{3-4}] sending LEARNER snapshot 8db06a9f at applied index 165
I191227 02:41:05.241550 2948 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r9/1:/Table/1{3-4}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:05.241871 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r9/1:/Table/1{3-4}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 406, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:05.251683 284 storage/replica_command.go:1586  [n1,replicate,s1,r9/1:/Table/1{3-4}] change replicas (add [(n2,s2):3] remove []): existing descriptor r9:/Table/1{3-4} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:05.254880 284 storage/replica_raft.go:291  [n1,s1,r9/1:/Table/1{3-4}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:05.256080 284 storage/replica_command.go:1586  [n1,replicate,s1,r10/1:/Table/1{4-5}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r10:/Table/1{4-5} [(n1,s1):1, next=2, gen=0]
I191227 02:41:05.259324 284 storage/replica_raft.go:291  [n1,s1,r10/1:/Table/1{4-5}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:05.261086 284 storage/store_snapshot.go:978  [n1,replicate,s1,r10/1:/Table/1{4-5}] sending LEARNER snapshot 4232614b at applied index 18
I191227 02:41:05.261167 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r10/1:/Table/1{4-5}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 7, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:05.261884 2955 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r10/1:/Table/1{4-5}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:05.269481 284 storage/replica_command.go:1586  [n1,replicate,s1,r10/1:/Table/1{4-5}] change replicas (add [(n3,s3):2] remove []): existing descriptor r10:/Table/1{4-5} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:05.272941 284 storage/replica_raft.go:291  [n1,s1,r10/1:/Table/1{4-5}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:05.274703 284 storage/replica_command.go:1586  [n1,replicate,s1,r10/1:/Table/1{4-5}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r10:/Table/1{4-5} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:05.285647 284 storage/replica_raft.go:291  [n1,s1,r10/1:/Table/1{4-5}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:05.287948 284 storage/store_snapshot.go:978  [n1,replicate,s1,r10/1:/Table/1{4-5}] sending LEARNER snapshot 07b8b2c1 at applied index 22
I191227 02:41:05.288079 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r10/1:/Table/1{4-5}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 11, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:05.288936 2960 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r10/1:/Table/1{4-5}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:05.324035 284 storage/replica_command.go:1586  [n1,replicate,s1,r10/1:/Table/1{4-5}] change replicas (add [(n2,s2):3] remove []): existing descriptor r10:/Table/1{4-5} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:05.328020 284 storage/replica_raft.go:291  [n1,s1,r10/1:/Table/1{4-5}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:05.329913 284 storage/replica_command.go:1586  [n1,replicate,s1,r18/1:/Table/2{2-3}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r18:/Table/2{2-3} [(n1,s1):1, next=2, gen=0]
I191227 02:41:05.332929 284 storage/replica_raft.go:291  [n1,s1,r18/1:/Table/2{2-3}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:05.334944 284 storage/store_snapshot.go:978  [n1,replicate,s1,r18/1:/Table/2{2-3}] sending LEARNER snapshot 5066b0a2 at applied index 18
I191227 02:41:05.334999 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r18/1:/Table/2{2-3}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 7, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:05.335027 2927 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r18/1:/Table/2{2-3}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:05.369233 284 storage/replica_command.go:1586  [n1,replicate,s1,r18/1:/Table/2{2-3}] change replicas (add [(n3,s3):2] remove []): existing descriptor r18:/Table/2{2-3} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:05.373225 284 storage/replica_raft.go:291  [n1,s1,r18/1:/Table/2{2-3}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:05.374530 284 storage/replica_command.go:1586  [n1,replicate,s1,r18/1:/Table/2{2-3}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r18:/Table/2{2-3} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:05.383445 284 storage/replica_raft.go:291  [n1,s1,r18/1:/Table/2{2-3}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:05.385358 284 storage/store_snapshot.go:978  [n1,replicate,s1,r18/1:/Table/2{2-3}] sending LEARNER snapshot d321fc34 at applied index 22
I191227 02:41:05.385428 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r18/1:/Table/2{2-3}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 11, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:05.386312 3013 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r18/1:/Table/2{2-3}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:05.395793 284 storage/replica_command.go:1586  [n1,replicate,s1,r18/1:/Table/2{2-3}] change replicas (add [(n2,s2):3] remove []): existing descriptor r18:/Table/2{2-3} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:05.399060 284 storage/replica_raft.go:291  [n1,s1,r18/1:/Table/2{2-3}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:05.400387 284 storage/replica_command.go:1586  [n1,replicate,s1,r3/1:/System/{NodeLive…-tsd}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r3:/System/{NodeLivenessMax-tsd} [(n1,s1):1, next=2, gen=0]
I191227 02:41:05.403607 284 storage/replica_raft.go:291  [n1,s1,r3/1:/System/{NodeLive…-tsd}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:05.406404 284 storage/store_snapshot.go:978  [n1,replicate,s1,r3/1:/System/{NodeLive…-tsd}] sending LEARNER snapshot 13dee557 at applied index 71
I191227 02:41:05.406513 3028 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r3/1:/System/{NodeLive…-tsd}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:05.406811 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r3/1:/System/{NodeLive…-tsd}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 45, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:05.417041 284 storage/replica_command.go:1586  [n1,replicate,s1,r3/1:/System/{NodeLive…-tsd}] change replicas (add [(n3,s3):2] remove []): existing descriptor r3:/System/{NodeLivenessMax-tsd} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:05.421336 284 storage/replica_raft.go:291  [n1,s1,r3/1:/System/{NodeLive…-tsd}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:05.422699 284 storage/replica_command.go:1586  [n1,replicate,s1,r3/1:/System/{NodeLive…-tsd}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r3:/System/{NodeLivenessMax-tsd} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:05.432020 284 storage/replica_raft.go:291  [n1,s1,r3/1:/System/{NodeLive…-tsd}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:05.434410 284 storage/store_snapshot.go:978  [n1,replicate,s1,r3/1:/System/{NodeLive…-tsd}] sending LEARNER snapshot d8c32d48 at applied index 75
I191227 02:41:05.434838 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r3/1:/System/{NodeLive…-tsd}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 49, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:05.435247 3074 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r3/1:/System/{NodeLive…-tsd}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:05.445939 284 storage/replica_command.go:1586  [n1,replicate,s1,r3/1:/System/{NodeLive…-tsd}] change replicas (add [(n2,s2):3] remove []): existing descriptor r3:/System/{NodeLivenessMax-tsd} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:05.448110 284 storage/replica_raft.go:291  [n1,s1,r3/1:/System/{NodeLive…-tsd}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:05.450813 284 storage/replica_command.go:1586  [n1,replicate,s1,r7/1:/Table/1{1-2}] change replicas (add [(n3,s3):2LEARNER] remove []): existing descriptor r7:/Table/1{1-2} [(n1,s1):1, next=2, gen=0]
I191227 02:41:05.453592 284 storage/replica_raft.go:291  [n1,s1,r7/1:/Table/1{1-2}] proposing ADD_REPLICA[(n3,s3):2LEARNER]: after=[(n1,s1):1 (n3,s3):2LEARNER] next=3
I191227 02:41:05.455983 284 storage/store_snapshot.go:978  [n1,replicate,s1,r7/1:/Table/1{1-2}] sending LEARNER snapshot 6d8b6cf3 at applied index 22
I191227 02:41:05.456053 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r7/1:/Table/1{1-2}] streamed snapshot to (n3,s3):2LEARNER: kv pairs: 8, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:05.456085 2937 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r7/1:/Table/1{1-2}] skipping snapshot; replica is likely a learner in the process of being added: (n3,s3):2LEARNER
I191227 02:41:05.467056 284 storage/replica_command.go:1586  [n1,replicate,s1,r7/1:/Table/1{1-2}] change replicas (add [(n3,s3):2] remove []): existing descriptor r7:/Table/1{1-2} [(n1,s1):1, (n3,s3):2LEARNER, next=3, gen=1]
I191227 02:41:05.469295 284 storage/replica_raft.go:291  [n1,s1,r7/1:/Table/1{1-2}] proposing ADD_REPLICA[(n3,s3):2]: after=[(n1,s1):1 (n3,s3):2] next=3
I191227 02:41:05.470541 284 storage/replica_command.go:1586  [n1,replicate,s1,r7/1:/Table/1{1-2}] change replicas (add [(n2,s2):3LEARNER] remove []): existing descriptor r7:/Table/1{1-2} [(n1,s1):1, (n3,s3):2, next=3, gen=2]
I191227 02:41:05.480157 284 storage/replica_raft.go:291  [n1,s1,r7/1:/Table/1{1-2}] proposing ADD_REPLICA[(n2,s2):3LEARNER]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3LEARNER] next=4
I191227 02:41:05.482794 284 storage/store_snapshot.go:978  [n1,replicate,s1,r7/1:/Table/1{1-2}] sending LEARNER snapshot b7680369 at applied index 26
I191227 02:41:05.482874 3030 storage/raft_snapshot_queue.go:125  [n1,raftsnapshot,s1,r7/1:/Table/1{1-2}] skipping snapshot; replica is likely a learner in the process of being added: (n2,s2):3LEARNER
I191227 02:41:05.482877 284 storage/store_snapshot.go:1021  [n1,replicate,s1,r7/1:/Table/1{1-2}] streamed snapshot to (n2,s2):3LEARNER: kv pairs: 12, log entries: 0, rate-limit: 8.0 MiB/sec, 0.00s
I191227 02:41:05.492775 284 storage/replica_command.go:1586  [n1,replicate,s1,r7/1:/Table/1{1-2}] change replicas (add [(n2,s2):3] remove []): existing descriptor r7:/Table/1{1-2} [(n1,s1):1, (n3,s3):2, (n2,s2):3LEARNER, next=4, gen=3]
I191227 02:41:05.497544 284 storage/replica_raft.go:291  [n1,s1,r7/1:/Table/1{1-2}] proposing ADD_REPLICA[(n2,s2):3]: after=[(n1,s1):1 (n3,s3):2 (n2,s2):3] next=4
I191227 02:41:05.499237 284 storage/queue.go:1132  [n1,replicate] purgatory is now empty
I191227 02:41:09.809525 80 server/status/runtime.go:498  [n1] runtime stats: 192 MiB RSS, 233 goroutines, 130 MiB/54 MiB/202 MiB GO alloc/idle/total, 14 MiB/20 MiB CGO alloc/total, 2477.5 CGO/sec, 5.2/7.7 %(u/s)time, 0.0 %gc (0x), 890 KiB/883 KiB (r/w)net
I191227 02:41:19.803051 76 gossip/gossip.go:566  [n1] gossip status (ok, 3 nodes)
gossip client (0/3 cur/max conns)
gossip server (2/3 cur/max conns, infos 251/86 sent/received, bytes 124063B/34803B sent/received)
  2: 192.168.80.129:26258 (31s)
  3: 192.168.80.129:26259 (16s)
gossip connectivity
  n1 [sentinel];
  n2 -> n1; n3 -> n1;
I191227 02:41:19.810551 80 server/status/runtime.go:498  [n1] runtime stats: 202 MiB RSS, 234 goroutines, 87 MiB/90 MiB/202 MiB GO alloc/idle/total, 14 MiB/21 MiB CGO alloc/total, 52.4 CGO/sec, 1.7/1.9 %(u/s)time, 0.0 %gc (1x), 320 KiB/318 KiB (r/w)net
I191227 02:41:29.810757 80 server/status/runtime.go:498  [n1] runtime stats: 202 MiB RSS, 234 goroutines, 100 MiB/79 MiB/202 MiB GO alloc/idle/total, 14 MiB/21 MiB CGO alloc/total, 82.1 CGO/sec, 1.2/2.6 %(u/s)time, 0.0 %gc (0x), 360 KiB/358 KiB (r/w)net
I191227 02:41:39.811704 80 server/status/runtime.go:498  [n1] runtime stats: 204 MiB RSS, 234 goroutines, 109 MiB/71 MiB/202 MiB GO alloc/idle/total, 14 MiB/21 MiB CGO alloc/total, 37.5 CGO/sec, 0.7/2.7 %(u/s)time, 0.0 %gc (0x), 250 KiB/250 KiB (r/w)net
I191227 02:41:49.813751 80 server/status/runtime.go:498  [n1] runtime stats: 205 MiB RSS, 234 goroutines, 118 MiB/63 MiB/202 MiB GO alloc/idle/total, 14 MiB/21 MiB CGO alloc/total, 36.5 CGO/sec, 1.1/2.3 %(u/s)time, 0.0 %gc (0x), 264 KiB/264 KiB (r/w)net
I191227 02:41:59.813152 80 server/status/runtime.go:498  [n1] runtime stats: 206 MiB RSS, 235 goroutines, 127 MiB/55 MiB/202 MiB GO alloc/idle/total, 14 MiB/21 MiB CGO alloc/total, 37.9 CGO/sec, 1.5/2.4 %(u/s)time, 0.0 %gc (0x), 252 KiB/252 KiB (r/w)net
I191227 02:42:09.813218 80 server/status/runtime.go:498  [n1] runtime stats: 206 MiB RSS, 235 goroutines, 136 MiB/46 MiB/202 MiB GO alloc/idle/total, 14 MiB/21 MiB CGO alloc/total, 31.1 CGO/sec, 1.7/3.9 %(u/s)time, 0.0 %gc (0x), 245 KiB/243 KiB (r/w)net
I191227 02:42:19.802947 76 gossip/gossip.go:566  [n1] gossip status (ok, 3 nodes)
gossip client (0/3 cur/max conns)
gossip server (2/3 cur/max conns, infos 678/205 sent/received, bytes 182269B/55244B sent/received)
  2: 192.168.80.129:26258 (1m31s)
  3: 192.168.80.129:26259 (1m16s)
I191227 02:42:19.813955 80 server/status/runtime.go:498  [n1] runtime stats: 219 MiB RSS, 235 goroutines, 148 MiB/35 MiB/202 MiB GO alloc/idle/total, 14 MiB/21 MiB CGO alloc/total, 36.5 CGO/sec, 0.8/2.3 %(u/s)time, 0.0 %gc (0x), 270 KiB/269 KiB (r/w)net
I191227 02:42:24.830461 3444 sql/event_log.go:130  [n1,client=192.168.80.129:37768,user=root] Event: "create_table", target: 52, info: {TableName:defaultdb.public.test Statement:CREATE TABLE test (id INT8) User:root}
I191227 02:42:24.835978 4381 storage/replica_command.go:411  [n1,split,s1,r24/1:/{Table/28-Max}] initiating a split of this range at key /Table/52 [r25] (zone config)
I191227 02:42:29.814870 80 server/status/runtime.go:498  [n1] runtime stats: 222 MiB RSS, 235 goroutines, 95 MiB/84 MiB/202 MiB GO alloc/idle/total, 22 MiB/30 MiB CGO alloc/total, 110.3 CGO/sec, 1.1/2.6 %(u/s)time, 0.0 %gc (1x), 354 KiB/352 KiB (r/w)net
I191227 02:42:39.815486 80 server/status/runtime.go:498  [n1] runtime stats: 222 MiB RSS, 233 goroutines, 105 MiB/76 MiB/202 MiB GO alloc/idle/total, 22 MiB/30 MiB CGO alloc/total, 36.8 CGO/sec, 0.5/2.4 %(u/s)time, 0.0 %gc (0x), 260 KiB/260 KiB (r/w)net
I191227 02:42:49.816107 80 server/status/runtime.go:498  [n1] runtime stats: 224 MiB RSS, 233 goroutines, 114 MiB/67 MiB/202 MiB GO alloc/idle/total, 22 MiB/30 MiB CGO alloc/total, 63.0 CGO/sec, 1.2/2.1 %(u/s)time, 0.0 %gc (0x), 330 KiB/329 KiB (r/w)net
I191227 02:42:59.817883 80 server/status/runtime.go:498  [n1] runtime stats: 224 MiB RSS, 234 goroutines, 124 MiB/59 MiB/202 MiB GO alloc/idle/total, 22 MiB/30 MiB CGO alloc/total, 35.8 CGO/sec, 1.1/1.6 %(u/s)time, 0.0 %gc (0x), 266 KiB/266 KiB (r/w)net
I191227 02:43:09.817994 80 server/status/runtime.go:498  [n1] runtime stats: 225 MiB RSS, 234 goroutines, 133 MiB/51 MiB/202 MiB GO alloc/idle/total, 22 MiB/30 MiB CGO alloc/total, 42.8 CGO/sec, 0.6/1.9 %(u/s)time, 0.0 %gc (0x), 256 KiB/256 KiB (r/w)net
I191227 02:43:19.803105 76 gossip/gossip.go:566  [n1] gossip status (ok, 3 nodes)
gossip client (0/3 cur/max conns)
gossip server (2/3 cur/max conns, infos 1105/326 sent/received, bytes 273958B/110355B sent/received)
  2: 192.168.80.129:26258 (2m31s)
  3: 192.168.80.129:26259 (2m16s)
I191227 02:43:19.817885 80 server/status/runtime.go:498  [n1] runtime stats: 226 MiB RSS, 234 goroutines, 142 MiB/42 MiB/202 MiB GO alloc/idle/total, 22 MiB/30 MiB CGO alloc/total, 39.0 CGO/sec, 1.3/1.9 %(u/s)time, 0.0 %gc (0x), 269 KiB/269 KiB (r/w)net
W191227 02:43:19.998786 4641 sql/stats/automatic_stats.go:450  failed to create statistics on table 52: create-stats: table is being dropped
I191227 02:43:29.819884 80 server/status/runtime.go:498  [n1] runtime stats: 228 MiB RSS, 233 goroutines, 153 MiB/31 MiB/202 MiB GO alloc/idle/total, 22 MiB/30 MiB CGO alloc/total, 57.4 CGO/sec, 1.0/2.2 %(u/s)time, 0.0 %gc (0x), 299 KiB/298 KiB (r/w)net
I191227 02:43:39.823999 80 server/status/runtime.go:498  [n1] runtime stats: 233 MiB RSS, 233 goroutines, 90 MiB/87 MiB/202 MiB GO alloc/idle/total, 22 MiB/30 MiB CGO alloc/total, 30.5 CGO/sec, 0.7/2.4 %(u/s)time, 0.0 %gc (1x), 246 KiB/254 KiB (r/w)net
I191227 02:43:49.821150 80 server/status/runtime.go:498  [n1] runtime stats: 234 MiB RSS, 233 goroutines, 99 MiB/79 MiB/202 MiB GO alloc/idle/total, 22 MiB/30 MiB CGO alloc/total, 40.3 CGO/sec, 1.0/2.0 %(u/s)time, 0.0 %gc (0x), 274 KiB/280 KiB (r/w)net
I191227 02:43:59.821678 80 server/status/runtime.go:498  [n1] runtime stats: 234 MiB RSS, 234 goroutines, 108 MiB/71 MiB/202 MiB GO alloc/idle/total, 22 MiB/30 MiB CGO alloc/total, 34.7 CGO/sec, 0.6/2.0 %(u/s)time, 0.0 %gc (0x), 256 KiB/265 KiB (r/w)net
I191227 02:44:09.822082 80 server/status/runtime.go:498  [n1] runtime stats: 235 MiB RSS, 234 goroutines, 117 MiB/63 MiB/202 MiB GO alloc/idle/total, 22 MiB/30 MiB CGO alloc/total, 36.5 CGO/sec, 0.8/1.9 %(u/s)time, 0.0 %gc (0x), 256 KiB/258 KiB (r/w)net
I191227 02:44:19.803057 76 gossip/gossip.go:566  [n1] gossip status (ok, 3 nodes)
gossip client (0/3 cur/max conns)
gossip server (2/3 cur/max conns, infos 1517/440 sent/received, bytes 327979B/129232B sent/received)
  3: 192.168.80.129:26259 (3m16s)
  2: 192.168.80.129:26258 (3m31s)
I191227 02:44:19.825697 80 server/status/runtime.go:498  [n1] runtime stats: 236 MiB RSS, 234 goroutines, 126 MiB/55 MiB/202 MiB GO alloc/idle/total, 22 MiB/30 MiB CGO alloc/total, 34.2 CGO/sec, 1.1/1.9 %(u/s)time, 0.0 %gc (0x), 268 KiB/276 KiB (r/w)net
I191227 02:44:29.823499 80 server/status/runtime.go:498  [n1] runtime stats: 236 MiB RSS, 233 goroutines, 137 MiB/46 MiB/202 MiB GO alloc/idle/total, 30 MiB/38 MiB CGO alloc/total, 55.3 CGO/sec, 1.3/3.1 %(u/s)time, 0.0 %gc (0x), 307 KiB/325 KiB (r/w)net
I191227 02:44:39.825255 80 server/status/runtime.go:498  [n1] runtime stats: 237 MiB RSS, 233 goroutines, 145 MiB/38 MiB/202 MiB GO alloc/idle/total, 30 MiB/38 MiB CGO alloc/total, 31.2 CGO/sec, 0.6/2.2 %(u/s)time, 0.0 %gc (0x), 264 KiB/267 KiB (r/w)net
I191227 02:44:49.826257 80 server/status/runtime.go:498  [n1] runtime stats: 238 MiB RSS, 233 goroutines, 83 MiB/93 MiB/202 MiB GO alloc/idle/total, 30 MiB/38 MiB CGO alloc/total, 40.7 CGO/sec, 1.4/2.9 %(u/s)time, 0.0 %gc (1x), 269 KiB/270 KiB (r/w)net
I191227 02:44:59.826989 80 server/status/runtime.go:498  [n1] runtime stats: 239 MiB RSS, 234 goroutines, 92 MiB/85 MiB/202 MiB GO alloc/idle/total, 30 MiB/38 MiB CGO alloc/total, 35.6 CGO/sec, 1.1/2.2 %(u/s)time, 0.0 %gc (0x), 248 KiB/248 KiB (r/w)net
I191227 02:45:09.827970 80 server/status/runtime.go:498  [n1] runtime stats: 239 MiB RSS, 234 goroutines, 101 MiB/77 MiB/202 MiB GO alloc/idle/total, 30 MiB/38 MiB CGO alloc/total, 31.8 CGO/sec, 0.7/2.4 %(u/s)time, 0.0 %gc (0x), 252 KiB/263 KiB (r/w)net
I191227 02:45:19.803315 76 gossip/gossip.go:566  [n1] gossip status (ok, 3 nodes)
gossip client (0/3 cur/max conns)
gossip server (2/3 cur/max conns, infos 1937/556 sent/received, bytes 382971B/148442B sent/received)
  2: 192.168.80.129:26258 (4m31s)
  3: 192.168.80.129:26259 (4m16s)
I191227 02:45:19.828556 80 server/status/runtime.go:498  [n1] runtime stats: 240 MiB RSS, 234 goroutines, 110 MiB/70 MiB/202 MiB GO alloc/idle/total, 30 MiB/38 MiB CGO alloc/total, 36.0 CGO/sec, 0.9/2.6 %(u/s)time, 0.0 %gc (0x), 263 KiB/263 KiB (r/w)net
I191227 02:45:29.829650 80 server/status/runtime.go:498  [n1] runtime stats: 240 MiB RSS, 233 goroutines, 121 MiB/61 MiB/202 MiB GO alloc/idle/total, 30 MiB/38 MiB CGO alloc/total, 54.5 CGO/sec, 0.6/2.9 %(u/s)time, 0.0 %gc (0x), 287 KiB/293 KiB (r/w)net
I191227 02:45:30.510617 7143 sql/lease.go:1852  refreshing table: 52 lease failed: table is being dropped
I191227 02:45:39.831106 80 server/status/runtime.go:498  [n1] runtime stats: 241 MiB RSS, 233 goroutines, 130 MiB/53 MiB/202 MiB GO alloc/idle/total, 30 MiB/38 MiB CGO alloc/total, 38.9 CGO/sec, 0.9/2.8 %(u/s)time, 0.0 %gc (0x), 272 KiB/282 KiB (r/w)net
I191227 02:45:49.831236 80 server/status/runtime.go:498  [n1] runtime stats: 242 MiB RSS, 233 goroutines, 139 MiB/45 MiB/202 MiB GO alloc/idle/total, 30 MiB/38 MiB CGO alloc/total, 30.3 CGO/sec, 1.2/1.9 %(u/s)time, 0.0 %gc (0x), 262 KiB/275 KiB (r/w)net
I191227 02:45:59.832117 80 server/status/runtime.go:498  [n1] runtime stats: 242 MiB RSS, 234 goroutines, 147 MiB/36 MiB/202 MiB GO alloc/idle/total, 30 MiB/38 MiB CGO alloc/total, 38.0 CGO/sec, 0.6/2.5 %(u/s)time, 0.0 %gc (0x), 259 KiB/264 KiB (r/w)net
I191227 02:46:09.835230 80 server/status/runtime.go:498  [n1] runtime stats: 244 MiB RSS, 234 goroutines, 84 MiB/92 MiB/202 MiB GO alloc/idle/total, 30 MiB/38 MiB CGO alloc/total, 30.1 CGO/sec, 1.7/1.9 %(u/s)time, 0.0 %gc (1x), 247 KiB/251 KiB (r/w)net
I191227 02:46:19.803203 76 gossip/gossip.go:566  [n1] gossip status (ok, 3 nodes)
gossip client (0/3 cur/max conns)
gossip server (2/3 cur/max conns, infos 2357/672 sent/received, bytes 437963B/167652B sent/received)
  3: 192.168.80.129:26259 (5m16s)
  2: 192.168.80.129:26258 (5m31s)
I191227 02:46:19.834349 80 server/status/runtime.go:498  [n1] runtime stats: 244 MiB RSS, 234 goroutines, 94 MiB/84 MiB/202 MiB GO alloc/idle/total, 30 MiB/38 MiB CGO alloc/total, 42.3 CGO/sec, 0.8/2.4 %(u/s)time, 0.0 %gc (0x), 272 KiB/278 KiB (r/w)net
I191227 02:46:20.096669 7879 sql/event_log.go:130  [n1,client=192.168.80.129:37774,user=root] Event: "create_database", target: 53, info: {DatabaseName:tpcc_51 Statement:CREATE DATABASE tpcc_51 User:root}
I191227 02:46:20.178641 7955 storage/replica_command.go:411  [n1,s1,r25/1:/{Table/52-Max}] initiating a split of this range at key /Table/54/1 [r26] (manual)
I191227 02:46:20.261136 7946 storage/replica_command.go:411  [n1,split,s1,r25/1:/Table/5{2-4/1}] initiating a split of this range at key /Table/54 [r27] (zone config)
I191227 02:46:20.301971 7994 storage/replica_command.go:411  [n1,s1,r26/1:/{Table/54/1-Max}] initiating a split of this range at key /Table/55/1 [r28] (manual)
I191227 02:46:24.219077 8126 storage/replica_command.go:411  [n1,s1,r28/1:/{Table/55/1-Max}] initiating a split of this range at key /Table/55/1/-9223356302416747688 [r29] (manual)
I191227 02:46:29.834714 80 server/status/runtime.go:498  [n1] runtime stats: 416 MiB RSS, 241 goroutines, 99 MiB/270 MiB/354 MiB GO alloc/idle/total, 40 MiB/48 MiB CGO alloc/total, 402.8 CGO/sec, 5.2/8.6 %(u/s)time, 0.1 %gc (7x), 206 MiB/206 MiB (r/w)net
I191227 02:46:39.835309 80 server/status/runtime.go:498  [n1] runtime stats: 418 MiB RSS, 241 goroutines, 127 MiB/242 MiB/355 MiB GO alloc/idle/total, 41 MiB/50 MiB CGO alloc/total, 178.7 CGO/sec, 6.4/3.7 %(u/s)time, 0.0 %gc (5x), 186 MiB/186 MiB (r/w)net
W191227 02:46:45.087185 154 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W191227 02:46:46.192144 139 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 638.697265ms (>= warning threshold 500ms)
W191227 02:46:46.956475 130 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W191227 02:46:52.376839 105 storage/engine/rocksdb.go:2076  batch [0/14/0] commit took 2.530323238s (>= warning threshold 500ms)
W191227 02:46:52.378044 140 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 3.3s [applied=0, batches=0, state_assertions=0]
W191227 02:46:52.378367 154 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 3.3s [applied=0, batches=0, state_assertions=0]
I191227 02:46:52.404003 80 server/status/runtime.go:498  [n1] runtime stats: 452 MiB RSS, 247 goroutines, 178 MiB/191 MiB/355 MiB GO alloc/idle/total, 42 MiB/50 MiB CGO alloc/total, 38.9 CGO/sec, 22.4/91.1 %(u/s)time, 1.1 %gc (1x), 56 MiB/56 MiB (r/w)net
W191227 02:46:53.374674 149 storage/engine/rocksdb.go:2076  batch [6/27662/0] commit took 640.731099ms (>= warning threshold 500ms)
W191227 02:46:54.021414 56 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 646.044356ms (>= warning threshold 500ms)
W191227 02:46:54.021975 153 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.3s [applied=0, batches=0, state_assertions=0]
W191227 02:46:54.022773 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 1.6s
W191227 02:46:54.022876 149 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.5s [applied=0, batches=0, state_assertions=0]
W191227 02:46:54.812099 154 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:46:54.812393 63 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:46:55.196540 141 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W191227 02:46:55.396001 58 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 588.714915ms (>= warning threshold 500ms)
I191227 02:46:59.879790 80 server/status/runtime.go:498  [n1] runtime stats: 453 MiB RSS, 243 goroutines, 189 MiB/181 MiB/358 MiB GO alloc/idle/total, 42 MiB/50 MiB CGO alloc/total, 50.7 CGO/sec, 19.0/100.7 %(u/s)time, 0.0 %gc (0x), 136 KiB/136 KiB (r/w)net
W191227 02:47:00.950391 161 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W191227 02:47:05.435434 160 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W191227 02:47:06.498718 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 1.7s
W191227 02:47:07.384997 133 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 1.206101537s (>= warning threshold 500ms)
W191227 02:47:08.028812 135 storage/engine/rocksdb.go:2076  batch [2/162/0] commit took 588.556799ms (>= warning threshold 500ms)
W191227 02:47:08.354030 142 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 1.3s [applied=0, batches=0, state_assertions=0]
W191227 02:47:08.354221 57 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W191227 02:47:08.884740 142 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
I191227 02:47:17.542760 80 server/status/runtime.go:498  [n1] runtime stats: 477 MiB RSS, 246 goroutines, 193 MiB/176 MiB/368 MiB GO alloc/idle/total, 54 MiB/64 MiB CGO alloc/total, 7682.1 CGO/sec, 16.4/134.8 %(u/s)time, 0.0 %gc (1x), 29 MiB/29 MiB (r/w)net
W191227 02:47:17.620482 152 storage/engine/rocksdb.go:2076  batch [1/79111/0] commit took 8.13632317s (>= warning threshold 500ms)
W191227 02:47:17.632462 2442 vendor/google.golang.org/grpc/clientconn.go:1206  grpc: addrConn.createTransport failed to connect to {192.168.80.129:26259 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W191227 02:47:17.632590 2393 vendor/google.golang.org/grpc/clientconn.go:1206  grpc: addrConn.createTransport failed to connect to {192.168.80.129:26258 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W191227 02:47:17.632638 2387 storage/raft_transport.go:634  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W191227 02:47:17.748919 2113 storage/raft_transport.go:634  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W191227 02:47:17.749131 2097 vendor/google.golang.org/grpc/clientconn.go:1206  grpc: addrConn.createTransport failed to connect to {192.168.80.129:26259 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W191227 02:47:17.821373 1575 vendor/google.golang.org/grpc/clientconn.go:1206  grpc: addrConn.createTransport failed to connect to {192.168.80.129:26258 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W191227 02:47:17.821847 2185 storage/raft_transport.go:634  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
I191227 02:47:17.822542 81 vendor/github.com/cockroachdb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc 192.168.80.129:26257 [n3] tripped: failed to check for ready connection to n3 at 192.168.80.129:26259: connection not ready: TRANSIENT_FAILURE
I191227 02:47:17.906687 81 vendor/github.com/cockroachdb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc 192.168.80.129:26257 [n3] event: BreakerTripped
W191227 02:47:17.822587 2388 storage/raft_transport.go:634  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
I191227 02:47:17.840909 285 rpc/nodedialer/nodedialer.go:160  [n1,summaries] unable to connect to n3: failed to check for ready connection to n3 at 192.168.80.129:26259: connection not ready: TRANSIENT_FAILURE
W191227 02:47:17.841566 108 gossip/gossip.go:1522  [n1] first range unavailable; trying remaining resolvers
W191227 02:47:17.841770 115 storage/closedts/provider/provider.go:150  [ct-closer] unable to move closed timestamp forward: not live
github.com/cockroachdb/cockroach/pkg/storage.init.ializers
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/storage/node_liveness.go:57
runtime.main
	/usr/local/go/src/runtime/proc.go:188
runtime.goexit
	/usr/local/go/src/runtime/asm_amd64.s:1337
I191227 02:47:18.063062 8964 gossip/client.go:124  [n1] started gossip client to 192.168.80.129:26259
W191227 02:47:18.699131 53 storage/engine/rocksdb.go:2076  batch [11/81468/0] commit took 854.876932ms (>= warning threshold 500ms)
I191227 02:47:19.828704 76 gossip/gossip.go:566  [n1] gossip status (stalled, 3 nodes)
gossip client (1/3 cur/max conns)
  3: 192.168.80.129:26259 (2s: infos 7/8 sent/received, bytes 1242B/1394B sent/received)
gossip server (1/3 cur/max conns, infos 2768/845 sent/received, bytes 531050B/226093B sent/received)
  2: 192.168.80.129:26258 (6m31s)
gossip connectivity
  n1 -> n3; n2 -> n1; n2 -> n3;
W191227 02:47:22.264000 53 storage/engine/rocksdb.go:2076  batch [694/79141/0] commit took 2.586322308s (>= warning threshold 500ms)
W191227 02:47:22.276965 146 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 3.1s [applied=0, batches=0, state_assertions=0]
I191227 02:47:22.277581 9058 gossip/client.go:124  [n1] started gossip client to 192.168.80.129:26258
I191227 02:47:22.278268 80 server/status/runtime.go:498  [n1] runtime stats: 489 MiB RSS, 250 goroutines, 213 MiB/157 MiB/369 MiB GO alloc/idle/total, 56 MiB/66 MiB CGO alloc/total, 4245.6 CGO/sec, 15.6/174.8 %(u/s)time, 0.0 %gc (0x), 100 KiB/107 KiB (r/w)net
I191227 02:47:22.300140 9039 vendor/github.com/cockroachdb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc 192.168.80.129:26257 [n3] event: BreakerReset
I191227 02:47:22.326978 198 storage/node_liveness.go:846  [n1,liveness-hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context deadline exceeded)
W191227 02:47:22.326994 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 13.0s
W191227 02:47:22.327013 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W191227 02:47:22.823071 175 storage/store_rebalancer.go:219  [n1,s1,store-rebalancer] StorePool missing descriptor for local store
W191227 02:47:22.834806 8962 storage/node_liveness.go:559  [n1,s1,r21/1:/Table/2{5-6}] slow heartbeat took 5.0s
E191227 02:47:22.834839 8962 storage/replica_range_lease.go:339  [n1,s1,r21/1:/Table/2{5-6}] heartbeat failed on epoch increment
I191227 02:47:22.835231 198 storage/node_liveness.go:474  [n1,liveness-hb] heartbeat failed on epoch increment; retrying
W191227 02:47:22.837303 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:1}]}
W191227 02:47:23.418794 135 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
I191227 02:47:24.022170 108 gossip/gossip.go:1531  [n1] node has connected to cluster via gossip
W191227 02:47:24.571704 56 storage/engine/rocksdb.go:2076  batch [694/79183/0] commit took 1.151363073s (>= warning threshold 500ms)
W191227 02:47:25.754371 154 storage/engine/rocksdb.go:2076  batch [1/79111/0] commit took 1.084027905s (>= warning threshold 500ms)
W191227 02:47:26.587127 132 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W191227 02:47:26.847354 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 3.9s
W191227 02:47:26.847491 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W191227 02:47:28.075602 132 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.5s [applied=0, batches=0, state_assertions=0]
W191227 02:47:28.378686 154 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 554.392315ms (>= warning threshold 500ms)
W191227 02:47:29.213664 154 storage/engine/rocksdb.go:2076  batch [4/79352/0] commit took 834.464413ms (>= warning threshold 500ms)
W191227 02:47:29.922975 160 storage/engine/rocksdb.go:2076  batch [7/574/0] commit took 708.834019ms (>= warning threshold 500ms)
I191227 02:47:29.924838 80 server/status/runtime.go:498  [n1] runtime stats: 496 MiB RSS, 265 goroutines, 110 MiB/260 MiB/371 MiB GO alloc/idle/total, 63 MiB/73 MiB CGO alloc/total, 10860.5 CGO/sec, 24.1/190.3 %(u/s)time, 0.0 %gc (1x), 494 KiB/495 KiB (r/w)net
W191227 02:47:29.925785 9022 storage/node_liveness.go:559  [n1,s1,r11/1:/Table/1{5-6}] slow heartbeat took 7.4s
E191227 02:47:29.925803 9022 storage/replica_range_lease.go:339  [n1,s1,r11/1:/Table/1{5-6}] heartbeat failed on epoch increment
W191227 02:47:29.926157 9112 storage/node_liveness.go:559  [n1,s1,r28/1:/Table/55/1{-/-92233…}] slow heartbeat took 7.4s
E191227 02:47:29.926167 9112 storage/replica_range_lease.go:339  [n1,s1,r28/1:/Table/55/1{-/-92233…}] heartbeat failed on epoch increment
W191227 02:47:29.926411 9008 storage/node_liveness.go:559  [n1,s1,r9/1:/Table/1{3-4}] slow heartbeat took 7.3s
E191227 02:47:29.926420 9008 storage/replica_range_lease.go:339  [n1,s1,r9/1:/Table/1{3-4}] heartbeat failed on epoch increment
W191227 02:47:29.954328 9163 storage/node_liveness.go:559  [n1,s1,r18/1:/Table/2{2-3}] slow heartbeat took 7.1s
E191227 02:47:29.954369 9163 storage/replica_range_lease.go:339  [n1,s1,r18/1:/Table/2{2-3}] heartbeat failed on epoch increment
W191227 02:47:30.121310 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:6}]}
W191227 02:47:31.389729 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 4.5s
W191227 02:47:31.389758 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s:
  - context deadline exceeded
W191227 02:47:31.428383 132 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:47:32.492083 154 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 1.233573827s (>= warning threshold 500ms)
W191227 02:47:34.329306 108 gossip/gossip.go:1520  [n1] first range unavailable; resolvers exhausted
I191227 02:47:34.419586 9287 internal/client/txn.go:630  [n1] async rollback failed: context deadline exceeded
W191227 02:47:35.125311 154 storage/engine/rocksdb.go:2076  batch [1383/158024/0] commit took 2.541250638s (>= warning threshold 500ms)
W191227 02:47:35.892481 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 4.5s
W191227 02:47:35.892537 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
I191227 02:47:36.141312 108 gossip/gossip.go:1531  [n1] node has connected to cluster via gossip
W191227 02:47:36.515876 62 storage/engine/rocksdb.go:2076  batch [2/26887/0] commit took 1.334994785s (>= warning threshold 500ms)
W191227 02:47:38.271590 147 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.4s [applied=0, batches=0, state_assertions=0]
W191227 02:47:38.902964 154 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 770.93971ms (>= warning threshold 500ms)
W191227 02:47:39.230618 147 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W191227 02:47:39.565275 9231 storage/node_liveness.go:559  [n1,s1,r11/1:/Table/1{5-6}] slow heartbeat took 9.6s
W191227 02:47:39.565462 9282 storage/node_liveness.go:559  [n1,s1,r24/1:/Table/{28-52}] slow heartbeat took 9.6s
W191227 02:47:39.565704 9285 storage/node_liveness.go:559  [n1,s1,r9/1:/Table/1{3-4}] slow heartbeat took 9.6s
W191227 02:47:39.602088 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 3.7s
I191227 02:47:39.937610 80 server/status/runtime.go:498  [n1] runtime stats: 505 MiB RSS, 252 goroutines, 126 MiB/247 MiB/371 MiB GO alloc/idle/total, 70 MiB/80 MiB CGO alloc/total, 8049.0 CGO/sec, 18.3/169.9 %(u/s)time, 0.0 %gc (0x), 447 KiB/447 KiB (r/w)net
W191227 02:47:40.003205 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:1}]}
W191227 02:47:43.749221 132 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W191227 02:47:46.344833 141 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 815.638227ms (>= warning threshold 500ms)
W191227 02:47:47.084892 142 storage/engine/rocksdb.go:2076  batch [1/68/0] commit took 582.030024ms (>= warning threshold 500ms)
I191227 02:47:49.960975 80 server/status/runtime.go:498  [n1] runtime stats: 521 MiB RSS, 249 goroutines, 148 MiB/228 MiB/371 MiB GO alloc/idle/total, 84 MiB/95 MiB CGO alloc/total, 17091.4 CGO/sec, 18.7/171.5 %(u/s)time, 0.0 %gc (0x), 422 KiB/424 KiB (r/w)net
W191227 02:47:51.102181 131 storage/engine/rocksdb.go:2076  batch [4/27442/0] commit took 1.566704648s (>= warning threshold 500ms)
W191227 02:47:51.289234 57 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W191227 02:47:51.466276 61 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:47:51.740303 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 1.9s
W191227 02:47:56.160650 58 storage/engine/rocksdb.go:2076  batch [1/135/0] commit took 556.252905ms (>= warning threshold 500ms)
W191227 02:47:56.467327 52 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W191227 02:47:59.653360 142 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
I191227 02:47:59.937442 80 server/status/runtime.go:498  [n1] runtime stats: 538 MiB RSS, 247 goroutines, 159 MiB/217 MiB/378 MiB GO alloc/idle/total, 99 MiB/111 MiB CGO alloc/total, 17591.4 CGO/sec, 18.3/177.2 %(u/s)time, 0.0 %gc (0x), 345 KiB/348 KiB (r/w)net
W191227 02:48:00.926931 55 storage/engine/rocksdb.go:2076  batch [2/79168/0] commit took 738.644999ms (>= warning threshold 500ms)
W191227 02:48:01.297379 149 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W191227 02:48:02.199740 55 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 779.090001ms (>= warning threshold 500ms)
W191227 02:48:04.160342 55 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 1.528801352s (>= warning threshold 500ms)
W191227 02:48:04.688089 131 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W191227 02:48:04.808690 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 1.5s
W191227 02:48:05.603679 60 storage/engine/rocksdb.go:2076  batch [1/79111/0] commit took 666.751363ms (>= warning threshold 500ms)
W191227 02:48:06.404344 151 storage/engine/rocksdb.go:2076  batch [2/452/0] commit took 800.040583ms (>= warning threshold 500ms)
W191227 02:48:06.908107 151 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.5s [applied=0, batches=0, state_assertions=0]
W191227 02:48:06.908132 130 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 1.3s [applied=0, batches=0, state_assertions=0]
W191227 02:48:06.908318 155 storage/store_raft.go:514  [n1,s1,r29/1:/Table/55/1/-9223356302416…] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W191227 02:48:07.721129 60 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 735.715736ms (>= warning threshold 500ms)
I191227 02:48:07.958126 9784 sql/lease.go:1852  refreshing table: 52 lease failed: table is being dropped
W191227 02:48:08.456466 163 storage/engine/rocksdb.go:2076  batch [5/326/0] commit took 542.166224ms (>= warning threshold 500ms)
W191227 02:48:08.843078 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 1.0s
W191227 02:48:10.067588 53 storage/engine/rocksdb.go:2076  batch [1/79111/0] commit took 1.0247142s (>= warning threshold 500ms)
I191227 02:48:10.221312 80 server/status/runtime.go:498  [n1] runtime stats: 548 MiB RSS, 260 goroutines, 167 MiB/208 MiB/386 MiB GO alloc/idle/total, 108 MiB/122 MiB CGO alloc/total, 11505.3 CGO/sec, 19.2/188.6 %(u/s)time, 0.0 %gc (0x), 296 KiB/297 KiB (r/w)net
W191227 02:48:10.519760 147 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W191227 02:48:11.272257 53 storage/engine/rocksdb.go:2076  batch [1/79111/0] commit took 786.058095ms (>= warning threshold 500ms)
W191227 02:48:11.890255 64 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.4s [applied=0, batches=0, state_assertions=0]
W191227 02:48:11.891519 147 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.4s [applied=0, batches=0, state_assertions=0]
W191227 02:48:18.526763 134 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 2.138310203s (>= warning threshold 500ms)
W191227 02:48:19.105665 52 storage/engine/rocksdb.go:2076  batch [2/26923/0] commit took 578.610769ms (>= warning threshold 500ms)
W191227 02:48:19.482612 131 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 2.7s [applied=0, batches=0, state_assertions=0]
W191227 02:48:19.482612 155 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 2.8s [applied=0, batches=0, state_assertions=0]
I191227 02:48:19.805707 76 gossip/gossip.go:566  [n1] gossip status (ok, 3 nodes)
gossip client (2/3 cur/max conns)
  3: 192.168.80.129:26259 (1m2s: infos 212/194 sent/received, bytes 50100B/47482B sent/received)
  2: 192.168.80.129:26258 (58s: infos 206/169 sent/received, bytes 35711B/44615B sent/received)
gossip server (0/3 cur/max conns, infos 3207/1238 sent/received, bytes 620695B/334454B sent/received)
gossip connectivity
  n1 [sentinel];
  n1 -> n2; n1 -> n3; n2 -> n3;
I191227 02:48:20.156087 80 server/status/runtime.go:498  [n1] runtime stats: 571 MiB RSS, 256 goroutines, 177 MiB/199 MiB/393 MiB GO alloc/idle/total, 136 MiB/151 MiB CGO alloc/total, 23465.0 CGO/sec, 19.3/208.1 %(u/s)time, 0.0 %gc (0x), 309 KiB/309 KiB (r/w)net
W191227 02:48:20.177309 155 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W191227 02:48:20.400998 131 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W191227 02:48:20.628642 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 3.8s
W191227 02:48:21.709749 131 storage/engine/rocksdb.go:2076  batch [4/79310/0] commit took 1.283218179s (>= warning threshold 500ms)
W191227 02:48:22.712654 158 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.8s [applied=0, batches=0, state_assertions=0]
W191227 02:48:22.714420 157 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W191227 02:48:23.553851 60 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:48:23.553900 158 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:48:23.554270 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 2.3s
E191227 02:48:23.837617 9866 storage/consistency_queue.go:134  [n1,consistencyChecker,s1,r29/1:/Table/55/1/-9223356302416…] computing own checksum: operation "collect checksum" timed out after 15s: rpc error: code = DeadlineExceeded desc = context deadline exceeded
E191227 02:48:23.837706 9866 storage/queue.go:1032  [n1,consistencyChecker,s1,r29/1:/Table/55/1/-9223356302416…] computing own checksum: operation "collect checksum" timed out after 15s: rpc error: code = DeadlineExceeded desc = context deadline exceeded
W191227 02:48:24.182627 60 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W191227 02:48:24.763201 138 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 519.864898ms (>= warning threshold 500ms)
W191227 02:48:25.703072 153 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.5s [applied=0, batches=0, state_assertions=0]
W191227 02:48:26.121449 141 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:48:28.245636 135 storage/engine/rocksdb.go:2076  batch [693/79094/0] commit took 1.383938516s (>= warning threshold 500ms)
W191227 02:48:28.963151 158 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W191227 02:48:28.963630 137 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.1s [applied=0, batches=0, state_assertions=0]
W191227 02:48:28.965210 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 3.1s
W191227 02:48:31.708081 59 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
I191227 02:48:32.107501 80 server/status/runtime.go:498  [n1] runtime stats: 584 MiB RSS, 256 goroutines, 188 MiB/188 MiB/400 MiB GO alloc/idle/total, 145 MiB/162 MiB CGO alloc/total, 8830.8 CGO/sec, 19.8/208.8 %(u/s)time, 0.0 %gc (0x), 335 KiB/336 KiB (r/w)net
W191227 02:48:32.652649 52 storage/engine/rocksdb.go:2076  batch [2/79279/0] commit took 675.449583ms (>= warning threshold 500ms)
W191227 02:48:33.343494 159 storage/engine/rocksdb.go:2076  batch [1/50/0] commit took 690.400291ms (>= warning threshold 500ms)
W191227 02:48:33.493771 59 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.8s [applied=0, batches=0, state_assertions=0]
W191227 02:48:33.842723 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 3.3s
W191227 02:48:35.604425 52 storage/engine/rocksdb.go:2076  batch [693/79136/0] commit took 1.07968279s (>= warning threshold 500ms)
W191227 02:48:36.114379 139 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 1.2s [applied=0, batches=0, state_assertions=0]
W191227 02:48:36.114643 63 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.4s [applied=0, batches=0, state_assertions=0]
W191227 02:48:37.198415 52 storage/engine/rocksdb.go:2076  batch [3/158248/0] commit took 1.505904751s (>= warning threshold 500ms)
W191227 02:48:38.070189 61 storage/engine/rocksdb.go:2076  batch [5/27511/0] commit took 871.602676ms (>= warning threshold 500ms)
W191227 02:48:38.648193 63 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 2.5s [applied=0, batches=0, state_assertions=0]
W191227 02:48:38.648386 64 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 2.9s [applied=0, batches=0, state_assertions=0]
W191227 02:48:38.648397 139 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 2.5s [applied=0, batches=0, state_assertions=0]
W191227 02:48:39.627864 105 storage/engine/rocksdb.go:2076  batch [692/79059/0] commit took 1.459800351s (>= warning threshold 500ms)
W191227 02:48:39.861318 108 gossip/gossip.go:1520  [n1] first range unavailable; resolvers exhausted
W191227 02:48:40.243109 64 storage/engine/rocksdb.go:2076  batch [8/27751/0] commit took 586.34824ms (>= warning threshold 500ms)
E191227 02:48:40.246703 10375 storage/replica_range_lease.go:339  [n1,s1,r11/1:/Table/1{5-6}] context canceled
W191227 02:48:40.342854 64 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.7s [applied=0, batches=0, state_assertions=0]
I191227 02:48:40.343072 198 storage/node_liveness.go:846  [n1,liveness-hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context deadline exceeded)
W191227 02:48:40.343083 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 5.5s
W191227 02:48:40.343100 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W191227 02:48:40.425854 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:1}]}
I191227 02:48:40.630367 10371 storage/queue.go:1132  [n1,replicate] purgatory is now empty
I191227 02:48:40.851563 80 server/status/runtime.go:498  [n1] runtime stats: 600 MiB RSS, 258 goroutines, 101 MiB/265 MiB/401 MiB GO alloc/idle/total, 158 MiB/175 MiB CGO alloc/total, 18003.2 CGO/sec, 28.1/239.8 %(u/s)time, 0.0 %gc (1x), 256 KiB/262 KiB (r/w)net
W191227 02:48:41.310590 64 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
I191227 02:48:41.606898 108 gossip/gossip.go:1531  [n1] node has connected to cluster via gossip
W191227 02:48:41.611289 10376 storage/node_liveness.go:559  [n1,s1,r11/1:/Table/1{5-6}] slow heartbeat took 1.4s
W191227 02:48:41.611638 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 1.3s
W191227 02:48:43.063854 145 storage/engine/rocksdb.go:2076  batch [1/50/0] commit took 600.16899ms (>= warning threshold 500ms)
W191227 02:48:46.612221 53 storage/engine/rocksdb.go:2076  batch [2/26953/0] commit took 3.409066464s (>= warning threshold 500ms)
W191227 02:48:47.311373 143 storage/engine/rocksdb.go:2076  batch [3/659/0] commit took 698.807404ms (>= warning threshold 500ms)
W191227 02:48:48.553837 115 storage/closedts/provider/provider.go:150  [ct-closer] unable to move closed timestamp forward: not live
github.com/cockroachdb/cockroach/pkg/storage.init.ializers
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/storage/node_liveness.go:57
runtime.main
	/usr/local/go/src/runtime/proc.go:188
runtime.goexit
	/usr/local/go/src/runtime/asm_amd64.s:1337
W191227 02:48:48.732366 153 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 2.7s [applied=0, batches=0, state_assertions=0]
W191227 02:48:48.732398 143 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 5.4s [applied=0, batches=0, state_assertions=0]
W191227 02:48:48.732366 132 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 4.4s [applied=0, batches=0, state_assertions=0]
W191227 02:48:49.559716 143 storage/engine/rocksdb.go:2076  batch [3/600/0] commit took 827.084576ms (>= warning threshold 500ms)
W191227 02:48:50.536118 153 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 1.8s [applied=0, batches=0, state_assertions=0]
I191227 02:48:50.857876 80 server/status/runtime.go:498  [n1] runtime stats: 607 MiB RSS, 263 goroutines, 108 MiB/260 MiB/401 MiB GO alloc/idle/total, 163 MiB/181 MiB CGO alloc/total, 6033.5 CGO/sec, 14.6/140.2 %(u/s)time, 0.0 %gc (0x), 290 KiB/293 KiB (r/w)net
W191227 02:48:50.957079 151 storage/engine/rocksdb.go:2076  batch [4/237347/0] commit took 1.39726066s (>= warning threshold 500ms)
W191227 02:48:52.007641 153 storage/engine/rocksdb.go:2076  batch [2/280/0] commit took 1.050406035s (>= warning threshold 500ms)
W191227 02:48:52.584575 143 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 3.9s [applied=0, batches=0, state_assertions=0]
I191227 02:48:52.584941 198 storage/node_liveness.go:846  [n1,liveness-hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context deadline exceeded)
W191227 02:48:52.584954 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 8.7s
W191227 02:48:52.584974 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W191227 02:48:52.860488 58 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:48:53.168868 144 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
I191227 02:48:55.629612 10439 internal/client/txn.go:630  [n1] async rollback failed: context deadline exceeded
W191227 02:48:57.119675 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 4.5s
W191227 02:48:57.119714 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W191227 02:48:58.798737 108 gossip/gossip.go:1520  [n1] first range unavailable; resolvers exhausted
W191227 02:48:59.998910 135 storage/engine/rocksdb.go:2076  batch [3/600/0] commit took 4.770454268s (>= warning threshold 500ms)
W191227 02:49:00.356966 135 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 5.1s [applied=0, batches=0, state_assertions=0]
W191227 02:49:00.423571 140 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 3.0s [applied=0, batches=0, state_assertions=0]
W191227 02:49:00.423577 55 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 4.6s [applied=0, batches=0, state_assertions=0]
I191227 02:49:00.891772 80 server/status/runtime.go:498  [n1] runtime stats: 610 MiB RSS, 259 goroutines, 110 MiB/259 MiB/401 MiB GO alloc/idle/total, 166 MiB/185 MiB CGO alloc/total, 4331.9 CGO/sec, 0.0/166.1 %(u/s)time, 0.0 %gc (0x), 98 KiB/99 KiB (r/w)net
W191227 02:49:01.651637 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 4.5s
W191227 02:49:01.651693 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W191227 02:49:02.170025 10498 storage/node_liveness.go:559  [n1,s1,r19/1:/Table/2{3-4}] slow heartbeat took 15.7s
E191227 02:49:02.170042 10498 storage/replica_range_lease.go:339  [n1,s1,r19/1:/Table/2{3-4}] heartbeat failed on epoch increment
I191227 02:49:02.170428 198 storage/node_liveness.go:474  [n1,liveness-hb] heartbeat failed on epoch increment; retrying
E191227 02:49:02.170459 10621 storage/replica_range_lease.go:339  [n1,s1,r11/1:/Table/1{5-6}] heartbeat failed on epoch increment
I191227 02:49:02.853012 108 gossip/gossip.go:1531  [n1] node has connected to cluster via gossip
W191227 02:49:02.975912 161 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:49:02.975992 147 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
E191227 02:49:04.103787 10701 storage/replica_range_lease.go:383  [n1,s1,r49/1:/Table/55/1/-9223356302413…] mismatch incrementing epoch for {NodeID:3 Epoch:1 Expiration:1577414932.872341930,0 Draining:false Decommissioning:false}; actual is {NodeID:3 Epoch:1 Expiration:1577414951.692901583,0 Draining:false Decommissioning:false}
I191227 02:49:04.104393 10453 storage/queue.go:1132  [n1,replicate] purgatory is now empty
W191227 02:49:04.800402 10335 storage/replica_raft.go:105  [n1,s1,r11/1:/Table/1{5-6}] context canceled before proposing: 1 HeartbeatTxn
W191227 02:49:05.385643 52 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W191227 02:49:05.400764 10787 storage/node_liveness.go:559  [n1,s1,r13/1:/Table/1{7-8}] slow heartbeat took 1.3s
W191227 02:49:05.660671 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:4}]}
W191227 02:49:06.979099 153 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W191227 02:49:08.348369 135 storage/engine/rocksdb.go:2076  batch [2074/236991/0] commit took 1.330375164s (>= warning threshold 500ms)
W191227 02:49:08.928818 155 storage/store_raft.go:514  [n1,s1,r24/1:/Table/{28-52}] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W191227 02:49:11.156144 137 storage/engine/rocksdb.go:2076  batch [7/316797/0] commit took 983.455069ms (>= warning threshold 500ms)
I191227 02:49:11.332077 80 server/status/runtime.go:498  [n1] runtime stats: 658 MiB RSS, 255 goroutines, 123 MiB/245 MiB/401 MiB GO alloc/idle/total, 210 MiB/233 MiB CGO alloc/total, 49751.3 CGO/sec, 22.7/174.9 %(u/s)time, 0.0 %gc (1x), 29 MiB/29 MiB (r/w)net
W191227 02:49:11.976936 141 storage/engine/rocksdb.go:2076  batch [5/925/0] commit took 755.512856ms (>= warning threshold 500ms)
W191227 02:49:13.394329 157 storage/engine/rocksdb.go:2076  batch [2/26893/0] commit took 1.417191848s (>= warning threshold 500ms)
W191227 02:49:14.038762 141 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 3.7s [applied=0, batches=0, state_assertions=0]
W191227 02:49:14.038891 156 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 3.5s [applied=0, batches=0, state_assertions=0]
W191227 02:49:14.039060 148 storage/store_raft.go:514  [n1,s1,r24/1:/Table/{28-52}] handle raft ready: 3.4s [applied=0, batches=0, state_assertions=0]
W191227 02:49:14.581325 156 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W191227 02:49:14.581359 148 storage/store_raft.go:514  [n1,s1,r24/1:/Table/{28-52}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W191227 02:49:14.581325 141 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W191227 02:49:14.802452 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 4.0s
W191227 02:49:15.761676 58 storage/store_raft.go:514  [n1,s1,r24/1:/Table/{28-52}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W191227 02:49:16.457064 160 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.1s [applied=0, batches=0, state_assertions=0]
W191227 02:49:16.512757 59 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W191227 02:49:17.213361 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 1.9s
W191227 02:49:17.213393 156 storage/engine/rocksdb.go:2076  batch [2/26923/0] commit took 844.148016ms (>= warning threshold 500ms)
W191227 02:49:17.908801 152 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 2.1s [applied=0, batches=0, state_assertions=0]
I191227 02:49:20.495620 76 gossip/gossip.go:566  [n1] gossip status (ok, 3 nodes)
gossip client (2/3 cur/max conns)
  3: 192.168.80.129:26259 (2m2s: infos 411/340 sent/received, bytes 83643B/75259B sent/received)
  2: 192.168.80.129:26258 (1m58s: infos 412/319 sent/received, bytes 70335B/73998B sent/received)
gossip server (0/3 cur/max conns, infos 3632/1534 sent/received, bytes 692492B/392069B sent/received)
I191227 02:49:21.044917 80 server/status/runtime.go:498  [n1] runtime stats: 674 MiB RSS, 272 goroutines, 136 MiB/234 MiB/401 MiB GO alloc/idle/total, 223 MiB/248 MiB CGO alloc/total, 17960.2 CGO/sec, 23.5/139.1 %(u/s)time, 0.0 %gc (0x), 318 KiB/317 KiB (r/w)net
W191227 02:49:21.361829 146 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 3.8s [applied=0, batches=0, state_assertions=0]
W191227 02:49:23.355242 65 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 2.9s [applied=0, batches=0, state_assertions=0]
W191227 02:49:25.047672 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 4.6s
W191227 02:49:25.047709 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s:
  - aborted during DistSender.Send: context deadline exceeded
W191227 02:49:25.100704 156 storage/engine/rocksdb.go:2076  batch [1/49/0] commit took 1.745790977s (>= warning threshold 500ms)
W191227 02:49:25.577331 146 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 4.2s [applied=0, batches=0, state_assertions=0]
W191227 02:49:25.577658 132 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 4.1s [applied=0, batches=0, state_assertions=0]
W191227 02:49:27.780144 108 gossip/gossip.go:1520  [n1] first range unavailable; resolvers exhausted
W191227 02:49:28.023081 65 storage/engine/rocksdb.go:2076  batch [8/238050/0] commit took 2.922195028s (>= warning threshold 500ms)
I191227 02:49:28.170140 11049 internal/client/txn.go:630  [n1] async rollback failed: context deadline exceeded
W191227 02:49:28.679670 58 storage/store_raft.go:514  [n1,s1,r19/1:/Table/2{3-4}] handle raft ready: 4.0s [applied=0, batches=0, state_assertions=0]
W191227 02:49:29.565312 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 4.5s
W191227 02:49:29.804792 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s:
  - aborted during DistSender.Send: context deadline exceeded
W191227 02:49:29.932101 58 storage/store_raft.go:514  [n1,s1,r19/1:/Table/2{3-4}] handle raft ready: 1.3s [applied=0, batches=0, state_assertions=0]
W191227 02:49:30.074288 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:2}]}
W191227 02:49:30.617042 65 storage/engine/rocksdb.go:2076  batch [2/179/0] commit took 685.04015ms (>= warning threshold 500ms)
I191227 02:49:31.092828 80 server/status/runtime.go:498  [n1] runtime stats: 683 MiB RSS, 277 goroutines, 142 MiB/229 MiB/401 MiB GO alloc/idle/total, 231 MiB/256 MiB CGO alloc/total, 9368.6 CGO/sec, 25.2/185.6 %(u/s)time, 0.0 %gc (0x), 254 KiB/254 KiB (r/w)net
W191227 02:49:31.093258 146 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.4s [applied=0, batches=0, state_assertions=0]
W191227 02:49:31.199113 65 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W191227 02:49:31.604692 11128 storage/node_liveness.go:559  [n1,s1,r11/1:/Table/1{5-6}] slow heartbeat took 3.1s
W191227 02:49:31.620076 11180 storage/node_liveness.go:559  [n1,s1,r4/1:/System{/tsd-tse}] slow heartbeat took 2.8s
W191227 02:49:31.620190 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 1.8s
W191227 02:49:31.620227 11184 storage/node_liveness.go:559  [n1,s1,r19/1:/Table/2{3-4}] slow heartbeat took 1.0s
I191227 02:49:31.852231 108 gossip/gossip.go:1531  [n1] node has connected to cluster via gossip
W191227 02:49:32.247353 64 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W191227 02:49:32.247566 65 storage/store_raft.go:514  [n1,s1,r19/1:/Table/2{3-4}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W191227 02:49:33.775047 63 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 2.0s [applied=0, batches=0, state_assertions=0]
W191227 02:49:34.296124 64 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 2.0s [applied=0, batches=0, state_assertions=0]
I191227 02:49:34.296280 11135 internal/client/txn.go:630  [n1] async rollback failed: result is ambiguous (context deadline exceeded)
W191227 02:49:34.874998 147 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.1s [applied=0, batches=0, state_assertions=0]
W191227 02:49:35.392669 157 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W191227 02:49:36.081193 157 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W191227 02:49:36.680992 157 storage/engine/rocksdb.go:2076  batch [1/50/0] commit took 599.33495ms (>= warning threshold 500ms)
W191227 02:49:36.682550 162 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 1.1s [applied=0, batches=0, state_assertions=0]
W191227 02:49:36.682686 65 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
I191227 02:49:36.686126 11286 storage/node_liveness.go:790  [n1,s1,r28/1:/Table/55/1{-/-92233…}] incremented n2 liveness epoch to 2
W191227 02:49:36.778263 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 3.4s
W191227 02:49:40.020833 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:1 Category:METRICS Description:ranges.underreplicated Value:37}]}
W191227 02:49:40.771329 142 storage/engine/rocksdb.go:2076  batch [2074/236991/0] commit took 3.403808812s (>= warning threshold 500ms)
I191227 02:49:41.077040 80 server/status/runtime.go:498  [n1] runtime stats: 703 MiB RSS, 259 goroutines, 167 MiB/206 MiB/401 MiB GO alloc/idle/total, 248 MiB/275 MiB CGO alloc/total, 21296.1 CGO/sec, 30.6/162.8 %(u/s)time, 0.0 %gc (0x), 1.7 MiB/1.7 MiB (r/w)net
W191227 02:49:41.866114 142 storage/engine/rocksdb.go:2076  batch [5/331/0] commit took 638.369047ms (>= warning threshold 500ms)
W191227 02:49:41.951824 65 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 4.5s [applied=0, batches=0, state_assertions=0]
I191227 02:49:42.350511 198 storage/node_liveness.go:846  [n1,liveness-hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context deadline exceeded)
W191227 02:49:42.350530 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 4.5s
W191227 02:49:42.350555 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W191227 02:49:43.223832 163 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W191227 02:49:43.717970 150 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.1s [applied=0, batches=0, state_assertions=0]
W191227 02:49:45.813546 152 storage/engine/rocksdb.go:2076  batch [4/237432/0] commit took 2.590200693s (>= warning threshold 500ms)
W191227 02:49:45.971726 152 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 2.7s [applied=0, batches=0, state_assertions=0]
W191227 02:49:46.221671 163 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 3.0s [applied=0, batches=0, state_assertions=0]
W191227 02:49:46.221865 150 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 2.5s [applied=0, batches=0, state_assertions=0]
W191227 02:49:46.813340 152 storage/engine/rocksdb.go:2076  batch [4/237432/0] commit took 708.396371ms (>= warning threshold 500ms)
I191227 02:49:46.815221 11388 internal/client/txn.go:630  [n1] async rollback failed: result is ambiguous (context deadline exceeded)
W191227 02:49:46.817673 152 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W191227 02:49:46.820119 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 4.5s
W191227 02:49:47.590218 135 storage/engine/rocksdb.go:2076  batch [5/237470/0] commit took 548.829793ms (>= warning threshold 500ms)
E191227 02:49:47.877608 11372 storage/replica_range_lease.go:383  [n1,s1,r3/1:/System/{NodeLive…-tsd}] mismatch incrementing epoch for {NodeID:3 Epoch:1 Expiration:1577414977.949731065,0 Draining:false Decommissioning:false}; actual is {NodeID:3 Epoch:1 Expiration:1577414986.801926534,0 Draining:false Decommissioning:false}
W191227 02:49:48.206444 58 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W191227 02:49:49.298881 135 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 1.21451159s (>= warning threshold 500ms)
W191227 02:49:49.370101 145 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.2s [applied=0, batches=0, state_assertions=0]
W191227 02:49:49.370387 56 storage/store_raft.go:514  [n1,s1,r19/1:/Table/2{3-4}] handle raft ready: 1.2s [applied=0, batches=0, state_assertions=0]
W191227 02:49:49.370908 58 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 1.2s [applied=0, batches=0, state_assertions=0]
I191227 02:49:50.271316 11284 storage/queue.go:1132  [n1,replicate] purgatory is now empty
W191227 02:49:50.895248 145 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.5s [applied=0, batches=0, state_assertions=0]
I191227 02:49:51.215648 80 server/status/runtime.go:498  [n1] runtime stats: 730 MiB RSS, 261 goroutines, 178 MiB/196 MiB/401 MiB GO alloc/idle/total, 271 MiB/301 MiB CGO alloc/total, 27700.8 CGO/sec, 41.3/196.0 %(u/s)time, 0.0 %gc (0x), 18 MiB/18 MiB (r/w)net
W191227 02:49:51.340693 135 storage/engine/rocksdb.go:2076  batch [1383/158024/0] commit took 569.33456ms (>= warning threshold 500ms)
W191227 02:49:52.280490 145 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W191227 02:49:52.979168 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 1.6s
E191227 02:49:53.508133 11532 storage/replica_range_lease.go:383  [n1,s1,r26/1:/Table/5{4/1-5}] mismatch incrementing epoch for {NodeID:3 Epoch:1 Expiration:1577414986.801926534,0 Draining:false Decommissioning:false}; actual is {NodeID:3 Epoch:1 Expiration:1577414996.320819552,0 Draining:false Decommissioning:false}
W191227 02:49:55.682009 61 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.5s [applied=0, batches=0, state_assertions=0]
W191227 02:49:55.683430 150 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.3s [applied=0, batches=0, state_assertions=0]
W191227 02:49:56.555084 61 storage/engine/rocksdb.go:2076  batch [1/69/0] commit took 872.711741ms (>= warning threshold 500ms)
W191227 02:49:57.029569 55 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.7s [applied=0, batches=0, state_assertions=0]
W191227 02:49:57.277932 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:1} {StoreID:1 Category:METRICS Description:ranges.underreplicated Value:37}]}
W191227 02:49:57.432183 61 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.7s [applied=0, batches=0, state_assertions=0]
W191227 02:49:58.555538 55 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.5s [applied=0, batches=0, state_assertions=0]
W191227 02:49:58.555987 150 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.5s [applied=0, batches=0, state_assertions=0]
W191227 02:49:59.088134 130 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.6s [applied=0, batches=0, state_assertions=0]
W191227 02:49:59.088743 62 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W191227 02:49:59.625489 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 3.7s
W191227 02:49:59.625787 59 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W191227 02:49:59.753545 62 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
I191227 02:50:01.163709 80 server/status/runtime.go:498  [n1] runtime stats: 752 MiB RSS, 249 goroutines, 158 MiB/210 MiB/401 MiB GO alloc/idle/total, 290 MiB/322 MiB CGO alloc/total, 23622.7 CGO/sec, 41.8/202.2 %(u/s)time, 0.0 %gc (1x), 19 MiB/19 MiB (r/w)net
W191227 02:50:01.939185 156 storage/engine/rocksdb.go:2076  batch [693/79095/0] commit took 1.464794231s (>= warning threshold 500ms)
W191227 02:50:02.515369 140 storage/engine/rocksdb.go:2076  batch [4/27257/0] commit took 576.060384ms (>= warning threshold 500ms)
W191227 02:50:02.576853 154 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 2.2s [applied=0, batches=0, state_assertions=0]
W191227 02:50:02.577265 131 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 2.4s [applied=0, batches=0, state_assertions=0]
W191227 02:50:03.661706 147 storage/engine/rocksdb.go:2076  batch [1/78/0] commit took 1.086099918s (>= warning threshold 500ms)
W191227 02:50:04.300782 59 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.8s [applied=0, batches=0, state_assertions=0]
W191227 02:50:05.076743 154 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 2.5s [applied=0, batches=0, state_assertions=0]
W191227 02:50:05.077363 57 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.4s [applied=0, batches=0, state_assertions=0]
W191227 02:50:05.699167 154 storage/engine/rocksdb.go:2076  batch [4/332/0] commit took 622.013665ms (>= warning threshold 500ms)
W191227 02:50:05.930880 53 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.3s [applied=0, batches=0, state_assertions=0]
W191227 02:50:05.931007 151 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 1.1s [applied=0, batches=0, state_assertions=0]
W191227 02:50:06.004837 57 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
I191227 02:50:06.557902 198 storage/node_liveness.go:846  [n1,liveness-hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context deadline exceeded)
W191227 02:50:06.557927 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 6.2s
W191227 02:50:06.557953 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W191227 02:50:06.752316 151 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:50:07.362883 154 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:50:07.363329 59 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:50:09.340744 160 storage/engine/rocksdb.go:2076  batch [1/49/0] commit took 1.17370397s (>= warning threshold 500ms)
W191227 02:50:10.112216 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:1}]}
W191227 02:50:10.694606 151 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 3.1s [applied=0, batches=0, state_assertions=0]
W191227 02:50:10.831699 55 storage/engine/rocksdb.go:2076  batch [6/79534/0] commit took 1.490782829s (>= warning threshold 500ms)
I191227 02:50:11.470084 80 server/status/runtime.go:498  [n1] runtime stats: 761 MiB RSS, 253 goroutines, 173 MiB/197 MiB/401 MiB GO alloc/idle/total, 298 MiB/331 MiB CGO alloc/total, 9669.9 CGO/sec, 30.2/166.9 %(u/s)time, 0.0 %gc (0x), 412 KiB/412 KiB (r/w)net
W191227 02:50:12.135104 160 storage/engine/rocksdb.go:2076  batch [1/57/0] commit took 767.830277ms (>= warning threshold 500ms)
W191227 02:50:13.209959 157 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 3.9s [applied=0, batches=0, state_assertions=0]
W191227 02:50:13.210553 151 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 2.5s [applied=0, batches=0, state_assertions=0]
W191227 02:50:13.210744 133 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 3.9s [applied=0, batches=0, state_assertions=0]
I191227 02:50:13.210779 11810 internal/client/txn.go:630  [n1] async rollback failed: result is ambiguous (context deadline exceeded)
W191227 02:50:13.211751 55 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 2.4s [applied=0, batches=0, state_assertions=0]
W191227 02:50:13.903220 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 4.6s
W191227 02:50:13.903406 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s:
  - context deadline exceeded
W191227 02:50:14.026048 58 storage/engine/rocksdb.go:2076  batch [2/26984/0] commit took 815.737606ms (>= warning threshold 500ms)
W191227 02:50:14.339432 157 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 1.1s [applied=0, batches=0, state_assertions=0]
W191227 02:50:15.015172 157 storage/engine/rocksdb.go:2076  batch [1/50/0] commit took 511.06005ms (>= warning threshold 500ms)
W191227 02:50:15.521610 133 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 2.3s [applied=0, batches=0, state_assertions=0]
W191227 02:50:15.530973 56 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W191227 02:50:15.531141 159 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W191227 02:50:15.531631 52 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W191227 02:50:16.621357 56 storage/engine/rocksdb.go:2076  batch [1/50/0] commit took 599.325697ms (>= warning threshold 500ms)
W191227 02:50:16.622370 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 2.7s
I191227 02:50:16.943836 11961 internal/client/txn.go:630  [n1] async rollback failed: context deadline exceeded
W191227 02:50:18.213614 133 storage/engine/rocksdb.go:2076  batch [1390/158942/0] commit took 1.591953047s (>= warning threshold 500ms)
W191227 02:50:18.881887 64 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 2.9s [applied=0, batches=0, state_assertions=0]
W191227 02:50:19.741195 133 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 1.451685736s (>= warning threshold 500ms)
I191227 02:50:19.822666 76 gossip/gossip.go:566  [n1] gossip status (ok, 3 nodes)
gossip client (2/3 cur/max conns)
  3: 192.168.80.129:26259 (3m2s: infos 609/499 sent/received, bytes 115672B/118459B sent/received)
  2: 192.168.80.129:26258 (2m58s: infos 601/466 sent/received, bytes 113736B/101280B sent/received)
gossip server (0/3 cur/max conns, infos 4041/1840 sent/received, bytes 771784B/463097B sent/received)
W191227 02:50:19.992850 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:1 Category:METRICS Description:ranges.underreplicated Value:37} {StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:1}]}
W191227 02:50:20.702743 64 storage/engine/rocksdb.go:2076  batch [7/79521/0] commit took 943.564377ms (>= warning threshold 500ms)
I191227 02:50:21.372405 80 server/status/runtime.go:498  [n1] runtime stats: 772 MiB RSS, 263 goroutines, 106 MiB/261 MiB/401 MiB GO alloc/idle/total, 315 MiB/349 MiB CGO alloc/total, 11105.4 CGO/sec, 29.1/163.8 %(u/s)time, 0.0 %gc (1x), 272 KiB/272 KiB (r/w)net
W191227 02:50:21.888930 133 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 2.1s [applied=0, batches=0, state_assertions=0]
W191227 02:50:21.933313 134 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 1.2s [applied=0, batches=0, state_assertions=0]
W191227 02:50:22.889730 150 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 2.2s [applied=0, batches=0, state_assertions=0]
W191227 02:50:22.890477 146 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 2.2s [applied=0, batches=0, state_assertions=0]
W191227 02:50:25.384999 133 storage/engine/rocksdb.go:2076  batch [2/79149/0] commit took 3.495277097s (>= warning threshold 500ms)
W191227 02:50:25.385144 115 storage/closedts/provider/provider.go:150  [ct-closer] unable to move closed timestamp forward: not live
github.com/cockroachdb/cockroach/pkg/storage.init.ializers
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/storage/node_liveness.go:57
runtime.main
	/usr/local/go/src/runtime/proc.go:188
runtime.goexit
	/usr/local/go/src/runtime/asm_amd64.s:1337
W191227 02:50:27.211401 134 storage/engine/rocksdb.go:2076  batch [29/1697/0] commit took 1.826185582s (>= warning threshold 500ms)
W191227 02:50:27.625099 146 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 4.7s [applied=0, batches=0, state_assertions=0]
I191227 02:50:27.656774 198 storage/node_liveness.go:846  [n1,liveness-hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context deadline exceeded)
W191227 02:50:27.656822 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 9.3s
W191227 02:50:27.656882 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W191227 02:50:28.829995 133 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 1.404443892s (>= warning threshold 500ms)
W191227 02:50:29.269615 134 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 1.6s [applied=0, batches=0, state_assertions=0]
W191227 02:50:29.714465 142 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W191227 02:50:30.350009 142 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
E191227 02:50:30.350428 12118 storage/replica_range_lease.go:383  [n1,s1,r20/1:/Table/2{4-5}] mismatch incrementing epoch for {NodeID:2 Epoch:2 Expiration:1577415016.417482187,0 Draining:false Decommissioning:false}; actual is {NodeID:2 Epoch:2 Expiration:1577415020.943974670,0 Draining:false Decommissioning:false}
E191227 02:50:30.350555 12086 storage/replica_range_lease.go:383  [n1,s1,r6/1:/Table/{SystemCon…-11}] mismatch incrementing epoch for {NodeID:3 Epoch:1 Expiration:1577415018.325675851,0 Draining:false Decommissioning:false}; actual is {NodeID:3 Epoch:1 Expiration:1577415027.360906634,0 Draining:false Decommissioning:false}
I191227 02:50:30.784132 12144 internal/client/txn.go:630  [n1] async rollback failed: result is ambiguous (context deadline exceeded)
W191227 02:50:31.250634 12142 storage/node_liveness.go:559  [n1,s1,r4/1:/System{/tsd-tse}] slow heartbeat took 6.5s
E191227 02:50:31.250652 12142 storage/replica_range_lease.go:339  [n1,s1,r4/1:/System{/tsd-tse}] heartbeat failed on epoch increment
I191227 02:50:31.250746 80 server/status/runtime.go:498  [n1] runtime stats: 786 MiB RSS, 258 goroutines, 115 MiB/255 MiB/401 MiB GO alloc/idle/total, 328 MiB/362 MiB CGO alloc/total, 14608.1 CGO/sec, 29.1/133.0 %(u/s)time, 0.0 %gc (0x), 19 MiB/19 MiB (r/w)net
W191227 02:50:31.250804 12208 storage/node_liveness.go:559  [n1,s1,r28/1:/Table/55/1{-/-92233…}] slow heartbeat took 4.1s
E191227 02:50:31.250818 12208 storage/replica_range_lease.go:339  [n1,s1,r28/1:/Table/55/1{-/-92233…}] heartbeat failed on epoch increment
W191227 02:50:31.250990 12188 storage/node_liveness.go:559  [n1,s1,r24/1:/Table/{28-52}] slow heartbeat took 4.0s
E191227 02:50:31.251002 12188 storage/replica_range_lease.go:339  [n1,s1,r24/1:/Table/{28-52}] heartbeat failed on epoch increment
W191227 02:50:31.251118 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 3.6s
I191227 02:50:31.251139 198 storage/node_liveness.go:474  [n1,liveness-hb] heartbeat failed on epoch increment; retrying
W191227 02:50:32.800973 154 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W191227 02:50:33.389973 138 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.5s [applied=0, batches=0, state_assertions=0]
W191227 02:50:33.401828 135 storage/store_raft.go:514  [n1,s1,r24/1:/Table/{28-52}] handle raft ready: 1.5s [applied=0, batches=0, state_assertions=0]
W191227 02:50:34.692957 154 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
I191227 02:50:35.459734 12389 sql/lease.go:1852  refreshing table: 52 lease failed: table is being dropped
W191227 02:50:35.954173 138 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 2.6s [applied=0, batches=0, state_assertions=0]
W191227 02:50:36.340044 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 4.5s
W191227 02:50:36.340113 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s:
  - context deadline exceeded
W191227 02:50:36.751892 159 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 2.1s [applied=0, batches=0, state_assertions=0]
W191227 02:50:36.752506 162 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 2.0s [applied=0, batches=0, state_assertions=0]
W191227 02:50:36.752934 157 storage/store_raft.go:514  [n1,s1,r13/1:/Table/1{7-8}] handle raft ready: 2.0s [applied=0, batches=0, state_assertions=0]
W191227 02:50:36.999725 138 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W191227 02:50:37.055570 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:6}]}
W191227 02:50:38.416021 145 storage/engine/rocksdb.go:2076  batch [5/483/0] commit took 1.002813183s (>= warning threshold 500ms)
W191227 02:50:38.460699 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 2.1s
W191227 02:50:38.710788 155 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.6s [applied=0, batches=0, state_assertions=0]
I191227 02:50:39.825675 75 storage/store.go:2364  [n1,s1] sstables (read amplification = 3):
0 [  10M  1 ]: 10M
5 [   9M  1 ]: 9M
6 [ 152M 17 ]: 10M[6] 9M[9] 5M[2]
I191227 02:50:40.015083 75 storage/store.go:2365  [n1,s1] 
** Compaction Stats [default] **
Level    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  L0      1/0    9.54 MB   0.5      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         1    0.001       0      0
  L5      1/0    9.29 MB   0.1      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.04              0.00         1    0.042       0      0
  L6     17/0   152.20 MB   0.0      0.0     0.0      0.0       0.0      0.0       0.1   0.0      0.0      0.0      1.56              0.00        17    0.092       0      0
 Sum     19/0   171.03 MB   0.0      0.0     0.0      0.0       0.0      0.0       0.2   0.0      0.0      0.0      1.61              0.00        19    0.084       0      0
 Int      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.2   0.0      0.0      0.0      1.61              0.00        19    0.084       0      0

** Compaction Stats [default] **
Priority    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
User      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.2   0.0      0.0      0.0      1.61              0.00        19    0.084       0      0
Uptime(secs): 620.3 total, 600.2 interval
Flush(GB): cumulative 0.000, interval 0.000
AddFile(GB): cumulative 0.167, interval 0.167
AddFile(Total Files): cumulative 19, interval 19
AddFile(L0 Files): cumulative 1, interval 1
AddFile(Keys): cumulative 4129124, interval 4129124
Cumulative compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 1.6 seconds
Interval compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 1.6 seconds
Stalls(count): 0 level0_slowdown, 0 level0_slowdown_with_compaction, 0 level0_numfiles, 0 level0_numfiles_with_compaction, 0 stop for pending_compaction_bytes, 0 slowdown for pending_compaction_bytes, 0 memtable_compaction, 0 memtable_slowdown, interval 0 total count
estimated_pending_compaction_bytes: 0 B
W191227 02:50:40.085532 108 gossip/gossip.go:1520  [n1] first range unavailable; resolvers exhausted
W191227 02:50:40.138227 65 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 3.0s [applied=0, batches=0, state_assertions=0]
W191227 02:50:40.138514 142 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.7s [applied=0, batches=0, state_assertions=0]
W191227 02:50:40.558534 155 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.6s [applied=0, batches=0, state_assertions=0]
W191227 02:50:41.338001 140 storage/engine/rocksdb.go:2076  batch [2/26995/0] commit took 779.18143ms (>= warning threshold 500ms)
I191227 02:50:41.365370 80 server/status/runtime.go:498  [n1] runtime stats: 790 MiB RSS, 273 goroutines, 120 MiB/248 MiB/401 MiB GO alloc/idle/total, 331 MiB/366 MiB CGO alloc/total, 4335.5 CGO/sec, 25.3/97.4 %(u/s)time, 0.1 %gc (1x), 19 MiB/19 MiB (r/w)net
W191227 02:50:42.007904 142 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W191227 02:50:42.009091 130 storage/store_raft.go:514  [n1,s1,r24/1:/Table/{28-52}] handle raft ready: 1.7s [applied=0, batches=0, state_assertions=0]
I191227 02:50:42.009830 12330 internal/client/txn.go:630  [n1] async rollback failed: result is ambiguous (context deadline exceeded)
W191227 02:50:42.010143 65 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W191227 02:50:43.124376 153 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.8s [applied=0, batches=0, state_assertions=0]
W191227 02:50:43.805559 163 storage/engine/rocksdb.go:2076  batch [1/79111/0] commit took 1.326535595s (>= warning threshold 500ms)
W191227 02:50:45.652606 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 4.8s
W191227 02:50:45.652625 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s:
  - context deadline exceeded
W191227 02:50:46.233296 140 storage/engine/rocksdb.go:2076  batch [2/26995/0] commit took 2.217815729s (>= warning threshold 500ms)
W191227 02:50:46.690868 130 storage/store_raft.go:514  [n1,s1,r24/1:/Table/{28-52}] handle raft ready: 4.7s [applied=0, batches=0, state_assertions=0]
W191227 02:50:46.715913 142 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 4.7s [applied=0, batches=0, state_assertions=0]
E191227 02:50:47.013187 12644 storage/replica_range_lease.go:339  [n1,s1,r24/1:/Table/{28-52}] context canceled
I191227 02:50:48.657087 12598 internal/client/txn.go:630  [n1] async rollback failed: context deadline exceeded
W191227 02:50:48.683822 153 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 5.6s [applied=0, batches=0, state_assertions=0]
W191227 02:50:48.684444 163 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 6.2s [applied=0, batches=0, state_assertions=0]
W191227 02:50:48.685853 156 storage/store_raft.go:514  [n1,s1,r29/1:/Table/55/1/-9223356302416…] handle raft ready: 2.9s [applied=0, batches=0, state_assertions=0]
W191227 02:50:49.619719 146 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 2.6s [applied=0, batches=0, state_assertions=0]
W191227 02:50:50.739995 163 storage/engine/rocksdb.go:2076  batch [9/133150/0] commit took 1.896134161s (>= warning threshold 500ms)
I191227 02:50:51.349083 80 server/status/runtime.go:498  [n1] runtime stats: 791 MiB RSS, 265 goroutines, 128 MiB/242 MiB/401 MiB GO alloc/idle/total, 331 MiB/366 MiB CGO alloc/total, 32.2 CGO/sec, 16.2/93.2 %(u/s)time, 0.0 %gc (0x), 302 KiB/302 KiB (r/w)net
W191227 02:50:51.655629 105 storage/engine/rocksdb.go:2076  batch [7/1018/0] commit took 865.778401ms (>= warning threshold 500ms)
W191227 02:50:52.332000 163 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 3.6s [applied=0, batches=0, state_assertions=0]
W191227 02:50:52.333617 156 storage/store_raft.go:514  [n1,s1,r29/1:/Table/55/1/-9223356302416…] handle raft ready: 3.6s [applied=0, batches=0, state_assertions=0]
W191227 02:50:52.772879 146 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 3.2s [applied=0, batches=0, state_assertions=0]
I191227 02:50:52.773811 198 storage/node_liveness.go:846  [n1,liveness-hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context deadline exceeded)
W191227 02:50:52.773851 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 7.1s
W191227 02:50:52.773907 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W191227 02:50:52.918190 156 storage/engine/rocksdb.go:2076  batch [693/79094/0] commit took 518.494229ms (>= warning threshold 500ms)
W191227 02:50:54.034257 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:2}]}
W191227 02:50:55.652837 146 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.5s [applied=0, batches=0, state_assertions=0]
I191227 02:50:55.824935 12705 internal/client/txn.go:630  [n1] async rollback failed: result is ambiguous (context deadline exceeded)
W191227 02:50:57.274864 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 4.5s
W191227 02:50:57.274963 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W191227 02:50:57.344659 12647 storage/node_liveness.go:559  [n1,s1,r24/1:/Table/{28-52}] slow heartbeat took 10.3s
E191227 02:50:57.344772 12647 storage/replica_range_lease.go:339  [n1,s1,r24/1:/Table/{28-52}] heartbeat failed on epoch increment
W191227 02:50:57.346014 12665 storage/node_liveness.go:559  [n1,s1,r11/1:/Table/1{5-6}] slow heartbeat took 6.6s
E191227 02:50:57.346046 12665 storage/replica_range_lease.go:339  [n1,s1,r11/1:/Table/1{5-6}] heartbeat failed on epoch increment
W191227 02:50:57.346429 12792 storage/node_liveness.go:559  [n1,s1,r4/1:/System{/tsd-tse}] slow heartbeat took 4.4s
E191227 02:50:57.346456 12792 storage/replica_range_lease.go:339  [n1,s1,r4/1:/System{/tsd-tse}] heartbeat failed on epoch increment
W191227 02:50:57.351160 12758 storage/node_liveness.go:559  [n1,s1,r29/1:/Table/55/1/-9223356302416…] slow heartbeat took 4.2s
E191227 02:50:57.351197 12758 storage/replica_range_lease.go:339  [n1,s1,r29/1:/Table/55/1/-9223356302416…] heartbeat failed on epoch increment
I191227 02:50:57.647910 198 storage/node_liveness.go:474  [n1,liveness-hb] heartbeat failed on epoch increment; retrying
E191227 02:50:57.648035 12853 storage/replica_range_lease.go:339  [n1,s1,r24/1:/Table/{28-52}] heartbeat failed on epoch increment
E191227 02:50:57.648164 12806 storage/replica_range_lease.go:339  [n1,s1,r4/1:/System{/tsd-tse}] heartbeat failed on epoch increment
E191227 02:50:57.648616 12875 storage/replica_range_lease.go:339  [n1,s1,r11/1:/Table/1{5-6}] heartbeat failed on epoch increment
I191227 02:50:58.563397 108 gossip/gossip.go:1531  [n1] node has connected to cluster via gossip
W191227 02:50:58.665468 140 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W191227 02:50:59.703124 143 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.3s [applied=0, batches=0, state_assertions=0]
W191227 02:51:00.077608 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:1 Category:METRICS Description:ranges.underreplicated Value:37} {StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:8}]}
W191227 02:51:00.282354 141 storage/store_raft.go:514  [n1,s1,r24/1:/Table/{28-52}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W191227 02:51:00.282940 150 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.6s [applied=0, batches=0, state_assertions=0]
W191227 02:51:00.317702 143 storage/engine/rocksdb.go:2076  batch [1/79111/0] commit took 614.235625ms (>= warning threshold 500ms)
W191227 02:51:00.644072 143 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W191227 02:51:00.857548 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 2.0s
I191227 02:51:01.486812 80 server/status/runtime.go:498  [n1] runtime stats: 793 MiB RSS, 248 goroutines, 165 MiB/210 MiB/401 MiB GO alloc/idle/total, 331 MiB/367 MiB CGO alloc/total, 137.5 CGO/sec, 22.8/67.3 %(u/s)time, 0.0 %gc (0x), 689 KiB/689 KiB (r/w)net
W191227 02:51:01.519007 143 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 619.737257ms (>= warning threshold 500ms)
W191227 02:51:01.714498 62 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W191227 02:51:01.714691 64 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:51:03.596790 143 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.8s [applied=0, batches=0, state_assertions=0]
W191227 02:51:03.599059 163 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.7s [applied=0, batches=0, state_assertions=0]
W191227 02:51:03.735942 63 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W191227 02:51:04.540092 159 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W191227 02:51:04.545949 63 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:51:04.548589 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 1.2s
W191227 02:51:05.633409 59 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
I191227 02:51:11.326114 80 server/status/runtime.go:498  [n1] runtime stats: 794 MiB RSS, 243 goroutines, 177 MiB/198 MiB/401 MiB GO alloc/idle/total, 331 MiB/367 MiB CGO alloc/total, 68.3 CGO/sec, 11.5/24.1 %(u/s)time, 0.0 %gc (0x), 413 KiB/413 KiB (r/w)net
I191227 02:51:15.418525 13221 storage/replica_command.go:411  [n1,s1,r65/1:/{Table/55/1/-…-Max}] initiating a split of this range at key /Table/57/1 [r30] (manual)
I191227 02:51:16.538188 13355 storage/replica_command.go:411  [n1,split,s1,r65/1:/Table/5{5/1/-922…-7/1}] initiating a split of this range at key /Table/57 [r31] (zone config); r65/2 is being probed (may or may not need a Raft snapshot); r65/3 is being probed (may or may not need a Raft snapshot)
W191227 02:51:17.376232 55 storage/store_raft.go:514  [n1,s1,r65/1:/Table/5{5/1/-922…-7/1}] handle raft ready: 1.6s [applied=0, batches=0, state_assertions=0]
I191227 02:51:19.302816 13256 storage/replica_command.go:411  [n1,s1,r30/1:/{Table/57/1-Max}] initiating a split of this range at key /Table/58/1 [r32] (manual)
I191227 02:51:19.802917 76 gossip/gossip.go:566  [n1] gossip status (ok, 3 nodes)
gossip client (2/3 cur/max conns)
  3: 192.168.80.129:26259 (4m2s: infos 795/652 sent/received, bytes 147674B/160814B sent/received)
  2: 192.168.80.129:26258 (3m58s: infos 796/635 sent/received, bytes 162356B/133743B sent/received)
gossip server (0/3 cur/max conns, infos 4503/2188 sent/received, bytes 866548B/555892B sent/received)
gossip connectivity
  n2 [sentinel];
  n1 -> n2; n1 -> n3; n2 -> n3;
I191227 02:51:21.326670 80 server/status/runtime.go:498  [n1] runtime stats: 795 MiB RSS, 249 goroutines, 159 MiB/211 MiB/401 MiB GO alloc/idle/total, 331 MiB/367 MiB CGO alloc/total, 184.0 CGO/sec, 13.5/29.8 %(u/s)time, 0.0 %gc (1x), 17 MiB/17 MiB (r/w)net
W191227 02:51:24.480949 55 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W191227 02:51:30.085349 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:1 Category:METRICS Description:ranges.underreplicated Value:40}]}
W191227 02:51:30.414465 60 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.5s [applied=0, batches=0, state_assertions=0]
W191227 02:51:30.664300 54 storage/store_raft.go:514  [n1,s1,r65/1:/Table/5{5/1/-922…-7/1}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
I191227 02:51:30.853358 13592 storage/node_liveness.go:790  [n1,s1,r6/1:/Table/{SystemCon…-11}] incremented n3 liveness epoch to 2
I191227 02:51:31.335992 80 server/status/runtime.go:498  [n1] runtime stats: 806 MiB RSS, 237 goroutines, 90 MiB/278 MiB/401 MiB GO alloc/idle/total, 342 MiB/379 MiB CGO alloc/total, 55.3 CGO/sec, 13.1/68.0 %(u/s)time, 0.5 %gc (1x), 168 KiB/168 KiB (r/w)net
W191227 02:51:31.738463 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 1.4s
W191227 02:51:34.078071 148 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.4s [applied=0, batches=0, state_assertions=0]
W191227 02:51:37.268597 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 2.5s
I191227 02:51:37.332471 13767 storage/replica_command.go:411  [n1,split,s1,r30/1:/Table/5{7/1-8/1}] initiating a split of this range at key /Table/58 [r33] (zone config)
I191227 02:51:41.354922 80 server/status/runtime.go:498  [n1] runtime stats: 808 MiB RSS, 249 goroutines, 108 MiB/263 MiB/401 MiB GO alloc/idle/total, 342 MiB/379 MiB CGO alloc/total, 147.7 CGO/sec, 10.6/13.5 %(u/s)time, 0.0 %gc (0x), 615 KiB/616 KiB (r/w)net
W191227 02:51:43.233757 194 sql/schema_changer.go:1991  [n1] Error executing schema change: descriptor not found
I191227 02:51:44.938266 14423 storage/replica_command.go:411  [n1,s1,r32/1:/{Table/58/1-Max}] initiating a split of this range at key /Table/60/1 [r34] (manual)
I191227 02:51:47.229392 14430 storage/replica_command.go:411  [n1,split,s1,r32/1:/Table/{58/1-60/1}] initiating a split of this range at key /Table/60 [r35] (zone config)
W191227 02:51:49.371582 163 storage/store_raft.go:514  [n1,s1,r6/1:/Table/{SystemCon…-11}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W191227 02:51:49.439362 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 1.1s
W191227 02:51:50.879076 150 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.5s [applied=0, batches=0, state_assertions=0]
W191227 02:51:51.126639 144 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W191227 02:51:51.126702 133 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
I191227 02:51:51.848303 80 server/status/runtime.go:498  [n1] runtime stats: 829 MiB RSS, 260 goroutines, 127 MiB/248 MiB/401 MiB GO alloc/idle/total, 360 MiB/400 MiB CGO alloc/total, 22003.6 CGO/sec, 22.4/57.3 %(u/s)time, 0.0 %gc (0x), 658 KiB/658 KiB (r/w)net
W191227 02:51:51.900929 150 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 1.021493589s (>= warning threshold 500ms)
W191227 02:51:53.642171 149 storage/store_raft.go:514  [n1,s1,r65/1:/Table/5{5/1/-922…-7}] handle raft ready: 2.0s [applied=0, batches=0, state_assertions=0]
W191227 02:51:53.642319 63 storage/store_raft.go:514  [n1,s1,r24/1:/Table/{28-52}] handle raft ready: 2.0s [applied=0, batches=0, state_assertions=0]
W191227 02:51:53.642343 150 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.7s [applied=0, batches=0, state_assertions=0]
W191227 02:51:53.862680 55 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W191227 02:51:53.863166 64 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W191227 02:51:54.494183 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 1.7s
W191227 02:51:54.494284 150 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 523.15589ms (>= warning threshold 500ms)
W191227 02:51:56.786489 62 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 2.3s [applied=0, batches=0, state_assertions=0]
W191227 02:51:56.786544 64 storage/store_raft.go:514  [n1,s1,r6/1:/Table/{SystemCon…-11}] handle raft ready: 2.0s [applied=0, batches=0, state_assertions=0]
E191227 02:51:59.552237 14395 storage/consistency_queue.go:134  [n1,consistencyChecker,s1,r55/1:/Table/55/1/-922335630241…] computing own checksum: operation "collect checksum" timed out after 15s: rpc error: code = DeadlineExceeded desc = context deadline exceeded
E191227 02:51:59.552253 14395 storage/queue.go:1032  [n1,consistencyChecker,s1,r55/1:/Table/55/1/-922335630241…] computing own checksum: operation "collect checksum" timed out after 15s: rpc error: code = DeadlineExceeded desc = context deadline exceeded
W191227 02:52:01.177854 138 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W191227 02:52:01.178334 61 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
I191227 02:52:01.178903 14909 storage/node_liveness.go:790  [n1,s1,r30/1:/Table/5{7/1-8}] incremented n3 liveness epoch to 3
I191227 02:52:01.504791 80 server/status/runtime.go:498  [n1] runtime stats: 843 MiB RSS, 241 goroutines, 137 MiB/238 MiB/401 MiB GO alloc/idle/total, 372 MiB/413 MiB CGO alloc/total, 16195.6 CGO/sec, 19.2/82.5 %(u/s)time, 0.0 %gc (0x), 236 KiB/236 KiB (r/w)net
W191227 02:52:01.907749 160 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W191227 02:52:03.197602 52 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W191227 02:52:04.578246 65 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W191227 02:52:09.958825 158 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.6s [applied=0, batches=0, state_assertions=0]
W191227 02:52:10.017537 8954 vendor/google.golang.org/grpc/clientconn.go:1206  grpc: addrConn.createTransport failed to connect to {192.168.80.129:26259 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W191227 02:52:10.017721 8840 storage/raft_transport.go:634  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W191227 02:52:10.787989 135 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W191227 02:52:11.659165 135 storage/engine/rocksdb.go:2076  batch [2/79168/0] commit took 870.976665ms (>= warning threshold 500ms)
W191227 02:52:11.768210 158 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.8s [applied=0, batches=0, state_assertions=0]
W191227 02:52:11.768574 134 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.4s [applied=0, batches=0, state_assertions=0]
I191227 02:52:11.828229 80 server/status/runtime.go:498  [n1] runtime stats: 844 MiB RSS, 233 goroutines, 148 MiB/228 MiB/401 MiB GO alloc/idle/total, 372 MiB/413 MiB CGO alloc/total, 798.6 CGO/sec, 9.0/21.4 %(u/s)time, 0.0 %gc (0x), 199 KiB/199 KiB (r/w)net
W191227 02:52:12.179232 135 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.4s [applied=0, batches=0, state_assertions=0]
W191227 02:52:12.512273 134 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W191227 02:52:12.512673 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 1.5s
W191227 02:52:13.597825 9042 vendor/google.golang.org/grpc/clientconn.go:1206  grpc: addrConn.createTransport failed to connect to {192.168.80.129:26259 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W191227 02:52:13.597924 9039 storage/raft_transport.go:634  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W191227 02:52:14.026209 159 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.5s [applied=0, batches=0, state_assertions=0]
W191227 02:52:14.873783 163 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.8s [applied=0, batches=0, state_assertions=0]
W191227 02:52:15.157688 159 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.1s [applied=0, batches=0, state_assertions=0]
I191227 02:52:16.791969 15069 vendor/github.com/cockroachdb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc 192.168.80.129:26257 [n3] tripped: failed to connect to n3 at 192.168.80.129:26259: initial connection heartbeat failed: operation "rpc heartbeat" timed out after 6s: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I191227 02:52:16.791985 15069 vendor/github.com/cockroachdb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc 192.168.80.129:26257 [n3] event: BreakerTripped
I191227 02:52:16.792014 15069 rpc/nodedialer/nodedialer.go:160  [n1] unable to connect to n3: failed to connect to n3 at 192.168.80.129:26259: initial connection heartbeat failed: operation "rpc heartbeat" timed out after 6s: rpc error: code = DeadlineExceeded desc = context deadline exceeded
W191227 02:52:17.001851 144 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.8s [applied=0, batches=0, state_assertions=0]
W191227 02:52:18.597365 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:1 Category:METRICS Description:ranges.underreplicated Value:44}]}
W191227 02:52:19.418948 56 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
I191227 02:52:19.612893 15147 vendor/github.com/cockroachdb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc 192.168.80.129:26257 [n3] tripped: failed to connect to n3 at 192.168.80.129:26259: initial connection heartbeat failed: operation "rpc heartbeat" timed out after 6s: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I191227 02:52:19.612921 15147 vendor/github.com/cockroachdb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc 192.168.80.129:26257 [n3] event: BreakerTripped
I191227 02:52:19.612951 15212 rpc/nodedialer/nodedialer.go:160  [n1,merge,s1,r30/1:/Table/5{7/1-8}] unable to connect to n3: failed to connect to n3 at 192.168.80.129:26259: initial connection heartbeat failed: operation "rpc heartbeat" timed out after 6s: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I191227 02:52:19.875111 76 gossip/gossip.go:566  [n1] gossip status (ok, 3 nodes)
gossip client (1/3 cur/max conns)
  2: 192.168.80.129:26258 (4m58s: infos 945/781 sent/received, bytes 276500B/163059B sent/received)
gossip server (0/3 cur/max conns, infos 4847/2392 sent/received, bytes 1098897B/616130B sent/received)
gossip connectivity
  n2 [sentinel];
  n1 -> n2;
W191227 02:52:20.024975 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:1 Category:METRICS Description:ranges.underreplicated Value:44}]}
W191227 02:52:20.544091 60 storage/store_raft.go:514  [n1,s1,r3/1:/System/{NodeLive…-tsd}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W191227 02:52:20.545824 159 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
I191227 02:52:21.806874 80 server/status/runtime.go:498  [n1] runtime stats: 845 MiB RSS, 219 goroutines, 161 MiB/216 MiB/401 MiB GO alloc/idle/total, 372 MiB/414 MiB CGO alloc/total, 55.1 CGO/sec, 10.4/41.3 %(u/s)time, 0.0 %gc (0x), 139 KiB/139 KiB (r/w)net
W191227 02:52:28.685040 62 storage/store_raft.go:514  [n1,s1,r6/1:/Table/{SystemCon…-11}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
I191227 02:52:28.844961 15345 vendor/github.com/cockroachdb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc 192.168.80.129:26257 [n3] event: BreakerReset
W191227 02:52:29.535714 152 storage/store_raft.go:514  [n1,s1,r6/1:/Table/{SystemCon…-11}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
I191227 02:52:29.917040 15498 vendor/github.com/cockroachdb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc 192.168.80.129:26257 [n3] event: BreakerReset
I191227 02:52:31.746502 80 server/status/runtime.go:498  [n1] runtime stats: 846 MiB RSS, 251 goroutines, 93 MiB/272 MiB/401 MiB GO alloc/idle/total, 380 MiB/422 MiB CGO alloc/total, 42474.5 CGO/sec, 23.2/0.0 %(u/s)time, 0.0 %gc (1x), 315 KiB/315 KiB (r/w)net
W191227 02:52:35.185573 132 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:52:35.847219 152 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W191227 02:52:38.514528 52 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W191227 02:52:38.867445 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 1.1s
W191227 02:52:39.267260 143 storage/store_raft.go:514  [n1,s1,r3/1:/System/{NodeLive…-tsd}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W191227 02:52:40.185478 143 storage/engine/rocksdb.go:2076  batch [1/50/0] commit took 918.028017ms (>= warning threshold 500ms)
W191227 02:52:40.504859 153 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.6s [applied=0, batches=0, state_assertions=0]
W191227 02:52:41.647198 153 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.1s [applied=0, batches=0, state_assertions=0]
I191227 02:52:41.754960 80 server/status/runtime.go:498  [n1] runtime stats: 846 MiB RSS, 251 goroutines, 107 MiB/260 MiB/401 MiB GO alloc/idle/total, 380 MiB/422 MiB CGO alloc/total, 50.7 CGO/sec, 10.2/15.3 %(u/s)time, 0.0 %gc (0x), 416 KiB/416 KiB (r/w)net
W191227 02:52:42.296809 153 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
I191227 02:52:46.824896 198 storage/node_liveness.go:846  [n1,liveness-hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context done during DistSender.Send: context deadline exceeded)
W191227 02:52:46.824937 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 4.5s
W191227 02:52:46.824985 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
I191227 02:52:49.826326 15786 internal/client/txn.go:630  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
I191227 02:52:51.342429 198 storage/node_liveness.go:846  [n1,liveness-hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context done during DistSender.Send: context deadline exceeded)
W191227 02:52:51.342443 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 4.5s
W191227 02:52:51.342458 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W191227 02:52:51.390195 115 storage/closedts/provider/provider.go:150  [ct-closer] unable to move closed timestamp forward: not live
github.com/cockroachdb/cockroach/pkg/storage.init.ializers
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/storage/node_liveness.go:57
runtime.main
	/usr/local/go/src/runtime/proc.go:188
runtime.goexit
	/usr/local/go/src/runtime/asm_amd64.s:1337
I191227 02:52:51.916493 80 server/status/runtime.go:498  [n1] runtime stats: 855 MiB RSS, 242 goroutines, 113 MiB/256 MiB/401 MiB GO alloc/idle/total, 389 MiB/431 MiB CGO alloc/total, 9831.3 CGO/sec, 10.0/56.7 %(u/s)time, 0.0 %gc (0x), 110 KiB/110 KiB (r/w)net
W191227 02:52:52.029081 52 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W191227 02:52:54.448491 63 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.4s [applied=0, batches=0, state_assertions=0]
I191227 02:52:54.496502 15791 internal/client/txn.go:630  [n1] async rollback failed: context deadline exceeded
W191227 02:52:54.760360 15788 storage/node_liveness.go:559  [n1,s1,r32/1:/Table/{58/1-60}] slow heartbeat took 7.0s
W191227 02:52:54.760736 15775 storage/node_liveness.go:559  [n1,s1,r4/1:/System{/tsd-tse}] slow heartbeat took 5.8s
W191227 02:52:54.760968 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 3.4s
W191227 02:52:55.518416 161 storage/store_raft.go:514  [n1,s1,r32/1:/Table/{58/1-60}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:52:55.519224 146 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:52:56.918728 53 storage/engine/rocksdb.go:2076  batch [1/50/0] commit took 797.198845ms (>= warning threshold 500ms)
W191227 02:52:56.920475 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 1.1s
W191227 02:52:57.724428 65 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
W191227 02:52:58.025865 59 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W191227 02:52:59.652546 59 storage/engine/rocksdb.go:2076  batch [4/657/0] commit took 1.62653966s (>= warning threshold 500ms)
W191227 02:52:59.966090 59 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.9s [applied=0, batches=0, state_assertions=0]
I191227 02:53:00.231045 15871 storage/node_liveness.go:790  [n1,s1,r11/1:/Table/1{5-6}] incremented n3 liveness epoch to 4
W191227 02:53:00.290426 148 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 637.663328ms (>= warning threshold 500ms)
W191227 02:53:00.724089 15498 storage/raft_transport.go:634  [n1] while processing outgoing Raft queue to node 3: EOF:
W191227 02:53:00.724149 15072 vendor/google.golang.org/grpc/clientconn.go:1206  grpc: addrConn.createTransport failed to connect to {192.168.80.129:26259 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
I191227 02:53:01.905729 80 server/status/runtime.go:498  [n1] runtime stats: 867 MiB RSS, 235 goroutines, 123 MiB/247 MiB/401 MiB GO alloc/idle/total, 400 MiB/442 MiB CGO alloc/total, 13199.0 CGO/sec, 20.9/104.8 %(u/s)time, 0.0 %gc (0x), 227 KiB/227 KiB (r/w)net
I191227 02:53:01.965824 15885 sql/lease.go:1852  refreshing table: 52 lease failed: table is being dropped
W191227 02:53:02.573753 158 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.4s [applied=0, batches=0, state_assertions=0]
W191227 02:53:02.679062 135 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 528.541905ms (>= warning threshold 500ms)
W191227 02:53:03.925869 15150 vendor/google.golang.org/grpc/clientconn.go:1206  grpc: addrConn.createTransport failed to connect to {192.168.80.129:26259 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W191227 02:53:03.934422 15497 storage/raft_transport.go:634  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W191227 02:53:04.937320 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:2} {StoreID:1 Category:METRICS Description:ranges.underreplicated Value:44}]}
W191227 02:53:05.334514 156 storage/engine/rocksdb.go:2076  batch [2/26897/0] commit took 552.898711ms (>= warning threshold 500ms)
W191227 02:53:06.367271 156 storage/store_raft.go:514  [n1,s1,r3/1:/System/{NodeLive…-tsd}] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W191227 02:53:06.501747 163 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.2s [applied=0, batches=0, state_assertions=0]
I191227 02:53:06.930204 16020 vendor/github.com/cockroachdb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc 192.168.80.129:26257 [n3] tripped: failed to connect to n3 at 192.168.80.129:26259: initial connection heartbeat failed: operation "rpc heartbeat" timed out after 6s: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I191227 02:53:06.930212 16020 vendor/github.com/cockroachdb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc 192.168.80.129:26257 [n3] event: BreakerTripped
W191227 02:53:07.873275 163 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.4s [applied=0, batches=0, state_assertions=0]
W191227 02:53:08.276101 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 3.1s
I191227 02:53:09.983047 16061 vendor/github.com/cockroachdb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc 192.168.80.129:26257 [n3] tripped: failed to connect to n3 at 192.168.80.129:26259: initial connection heartbeat failed: operation "rpc heartbeat" timed out after 6s: rpc error: code = DeadlineExceeded desc = context deadline exceeded
I191227 02:53:09.983082 16061 vendor/github.com/cockroachdb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc 192.168.80.129:26257 [n3] event: BreakerTripped
W191227 02:53:10.188340 60 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.2s [applied=0, batches=0, state_assertions=0]
W191227 02:53:10.189230 151 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W191227 02:53:10.461847 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:1 Category:METRICS Description:ranges.underreplicated Value:44}]}
W191227 02:53:10.890610 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 1.6s
W191227 02:53:11.029076 60 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:53:11.115913 152 storage/store_raft.go:514  [n1,s1,r3/1:/System/{NodeLive…-tsd}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
I191227 02:53:11.165337 16142 sql/flowinfra/outbox.go:230  [n1] outbox: connection dial error: initial connection heartbeat failed:
  - operation "rpc heartbeat" timed out after 6s:
  - rpc error: code = DeadlineExceeded desc = context deadline exceeded
failed to connect to n3 at 192.168.80.129:26259
github.com/cockroachdb/cockroach/pkg/rpc/nodedialer.(*Dialer).dial
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/rpc/nodedialer/nodedialer.go:169
github.com/cockroachdb/cockroach/pkg/rpc/nodedialer.(*Dialer).DialNoBreaker
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/rpc/nodedialer/nodedialer.go:105
github.com/cockroachdb/cockroach/pkg/sql/flowinfra.(*Outbox).mainLoop
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/sql/flowinfra/outbox.go:225
github.com/cockroachdb/cockroach/pkg/sql/flowinfra.(*Outbox).run
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/sql/flowinfra/outbox.go:429
runtime.goexit
	/usr/local/go/src/runtime/asm_amd64.s:1337
W191227 02:53:11.265462 156 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
I191227 02:53:11.822907 80 server/status/runtime.go:498  [n1] runtime stats: 891 MiB RSS, 249 goroutines, 144 MiB/222 MiB/401 MiB GO alloc/idle/total, 422 MiB/468 MiB CGO alloc/total, 13618.6 CGO/sec, 28.5/92.0 %(u/s)time, 0.0 %gc (1x), 9.6 MiB/9.6 MiB (r/w)net
W191227 02:53:12.165156 154 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
I191227 02:53:12.165481 16213 vendor/github.com/cockroachdb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc 192.168.80.129:26257 [n3] event: BreakerReset
W191227 02:53:12.285786 60 storage/engine/rocksdb.go:2076  batch [6/106263/0] commit took 673.975681ms (>= warning threshold 500ms)
I191227 02:53:12.294468 16182 storage/replica_command.go:411  [n1,s1,r32/1:/Table/{58/1-60}] initiating a split of this range at key /Table/58/1/-9223356302387006614 [r36] (manual)
W191227 02:53:12.773140 58 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W191227 02:53:13.609061 130 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W191227 02:53:13.609324 152 storage/store_raft.go:514  [n1,s1,r3/1:/System/{NodeLive…-tsd}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:53:13.610142 58 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
I191227 02:53:14.258908 16265 vendor/github.com/cockroachdb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc 192.168.80.129:26257 [n3] event: BreakerReset
W191227 02:53:15.671348 154 storage/store_raft.go:514  [n1,s1,r32/1:/Table/{58/1-60}] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W191227 02:53:16.284902 58 storage/engine/rocksdb.go:2076  batch [1/50/0] commit took 614.730335ms (>= warning threshold 500ms)
W191227 02:53:16.496593 16183 storage/replica_raft.go:105  [n1,s1,r32/1:/Table/58/1{-/-92233…}] context canceled before proposing: 1 HeartbeatTxn
W191227 02:53:16.874783 55 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
W191227 02:53:17.066188 142 storage/store_raft.go:514  [n1,s1,r9/1:/Table/1{3-4}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W191227 02:53:17.874814 159 storage/store_raft.go:514  [n1,s1,r24/1:/Table/{28-52}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W191227 02:53:18.546896 64 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W191227 02:53:19.197733 153 storage/store_raft.go:514  [n1,s1,r24/1:/Table/{28-52}] handle raft ready: 1.2s [applied=0, batches=0, state_assertions=0]
W191227 02:53:19.197863 158 storage/store_raft.go:514  [n1,s1,r36/1:/Table/{58/1/-922…-60}] handle raft ready: 1.3s [applied=0, batches=0, state_assertions=0]
W191227 02:53:19.198215 133 storage/store_raft.go:514  [n1,s1,r32/1:/Table/58/1{-/-92233…}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
I191227 02:53:19.928361 76 gossip/gossip.go:566  [n1] gossip status (ok, 3 nodes)
gossip client (1/3 cur/max conns)
  2: 192.168.80.129:26258 (5m58s: infos 1084/924 sent/received, bytes 305246B/190520B sent/received)
gossip server (1/3 cur/max conns, infos 5192/2597 sent/received, bytes 1161568B/658149B sent/received)
  3: 192.168.80.129:26259 (52s)
gossip connectivity
  n2 [sentinel];
  n1 -> n2; n3 -> n1; n3 -> n2;
I191227 02:53:20.076819 15216 storage/replica_command.go:677  [n1,merge,s1,r30/1:/Table/5{7/1-8}] initiating a merge of r33:/Table/58{-/1} [(n1,s1):1, (n3,s3):2, (n2,s2):3, next=4, gen=17] into this range (lhs+rhs has (size=191 B+0 B qps=0.00+0.00 --> 0.00qps) below threshold (size=191 B, qps=0.00))
W191227 02:53:20.305749 64 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.8s [applied=0, batches=0, state_assertions=0]
W191227 02:53:20.307293 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 2.0s
W191227 02:53:20.307442 58 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.2s [applied=0, batches=0, state_assertions=0]
W191227 02:53:22.157134 58 storage/engine/rocksdb.go:2076  batch [1/79111/0] commit took 1.849575892s (>= warning threshold 500ms)
W191227 02:53:22.229955 133 storage/store_raft.go:514  [n1,s1,r32/1:/Table/58/1{-/-92233…}] handle raft ready: 3.0s [applied=0, batches=0, state_assertions=0]
W191227 02:53:22.230023 158 storage/store_raft.go:514  [n1,s1,r36/1:/Table/{58/1/-922…-60}] handle raft ready: 2.9s [applied=0, batches=0, state_assertions=0]
W191227 02:53:22.230113 160 storage/store_raft.go:514  [n1,s1,r30/1:/Table/5{7/1-8}] handle raft ready: 2.2s [applied=0, batches=0, state_assertions=0]
W191227 02:53:22.230193 62 storage/store_raft.go:514  [n1,s1,r24/1:/Table/{28-52}] handle raft ready: 2.2s [applied=0, batches=0, state_assertions=0]
I191227 02:53:22.231871 80 server/status/runtime.go:498  [n1] runtime stats: 927 MiB RSS, 264 goroutines, 163 MiB/208 MiB/401 MiB GO alloc/idle/total, 468 MiB/514 MiB CGO alloc/total, 18411.0 CGO/sec, 29.9/119.0 %(u/s)time, 0.0 %gc (0x), 700 KiB/700 KiB (r/w)net
W191227 02:53:24.404236 153 storage/engine/rocksdb.go:2076  batch [2/462/0] commit took 2.247011776s (>= warning threshold 500ms)
W191227 02:53:25.225402 58 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 4.9s [applied=0, batches=0, state_assertions=0]
W191227 02:53:25.226766 160 storage/store_raft.go:514  [n1,s1,r30/1:/Table/5{7/1-8}] handle raft ready: 3.0s [applied=0, batches=0, state_assertions=0]
W191227 02:53:25.229941 62 storage/store_raft.go:514  [n1,s1,r24/1:/Table/{28-52}] handle raft ready: 3.0s [applied=0, batches=0, state_assertions=0]
W191227 02:53:25.230797 155 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 4.8s [applied=0, batches=0, state_assertions=0]
W191227 02:53:26.230165 145 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.5s [applied=0, batches=0, state_assertions=0]
W191227 02:53:26.972534 145 storage/engine/rocksdb.go:2076  batch [5/1135/0] commit took 742.057794ms (>= warning threshold 500ms)
W191227 02:53:27.567105 108 gossip/gossip.go:1520  [n1] first range unavailable; resolvers exhausted
I191227 02:53:27.567213 16554 gossip/client.go:124  [n1] started gossip client to 192.168.80.129:26259
W191227 02:53:27.737682 133 storage/store_raft.go:514  [n1,s1,r9/1:/Table/1{3-4}] handle raft ready: 2.5s [applied=0, batches=0, state_assertions=0]
W191227 02:53:27.738503 58 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 2.5s [applied=0, batches=0, state_assertions=0]
W191227 02:53:27.739313 148 storage/store_raft.go:514  [n1,s1,r24/1:/Table/{28-52}] handle raft ready: 2.0s [applied=0, batches=0, state_assertions=0]
W191227 02:53:27.739461 156 storage/store_raft.go:514  [n1,s1,r30/1:/Table/5{7/1-8}] handle raft ready: 2.0s [applied=0, batches=0, state_assertions=0]
W191227 02:53:28.396016 132 storage/store_raft.go:514  [n1,s1,r54/1:/Table/55/1/-9223356302413…] handle raft ready: 2.2s [applied=0, batches=0, state_assertions=0]
W191227 02:53:28.531397 133 storage/store_raft.go:514  [n1,s1,r9/1:/Table/1{3-4}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:53:29.250751 58 storage/engine/rocksdb.go:2076  batch [2074/236991/0] commit took 1.511793654s (>= warning threshold 500ms)
I191227 02:53:29.292689 108 gossip/gossip.go:1531  [n1] node has connected to cluster via gossip
I191227 02:53:29.296601 198 storage/node_liveness.go:846  [n1,liveness-hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context deadline exceeded)
W191227 02:53:29.296621 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 6.5s
W191227 02:53:29.296649 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W191227 02:53:29.456756 152 storage/store_raft.go:514  [n1,s1,r6/1:/Table/{SystemCon…-11}] handle raft ready: 1.7s [applied=0, batches=0, state_assertions=0]
W191227 02:53:30.028714 149 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W191227 02:53:30.029008 152 storage/store_raft.go:514  [n1,s1,r6/1:/Table/{SystemCon…-11}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
I191227 02:53:30.035892 16754 storage/replica_command.go:411  [n1,split,s1,r34/1:/{Table/60/1-Max}] initiating a split of this range at key /Table/61 [r37] (zone config)
W191227 02:53:30.037850 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:1} {StoreID:1 Category:METRICS Description:ranges.underreplicated Value:45}]}
W191227 02:53:31.818704 64 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.4s [applied=0, batches=0, state_assertions=0]
I191227 02:53:31.932561 80 server/status/runtime.go:498  [n1] runtime stats: 942 MiB RSS, 276 goroutines, 204 MiB/163 MiB/401 MiB GO alloc/idle/total, 432 MiB/478 MiB CGO alloc/total, 7374.5 CGO/sec, 33.1/114.3 %(u/s)time, 1.9 %gc (2x), 29 MiB/29 MiB (r/w)net
W191227 02:53:32.128565 16527 storage/node_liveness.go:559  [n1,s1,r33/1:/Table/58{-/1}] slow heartbeat took 3.6s
E191227 02:53:32.128576 16527 storage/replica_range_lease.go:339  [n1,s1,r33/1:/Table/58{-/1}] heartbeat failed on epoch increment
W191227 02:53:32.129020 16628 storage/node_liveness.go:559  [n1,s1,r4/1:/System{/tsd-tse}] slow heartbeat took 2.8s
E191227 02:53:32.129026 16628 storage/replica_range_lease.go:339  [n1,s1,r4/1:/System{/tsd-tse}] heartbeat failed on epoch increment
W191227 02:53:32.129222 16570 storage/node_liveness.go:559  [n1,s1,r11/1:/Table/1{5-6}] slow heartbeat took 2.8s
E191227 02:53:32.129228 16570 storage/replica_range_lease.go:339  [n1,s1,r11/1:/Table/1{5-6}] heartbeat failed on epoch increment
W191227 02:53:32.129363 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 2.8s
I191227 02:53:32.129380 198 storage/node_liveness.go:474  [n1,liveness-hb] heartbeat failed on epoch increment; retrying
W191227 02:53:32.129397 16541 storage/node_liveness.go:559  [n1,s1,r24/1:/Table/{28-52}] slow heartbeat took 2.8s
E191227 02:53:32.129402 16541 storage/replica_range_lease.go:339  [n1,s1,r24/1:/Table/{28-52}] heartbeat failed on epoch increment
W191227 02:53:32.642469 139 storage/store_raft.go:514  [n1,s1,r30/1:/Table/5{7/1-8}] handle raft ready: 1.8s [applied=0, batches=0, state_assertions=0]
W191227 02:53:32.643151 162 storage/store_raft.go:514  [n1,s1,r34/1:/{Table/60/1-Max}] handle raft ready: 1.7s [applied=0, batches=0, state_assertions=0]
W191227 02:53:32.643284 133 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.7s [applied=0, batches=0, state_assertions=0]
W191227 02:53:33.825114 132 storage/store_raft.go:514  [n1,s1,r24/1:/Table/{28-52}] handle raft ready: 1.7s [applied=0, batches=0, state_assertions=0]
W191227 02:53:33.826049 151 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.7s [applied=0, batches=0, state_assertions=0]
W191227 02:53:33.826087 56 storage/store_raft.go:514  [n1,s1,r33/1:/Table/58{-/1}] handle raft ready: 1.7s [applied=0, batches=0, state_assertions=0]
W191227 02:53:33.826119 64 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.7s [applied=0, batches=0, state_assertions=0]
E191227 02:53:34.608986 16814 storage/replica_range_lease.go:339  [n1,s1,r34/1:/Table/6{0/1-1}] context canceled
W191227 02:53:35.061749 133 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 2.4s [applied=0, batches=0, state_assertions=0]
W191227 02:53:35.062437 160 storage/store_raft.go:514  [n1,s1,r25/1:/Table/5{2-4}] handle raft ready: 2.2s [applied=0, batches=0, state_assertions=0]
W191227 02:53:37.481452 132 storage/store_raft.go:514  [n1,s1,r24/1:/Table/{28-52}] handle raft ready: 3.7s [applied=0, batches=0, state_assertions=0]
W191227 02:53:37.482756 56 storage/store_raft.go:514  [n1,s1,r33/1:/Table/58{-/1}] handle raft ready: 3.7s [applied=0, batches=0, state_assertions=0]
W191227 02:53:37.483818 64 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 3.7s [applied=0, batches=0, state_assertions=0]
I191227 02:53:37.509343 198 storage/node_liveness.go:846  [n1,liveness-hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context deadline exceeded)
W191227 02:53:37.509440 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 5.3s
W191227 02:53:37.509546 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W191227 02:53:39.141090 135 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.6s [applied=0, batches=0, state_assertions=0]
W191227 02:53:40.060632 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:6} {StoreID:1 Category:METRICS Description:ranges.underreplicated Value:45}]}
W191227 02:53:40.386787 149 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.3s [applied=0, batches=0, state_assertions=0]
W191227 02:53:41.038065 149 storage/engine/rocksdb.go:2076  batch [2/79168/0] commit took 651.015251ms (>= warning threshold 500ms)
W191227 02:53:41.802133 135 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 2.7s [applied=0, batches=0, state_assertions=0]
W191227 02:53:41.954046 175 storage/store_rebalancer.go:219  [n1,s1,store-rebalancer] StorePool missing descriptor for local store
W191227 02:53:42.014647 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 4.5s
W191227 02:53:42.014703 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
I191227 02:53:42.015597 80 server/status/runtime.go:498  [n1] runtime stats: 946 MiB RSS, 282 goroutines, 215 MiB/154 MiB/401 MiB GO alloc/idle/total, 435 MiB/482 MiB CGO alloc/total, 4632.6 CGO/sec, 17.3/51.3 %(u/s)time, 0.0 %gc (0x), 271 KiB/272 KiB (r/w)net
W191227 02:53:42.019222 149 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.6s [applied=0, batches=0, state_assertions=0]
W191227 02:53:42.322140 62 storage/store_raft.go:514  [n1,s1,r65/1:/Table/5{5/1/-922…-7}] handle raft ready: 13.2s [applied=0, batches=0, state_assertions=0]
I191227 02:53:42.515395 16879 internal/client/txn.go:630  [n1] async rollback failed: result is ambiguous (context deadline exceeded)
W191227 02:53:43.050900 57 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W191227 02:53:43.579365 57 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.5s [applied=0, batches=0, state_assertions=0]
W191227 02:53:45.383496 16833 storage/node_liveness.go:559  [n1,s1,r30/1:/Table/5{7/1-8}] slow heartbeat took 11.4s
E191227 02:53:45.383515 16833 storage/replica_range_lease.go:339  [n1,s1,r30/1:/Table/5{7/1-8}] heartbeat failed on epoch increment
W191227 02:53:45.383724 16842 storage/node_liveness.go:559  [n1,s1,r9/1:/Table/1{3-4}] slow heartbeat took 10.7s
E191227 02:53:45.383736 16842 storage/replica_range_lease.go:339  [n1,s1,r9/1:/Table/1{3-4}] heartbeat failed on epoch increment
W191227 02:53:45.383803 16848 storage/node_liveness.go:559  [n1,s1,r11/1:/Table/1{5-6}] slow heartbeat took 10.0s
E191227 02:53:45.383812 16848 storage/replica_range_lease.go:339  [n1,s1,r11/1:/Table/1{5-6}] heartbeat failed on epoch increment
W191227 02:53:45.383932 16849 storage/node_liveness.go:559  [n1,s1,r25/1:/Table/5{2-4}] slow heartbeat took 10.0s
E191227 02:53:45.383944 16849 storage/replica_range_lease.go:339  [n1,s1,r25/1:/Table/5{2-4}] heartbeat failed on epoch increment
W191227 02:53:45.384059 16882 storage/node_liveness.go:559  [n1,s1,r4/1:/System{/tsd-tse}] slow heartbeat took 10.0s
E191227 02:53:45.384065 16882 storage/replica_range_lease.go:339  [n1,s1,r4/1:/System{/tsd-tse}] heartbeat failed on epoch increment
W191227 02:53:45.384113 16886 storage/node_liveness.go:559  [n1,s1,r6/1:/Table/{SystemCon…-11}] slow heartbeat took 10.0s
E191227 02:53:45.384119 16886 storage/replica_range_lease.go:339  [n1,s1,r6/1:/Table/{SystemCon…-11}] heartbeat failed on epoch increment
W191227 02:53:45.384177 16901 storage/node_liveness.go:559  [n1,s1,r33/1:/Table/58{-/1}] slow heartbeat took 7.9s
E191227 02:53:45.384182 16901 storage/replica_range_lease.go:339  [n1,s1,r33/1:/Table/58{-/1}] heartbeat failed on epoch increment
W191227 02:53:45.384225 16797 storage/node_liveness.go:559  [n1,s1,r24/1:/Table/{28-52}] slow heartbeat took 7.9s
E191227 02:53:45.384230 16797 storage/replica_range_lease.go:339  [n1,s1,r24/1:/Table/{28-52}] heartbeat failed on epoch increment
I191227 02:53:45.519154 16532 storage/store_send.go:78  [n1,s1] SST ingestion was delayed by 16.897194852s (48.979µs for storage engine back-pressure)
W191227 02:53:46.115428 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 4.1s
I191227 02:53:46.989532 16826 storage/queue.go:1132  [n1,replicate] purgatory is now empty
W191227 02:53:47.366504 58 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W191227 02:53:47.417052 135 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W191227 02:53:47.609107 159 storage/store_raft.go:514  [n1,s1,r30/1:/Table/5{7/1-8}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W191227 02:53:47.609123 64 storage/store_raft.go:514  [n1,s1,r18/1:/Table/2{2-3}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W191227 02:53:48.641644 159 storage/engine/rocksdb.go:2076  batch [2/199/0] commit took 740.240643ms (>= warning threshold 500ms)
W191227 02:53:55.852054 57 storage/engine/rocksdb.go:2076  batch [2/26913/0] commit took 6.555066712s (>= warning threshold 500ms)
W191227 02:53:55.853762 8958 vendor/google.golang.org/grpc/clientconn.go:1206  grpc: addrConn.createTransport failed to connect to {192.168.80.129:26258 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W191227 02:53:55.853823 115 storage/closedts/provider/provider.go:150  [ct-closer] unable to move closed timestamp forward: not live
github.com/cockroachdb/cockroach/pkg/storage.init.ializers
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/storage/node_liveness.go:57
runtime.main
	/usr/local/go/src/runtime/proc.go:188
runtime.goexit
	/usr/local/go/src/runtime/asm_amd64.s:1337
W191227 02:53:55.853853 16064 vendor/google.golang.org/grpc/clientconn.go:1206  grpc: addrConn.createTransport failed to connect to {192.168.80.129:26259 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W191227 02:53:55.867766 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:8}]}
W191227 02:53:55.873684 65 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 8.6s [applied=0, batches=0, state_assertions=0]
I191227 02:53:56.878245 80 server/status/runtime.go:498  [n1] runtime stats: 971 MiB RSS, 277 goroutines, 215 MiB/154 MiB/401 MiB GO alloc/idle/total(stale), 435 MiB/482 MiB CGO alloc/total, 74.7 CGO/sec, 20.7/123.7 %(u/s)time, 0.0 %gc (0x), 29 MiB/29 MiB (r/w)net
W191227 02:53:58.802977 161 storage/store_raft.go:514  [n1,s1,r24/1:/Table/{28-52}] handle raft ready: 11.2s [applied=0, batches=0, state_assertions=0]
W191227 02:53:58.803422 141 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 11.4s [applied=0, batches=0, state_assertions=0]
W191227 02:53:58.803601 137 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 11.2s [applied=0, batches=0, state_assertions=0]
W191227 02:53:58.803857 138 storage/store_raft.go:514  [n1,s1,r34/1:/Table/6{0/1-1}] handle raft ready: 10.7s [applied=0, batches=0, state_assertions=0]
W191227 02:53:58.822307 8907 storage/raft_transport.go:634  [n1] while processing outgoing Raft queue to node 2: EOF:
W191227 02:54:00.133397 141 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.3s [applied=0, batches=0, state_assertions=0]
W191227 02:54:00.134076 138 storage/store_raft.go:514  [n1,s1,r34/1:/Table/6{0/1-1}] handle raft ready: 1.3s [applied=0, batches=0, state_assertions=0]
W191227 02:54:00.134198 137 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 1.3s [applied=0, batches=0, state_assertions=0]
W191227 02:54:00.368211 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 4.5s
W191227 02:54:00.368422 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W191227 02:54:03.056964 131 storage/store_raft.go:514  [n1,s1,r65/1:/Table/5{5/1/-922…-7}] handle raft ready: 15.6s [applied=0, batches=0, state_assertions=0]
W191227 02:54:03.771406 16265 storage/raft_transport.go:634  [n1] while processing outgoing Raft queue to node 3: EOF:
W191227 02:54:04.761370 17155 storage/node_liveness.go:559  [n1,s1,r30/1:/Table/5{7/1-8}] slow heartbeat took 8.9s
W191227 02:54:04.761656 17173 storage/node_liveness.go:559  [n1,s1,r29/1:/Table/55/1/-9223356302416…] slow heartbeat took 8.9s
W191227 02:54:04.761955 17174 storage/node_liveness.go:559  [n1,s1,r6/1:/Table/{SystemCon…-11}] slow heartbeat took 8.9s
W191227 02:54:04.762242 17184 storage/node_liveness.go:559  [n1,s1,r4/1:/System{/tsd-tse}] slow heartbeat took 8.9s
W191227 02:54:04.762377 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 4.4s
W191227 02:54:04.762505 17282 storage/node_liveness.go:559  [n1,s1,r11/1:/Table/1{5-6}] slow heartbeat took 3.6s
W191227 02:54:04.762669 17286 storage/node_liveness.go:559  [n1,s1,r45/1:/Table/55/1/-922335630241…] slow heartbeat took 1.6s
I191227 02:54:05.283110 17320 storage/replica_command.go:411  [n1,s1,r37/1:/{Table/61-Max}] initiating a split of this range at key /Table/61/1 [r38] (manual)
I191227 02:54:05.663739 141 storage/store_remove_replica.go:129  [n1,s1,r30/1:/Table/5{7/1-8}] removing replica r33/1
I191227 02:54:05.664657 15216 storage/queue.go:1132  [n1,merge] purgatory is now empty
W191227 02:54:05.665747 16485 storage/replica_raft.go:105  [n1,s1,r30/1:/Table/5{7/1-8/1}] context canceled before proposing: 1 HeartbeatTxn
I191227 02:54:06.100928 80 server/status/runtime.go:498  [n1] runtime stats: 1006 MiB RSS, 263 goroutines, 328 MiB/104 MiB/443 MiB GO alloc/idle/total, 435 MiB/483 MiB CGO alloc/total, 114.0 CGO/sec, 27.0/202.5 %(u/s)time, 69.1 %gc (1x), 20 MiB/20 MiB (r/w)net
W191227 02:54:07.184573 150 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W191227 02:54:07.580475 63 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:54:07.580614 59 storage/store_raft.go:514  [n1,s1,r37/1:/{Table/61-Max}] handle raft ready: 1.2s [applied=0, batches=0, state_assertions=0]
W191227 02:54:07.596748 17321 storage/replica_raft.go:105  [n1,s1,r37/1:/Table/61{-/1}] context canceled before proposing: 1 HeartbeatTxn
W191227 02:54:08.833148 146 storage/store_raft.go:514  [n1,s1,r30/1:/Table/5{7/1-8/1}] handle raft ready: 1.1s [applied=0, batches=0, state_assertions=0]
W191227 02:54:08.833478 60 storage/store_raft.go:514  [n1,s1,r9/1:/Table/1{3-4}] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W191227 02:54:09.175298 148 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W191227 02:54:09.176302 150 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 705.364289ms (>= warning threshold 500ms)
W191227 02:54:09.379564 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 1.5s
W191227 02:54:09.403824 146 storage/store_raft.go:514  [n1,s1,r30/1:/Table/5{7/1-8/1}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W191227 02:54:10.485755 157 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W191227 02:54:10.763087 153 storage/store_raft.go:514  [n1,s1,r65/1:/Table/5{5/1/-922…-7}] handle raft ready: 5.8s [applied=0, batches=0, state_assertions=0]
W191227 02:54:13.979097 134 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 2.3s [applied=0, batches=0, state_assertions=0]
W191227 02:54:19.396453 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 5.4s
I191227 02:54:19.450596 80 server/status/runtime.go:498  [n1] runtime stats: 1.0 GiB RSS, 298 goroutines, 229 MiB/268 MiB/535 MiB GO alloc/idle/total, 435 MiB/483 MiB CGO alloc/total, 77.2 CGO/sec, 92.8/84.2 %(u/s)time, 14.5 %gc (4x), 49 MiB/49 MiB (r/w)net
W191227 02:54:19.451766 108 gossip/gossip.go:1520  [n1] first range unavailable; resolvers exhausted
I191227 02:54:19.943194 76 gossip/gossip.go:566  [n1] gossip status (stalled, 3 nodes)
gossip client (2/3 cur/max conns)
  2: 192.168.80.129:26258 (6m58s: infos 1254/1131 sent/received, bytes 352691B/242839B sent/received)
  3: 192.168.80.129:26259 (52s: infos 136/201 sent/received, bytes 40122B/35901B sent/received)
gossip server (0/3 cur/max conns, infos 5533/3017 sent/received, bytes 1254984B/749508B sent/received)
gossip connectivity
  n1 -> n2; n1 -> n3; n3 -> n2;
W191227 02:54:20.560559 57 storage/engine/rocksdb.go:2076  batch [1/284/0] commit took 597.920601ms (>= warning threshold 500ms)
W191227 02:54:20.988061 139 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 1.6s [applied=0, batches=0, state_assertions=0]
W191227 02:54:22.190920 139 storage/engine/rocksdb.go:2076  batch [2/158210/0] commit took 1.202602993s (>= warning threshold 500ms)
W191227 02:54:23.322164 133 storage/engine/rocksdb.go:2076  batch [2/138/0] commit took 945.80467ms (>= warning threshold 500ms)
W191227 02:54:23.747098 139 storage/store_raft.go:514  [n1,s1,r4/1:/System{/tsd-tse}] handle raft ready: 2.8s [applied=0, batches=0, state_assertions=0]
I191227 02:54:24.191315 198 storage/node_liveness.go:846  [n1,liveness-hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context done during DistSender.Send: context deadline exceeded)
W191227 02:54:24.191347 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 4.8s
W191227 02:54:24.191387 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
I191227 02:54:24.380567 108 gossip/gossip.go:1531  [n1] node has connected to cluster via gossip
W191227 02:54:24.381211 155 storage/store_raft.go:514  [n1,s1,r6/1:/Table/{SystemCon…-11}] handle raft ready: 2.8s [applied=0, batches=0, state_assertions=0]
W191227 02:54:24.837627 55 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 2.8s [applied=0, batches=0, state_assertions=0]
W191227 02:54:25.752577 155 storage/store_raft.go:514  [n1,s1,r6/1:/Table/{SystemCon…-11}] handle raft ready: 1.4s [applied=0, batches=0, state_assertions=0]
W191227 02:54:25.879772 55 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.0s [applied=0, batches=0, state_assertions=0]
I191227 02:54:26.084470 80 server/status/runtime.go:498  [n1] runtime stats: 1.0 GiB RSS, 283 goroutines, 237 MiB/260 MiB/536 MiB GO alloc/idle/total, 435 MiB/483 MiB CGO alloc/total, 38.3 CGO/sec, 78.4/152.1 %(u/s)time, 6.3 %gc (2x), 36 MiB/36 MiB (r/w)net
W191227 02:54:27.370756 132 storage/engine/rocksdb.go:2076  batch [2074/236991/0] commit took 725.971443ms (>= warning threshold 500ms)
I191227 02:54:27.370766 17724 internal/client/txn.go:630  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
W191227 02:54:41.273996 108 gossip/gossip.go:1520  [n1] first range unavailable; resolvers exhausted
W191227 02:54:41.277120 170 storage/store.go:1530  [n1,s1,r2/1:/System/NodeLiveness{-Max}] could not gossip node liveness: [NotLeaseHolderError] r2: replica (n1,s1):1 not lease holder; lease holder unknown
I191227 02:54:41.277797 198 storage/node_liveness.go:846  [n1,liveness-hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context done during DistSender.Send: context deadline exceeded)
W191227 02:54:41.277807 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 17.1s
W191227 02:54:41.277823 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W191227 02:54:41.283499 137 storage/syncing_write.go:52  [n1,s1,r65/1:/Table/5{5/1/-922…-7}] bulk io write limiter took 12.556415713s (>500ms):
goroutine 137 [running]:
runtime/debug.Stack(0x2b53f39c, 0xed5976964, 0x0)
	/usr/local/go/src/runtime/debug/stack.go:24 +0x9d
github.com/cockroachdb/cockroach/pkg/storage.limitBulkIOWrite(0x49a2cc0, 0xc006c465a0, 0xc00044a000, 0x200000)
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/storage/syncing_write.go:53 +0x181
github.com/cockroachdb/cockroach/pkg/storage.writeFileSyncing(0x49a2cc0, 0xc006c465a0, 0xc0094809c0, 0x34, 0xc00a978000, 0x9478e0, 0x948000, 0x4a3d480, 0xc000856a80, 0xc0000001a4, ...)
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/storage/syncing_write.go:103 +0x1cd
github.com/cockroachdb/cockroach/pkg/storage.(*diskSideloadStorage).Put(0xc003beafc0, 0x49a2cc0, 0xc006c465a0, 0x29, 0xd, 0xc00a978000, 0x9478e0, 0x948000, 0x0, 0x0)
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/storage/replica_sideload_disk.go:188 +0x11c
github.com/cockroachdb/cockroach/pkg/storage.maybeSideloadEntriesImpl(0x49a2cc0, 0xc006c465a0, 0xc00630e960, 0x1, 0x1, 0x49e69a0, 0xc003beafc0, 0x3, 0x4, 0x0, ...)
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/storage/replica_sideload.go:124 +0x5b3
github.com/cockroachdb/cockroach/pkg/storage.(*Replica).maybeSideloadEntriesRaftMuLocked(...)
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/storage/replica_sideload.go:68
github.com/cockroachdb/cockroach/pkg/storage.(*Replica).handleRaftReadyRaftMuLocked(0xc006a2b000, 0x49a2cc0, 0xc006c465a0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, ...)
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/storage/replica_raft.go:655 +0x1510
github.com/cockroachdb/cockroach/pkg/storage.(*Store).processRequestQueue.func1(0x49a2cc0, 0xc006c465a0, 0xc006a2b000, 0x49a2cc0)
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/storage/store_raft.go:447 +0x12e
github.com/cockroachdb/cockroach/pkg/storage.(*Store).withReplicaForRequest(0xc000b24000, 0x49a2cc0, 0xc006c465a0, 0xc006b7a5f0, 0xc00a315ec0, 0x0)
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/storage/store_raft.go:200 +0x16b
github.com/cockroachdb/cockroach/pkg/storage.(*Store).processRequestQueue(0xc000b24000, 0x49a2cc0, 0xc000676450, 0x41)
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/storage/store_raft.go:436 +0x1f4
github.com/cockroachdb/cockroach/pkg/storage.(*raftScheduler).worker(0xc000868900, 0x49a2cc0, 0xc000676450)
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/storage/scheduler.go:238 +0x214
github.com/cockroachdb/cockroach/pkg/storage.(*raftScheduler).Start.func2(0x49a2cc0, 0xc000676450)
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/storage/scheduler.go:161 +0x3e
github.com/cockroachdb/cockroach/pkg/util/stop.(*Stopper).RunWorker.func1(0xc00020e4d0, 0xc0002d4900, 0xc00020e4c0)
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/util/stop/stopper.go:196 +0xfb
created by github.com/cockroachdb/cockroach/pkg/util/stop.(*Stopper).RunWorker
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/util/stop/stopper.go:189 +0xa8
W191227 02:54:41.295313 17197 vendor/google.golang.org/grpc/clientconn.go:1206  grpc: addrConn.createTransport failed to connect to {192.168.80.129:26258 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W191227 02:54:41.295635 17131 storage/raft_transport.go:634  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
I191227 02:54:41.540642 80 server/status/runtime.go:498  [n1] runtime stats: 1.1 GiB RSS, 240 goroutines, 266 MiB/291 MiB/528 MiB GO alloc/idle/total, 435 MiB/483 MiB CGO alloc/total, 11.1 CGO/sec, 48.5/127.3 %(u/s)time, 3.9 %gc (2x), 153 KiB/153 KiB (r/w)net
W191227 02:54:43.395814 175 storage/store_rebalancer.go:219  [n1,s1,store-rebalancer] StorePool missing descriptor for local store
W191227 02:54:43.396531 168 storage/store.go:1530  [n1,s1,r1/1:/{Min-System/NodeL…}] could not gossip first range descriptor: [NotLeaseHolderError] r1: replica (n1,s1):1 not lease holder; lease holder unknown
I191227 02:54:44.278713 17809 internal/client/txn.go:630  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
I191227 02:54:44.991485 108 gossip/gossip.go:1531  [n1] node has connected to cluster via gossip
W191227 02:54:45.778574 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 4.5s
W191227 02:54:45.778612 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
I191227 02:54:45.948062 80 server/status/runtime.go:498  [n1] runtime stats: 1.1 GiB RSS, 247 goroutines, 356 MiB/202 MiB/528 MiB GO alloc/idle/total, 435 MiB/483 MiB CGO alloc/total, 57.0 CGO/sec, 10.2/19.1 %(u/s)time, 0.0 %gc (0x), 12 MiB/12 MiB (r/w)net
W191227 02:54:46.915979 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:2}]}
W191227 02:54:47.436793 17042 storage/replica_write.go:200  [n1,s1,r65/1:/Table/5{5/1/-922…-7}] have been waiting 60.02s for proposing command AddSSTable [/Table/55/1/-9223356302412037674/0,/Table/55/1/-9223356302411813491/0/NULL).
This range is likely unavailable.
Please submit this message at

  https://github.com/cockroachdb/cockroach/issues/new/choose

along with

	https://yourhost:8080/#/reports/range/65

and the following Raft status: {"id":"1","term":13,"vote":"0","commit":40,"lead":"3","raftState":"StateFollower","applied":40,"progress":{},"leadtransferee":"0"}
W191227 02:54:50.330287 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 4.6s
W191227 02:54:50.330355 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W191227 02:54:50.333989 17566 storage/node_liveness.go:559  [n1,s1,r65/1:/Table/5{5/1/-922…-7}] slow heartbeat took 24.5s
E191227 02:54:50.334001 17566 storage/replica_range_lease.go:339  [n1,s1,r65/1:/Table/5{5/1/-922…-7}] heartbeat failed on epoch increment
W191227 02:54:50.334170 17731 storage/node_liveness.go:559  [n1,s1,r4/1:/System{/tsd-tse}] slow heartbeat took 23.0s
E191227 02:54:50.334179 17731 storage/replica_range_lease.go:339  [n1,s1,r4/1:/System{/tsd-tse}] heartbeat failed on epoch increment
W191227 02:54:50.334288 17762 storage/node_liveness.go:559  [n1,s1,r35/1:/Table/60{-/1}] slow heartbeat took 22.9s
E191227 02:54:50.334295 17762 storage/replica_range_lease.go:339  [n1,s1,r35/1:/Table/60{-/1}] heartbeat failed on epoch increment
W191227 02:54:50.336824 17735 storage/node_liveness.go:559  [n1,s1,r11/1:/Table/1{5-6}] slow heartbeat took 22.9s
E191227 02:54:50.336834 17735 storage/replica_range_lease.go:339  [n1,s1,r11/1:/Table/1{5-6}] heartbeat failed on epoch increment
W191227 02:54:51.243118 17850 storage/node_liveness.go:559  [n1,s1,r27/1:/Table/54{-/1}] slow heartbeat took 3.8s
W191227 02:54:52.066739 53 storage/store_raft.go:514  [n1,s1,r34/1:/Table/6{0/1-1}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:54:52.066901 161 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:54:52.066935 61 storage/store_raft.go:514  [n1,s1,r27/1:/Table/54{-/1}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:54:52.067036 152 storage/store_raft.go:514  [n1,s1,r24/1:/Table/{28-52}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:54:54.087065 142 storage/store_raft.go:514  [n1,s1,r24/1:/Table/{28-52}] handle raft ready: 1.2s [applied=0, batches=0, state_assertions=0]
W191227 02:54:54.087289 136 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 1.2s [applied=0, batches=0, state_assertions=0]
W191227 02:54:54.909065 142 storage/store_raft.go:514  [n1,s1,r24/1:/Table/{28-52}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:54:54.909256 136 storage/store_raft.go:514  [n1,s1,r11/1:/Table/1{5-6}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:55:07.565135 115 storage/closedts/provider/provider.go:150  [ct-closer] unable to move closed timestamp forward: not live
github.com/cockroachdb/cockroach/pkg/storage.init.ializers
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/storage/node_liveness.go:57
runtime.main
	/usr/local/go/src/runtime/proc.go:188
runtime.goexit
	/usr/local/go/src/runtime/asm_amd64.s:1337
W191227 02:55:07.565194 134 storage/engine/rocksdb.go:2076  batch [7/293/0] commit took 11.689756733s (>= warning threshold 500ms)
I191227 02:55:07.567778 80 server/status/runtime.go:498  [n1] runtime stats: 1.1 GiB RSS, 253 goroutines, 451 MiB/174 MiB/575 MiB GO alloc/idle/total, 442 MiB/491 MiB CGO alloc/total, 36.4 CGO/sec, 11.1/71.0 %(u/s)time, 0.0 %gc (0x), 7.9 MiB/7.9 MiB (r/w)net
W191227 02:55:07.601591 108 gossip/gossip.go:1520  [n1] first range unavailable; resolvers exhausted
W191227 02:55:07.603226 17195 vendor/google.golang.org/grpc/clientconn.go:1206  grpc: addrConn.createTransport failed to connect to {192.168.80.129:26259 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W191227 02:55:07.603287 16004 vendor/google.golang.org/grpc/clientconn.go:1206  grpc: addrConn.createTransport failed to connect to {192.168.80.129:26259 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W191227 02:55:07.603502 17303 storage/raft_transport.go:634  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
W191227 02:55:07.603714 16213 storage/raft_transport.go:634  [n1] while processing outgoing Raft queue to node 3: rpc error: code = Unavailable desc = transport is closing:
I191227 02:55:07.604356 108 gossip/gossip.go:1531  [n1] node has connected to cluster via gossip
I191227 02:55:27.215892 76 gossip/gossip.go:566  [n1] gossip status (stalled, 3 nodes)
gossip client (1/3 cur/max conns)
  2: 192.168.80.129:26258 (8m5s: infos 1314/1232 sent/received, bytes 377159B/271547B sent/received)
gossip server (1/3 cur/max conns, infos 5735/3262 sent/received, bytes 1302384B/843538B sent/received)
  3: 192.168.80.129:26259 (20s)
gossip connectivity
W191227 02:55:27.220309 18168 vendor/google.golang.org/grpc/server.go:967  grpc: Server.processUnaryRPC failed to write status connection error: desc = "transport is closing"
I191227 02:55:27.223077 80 server/status/runtime.go:498  [n1] runtime stats: 1.1 GiB RSS, 255 goroutines, 451 MiB/174 MiB/575 MiB GO alloc/idle/total(stale), 442 MiB/491 MiB CGO alloc/total, 3.2 CGO/sec, 0.0/98.7 %(u/s)time, 0.0 %gc (0x), 222 KiB/222 KiB (r/w)net
W191227 02:55:27.223131 108 gossip/gossip.go:1520  [n1] first range unavailable; resolvers exhausted
W191227 02:55:27.223870 61 storage/engine/rocksdb.go:2076  batch [19/1673/0] commit took 19.621959308s (>= warning threshold 500ms)
W191227 02:55:27.224735 17832 vendor/google.golang.org/grpc/clientconn.go:1206  grpc: addrConn.createTransport failed to connect to {192.168.80.129:26258 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
E191227 02:55:27.225772 7967 sql/distsql/server.go:564  [n1] communication error: rpc error: code = Canceled desc = context canceled
W191227 02:55:27.229038 18206 vendor/google.golang.org/grpc/server.go:967  grpc: Server.processUnaryRPC failed to write status connection error: desc = "transport is closing"
E191227 02:55:27.255854 18134 storage/replica_range_lease.go:339  [n1,s1,r29/1:/Table/55/1/-9223356302416…] aborted during DistSender.Send: context canceled
W191227 02:55:27.292338 8952 vendor/google.golang.org/grpc/clientconn.go:1206  grpc: addrConn.createTransport failed to connect to {192.168.80.129:26258 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W191227 02:55:27.292858 8841 storage/raft_transport.go:634  [n1] while processing outgoing Raft queue to node 2: rpc error: code = Unavailable desc = transport is closing:
I191227 02:55:27.293771 18169 gossip/client.go:124  [n1] started gossip client to 192.168.80.129:26259
E191227 02:55:27.427042 17730 storage/queue.go:1032  [n1,raftlog,s1,r4/1:/System{/tsd-tse}] operation "raftlog queue process replica 4" timed out after 1m0s: aborted during DistSender.Send: context deadline exceeded
W191227 02:55:27.725533 17829 storage/raft_transport.go:634  [n1] while processing outgoing Raft queue to node 2: EOF:
I191227 02:55:27.733994 17042 storage/replica_write.go:219  [n1,s1,r65/1:/Table/5{5/1/-922…-7}] slow command AddSSTable [/Table/55/1/-9223356302412037674/0,/Table/55/1/-9223356302411813491/0/NULL) finished after 100.32s with error result is ambiguous (context canceled)
I191227 02:55:28.284464 80 server/status/runtime.go:498  [n1] runtime stats: 1.1 GiB RSS, 238 goroutines, 465 MiB/161 MiB/586 MiB GO alloc/idle/total(stale), 446 MiB/496 MiB CGO alloc/total, 355.2 CGO/sec, 0.0/130.0 %(u/s)time, 0.0 %gc (0x), 129 KiB/129 KiB (r/w)net
I191227 02:55:29.225447 108 gossip/gossip.go:1531  [n1] node has connected to cluster via gossip
W191227 02:55:30.222272 150 storage/store_raft.go:514  [n1,s1,r65/1:/Table/5{5/1/-922…-7}] handle raft ready: 0.8s [applied=0, batches=0, state_assertions=0]
W191227 02:55:31.472294 150 storage/store_raft.go:514  [n1,s1,r65/1:/Table/5{5/1/-922…-7}] handle raft ready: 1.2s [applied=0, batches=0, state_assertions=0]
I191227 02:55:33.941201 18334 sql/lease.go:1852  refreshing table: 52 lease failed: table is being dropped
W191227 02:55:34.458672 156 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 0.9s [applied=0, batches=0, state_assertions=0]
W191227 02:55:34.459503 168 storage/store.go:1530  [n1,s1,r1/1:/{Min-System/NodeL…}] could not gossip first range descriptor: [NotLeaseHolderError] r1: replica (n1,s1):1 not lease holder; lease holder unknown
W191227 02:55:35.944934 139 storage/engine/rocksdb.go:2076  batch [5/807/0] commit took 729.21539ms (>= warning threshold 500ms)
W191227 02:55:36.160550 133 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 1.6s [applied=0, batches=0, state_assertions=0]
W191227 02:55:37.115765 108 gossip/gossip.go:1520  [n1] first range unavailable; resolvers exhausted
I191227 02:55:37.116428 18318 gossip/client.go:124  [n1] started gossip client to 192.168.80.129:26258
I191227 02:55:37.335608 80 server/status/runtime.go:498  [n1] runtime stats: 1.1 GiB RSS, 265 goroutines, 483 MiB/145 MiB/587 MiB GO alloc/idle/total, 448 MiB/500 MiB CGO alloc/total, 49.9 CGO/sec, 0.0/146.1 %(u/s)time, 0.0 %gc (0x), 414 KiB/414 KiB (r/w)net
W191227 02:55:39.516480 139 storage/engine/rocksdb.go:2076  batch [1/79111/0] commit took 1.560299693s (>= warning threshold 500ms)
W191227 02:55:40.311717 175 storage/store_rebalancer.go:219  [n1,s1,store-rebalancer] StorePool missing descriptor for local store
I191227 02:55:40.597284 108 gossip/gossip.go:1531  [n1] node has connected to cluster via gossip
W191227 02:55:40.828619 132 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 1.2s [applied=0, batches=0, state_assertions=0]
W191227 02:55:42.741049 139 storage/engine/rocksdb.go:2076  batch [1/90/0] commit took 515.396901ms (>= warning threshold 500ms)
W191227 02:55:46.053758 131 storage/engine/rocksdb.go:2076  batch [1/49/0] commit took 1.675492485s (>= warning threshold 500ms)
I191227 02:55:47.350740 80 server/status/runtime.go:498  [n1] runtime stats: 1.1 GiB RSS, 259 goroutines, 494 MiB/135 MiB/589 MiB GO alloc/idle/total, 447 MiB/500 MiB CGO alloc/total, 19.2 CGO/sec, 8.4/119.0 %(u/s)time, 0.0 %gc (0x), 10 MiB/10 MiB (r/w)net
W191227 02:55:49.466279 161 storage/engine/rocksdb.go:2076  batch [2/262/0] commit took 1.826752191s (>= warning threshold 500ms)
W191227 02:55:49.902503 162 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 3.3s [applied=0, batches=0, state_assertions=0]
W191227 02:55:52.895443 108 gossip/gossip.go:1520  [n1] first range unavailable; resolvers exhausted
W191227 02:55:53.547859 139 storage/engine/rocksdb.go:2076  batch [2074/236991/0] commit took 3.500620281s (>= warning threshold 500ms)
W191227 02:55:54.645096 162 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
I191227 02:55:56.698476 108 gossip/gossip.go:1531  [n1] node has connected to cluster via gossip
I191227 02:55:57.354903 80 server/status/runtime.go:498  [n1] runtime stats: 1.2 GiB RSS, 253 goroutines, 102 MiB/519 MiB/590 MiB GO alloc/idle/total, 452 MiB/501 MiB CGO alloc/total, 18.5 CGO/sec, 19.1/142.3 %(u/s)time, 0.3 %gc (1x), 256 KiB/256 KiB (r/w)net
W191227 02:56:00.883969 64 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 0.6s [applied=0, batches=0, state_assertions=0]
W191227 02:56:01.123252 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:5}]}
W191227 02:56:01.124702 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 33.9s
W191227 02:56:01.124876 18253 storage/node_liveness.go:559  [n1,s1,r31/1:/Table/57{-/1}] slow heartbeat took 33.2s
E191227 02:56:01.124892 18253 storage/replica_range_lease.go:339  [n1,s1,r31/1:/Table/57{-/1}] heartbeat failed on epoch increment
W191227 02:56:01.125268 18292 storage/node_liveness.go:559  [n1,s1,r32/1:/Table/58/1{-/-92233…}] slow heartbeat took 32.9s
E191227 02:56:01.125282 18292 storage/replica_range_lease.go:339  [n1,s1,r32/1:/Table/58/1{-/-92233…}] heartbeat failed on epoch increment
W191227 02:56:01.197792 18347 storage/node_liveness.go:559  [n1,s1,r30/1:/Table/5{7/1-8/1}] slow heartbeat took 24.2s
W191227 02:56:01.214267 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:2}]}
E191227 02:56:01.270116 288 jobs/registry.go:326  error while adopting jobs: unable to acquire lease: job 515586065240129537 no longer running
I191227 02:56:07.357055 80 server/status/runtime.go:498  [n1] runtime stats: 1.2 GiB RSS, 236 goroutines, 178 MiB/444 MiB/612 MiB GO alloc/idle/total, 460 MiB/510 MiB CGO alloc/total, 87.0 CGO/sec, 43.5/119.6 %(u/s)time, 0.6 %gc (3x), 49 MiB/49 MiB (r/w)net
I191227 02:56:08.094851 19108 sql/event_log.go:130  [n1,client=192.168.80.129:37876,user=root] Event: "create_database", target: 62, info: {DatabaseName:tpcc_52 Statement:CREATE DATABASE tpcc_52 User:root}
I191227 02:56:08.329936 130 storage/store_remove_replica.go:129  [n1,s1,r49/1:/Table/55/1/-9223356302413…] removing replica r54/1
W191227 02:56:10.856600 54 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 1.252062537s (>= warning threshold 500ms)
W191227 02:56:10.856681 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 1.5s
W191227 02:56:12.297341 138 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 0.7s [applied=0, batches=0, state_assertions=0]
W191227 02:56:13.580695 54 storage/engine/rocksdb.go:2076  batch [692/79057/0] commit took 1.073293665s (>= warning threshold 500ms)
W191227 02:56:15.137569 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 1.3s
I191227 02:56:17.504729 80 server/status/runtime.go:498  [n1] runtime stats: 1.2 GiB RSS, 236 goroutines, 212 MiB/411 MiB/642 MiB GO alloc/idle/total, 479 MiB/532 MiB CGO alloc/total, 99.5 CGO/sec, 24.8/104.1 %(u/s)time, 0.0 %gc (1x), 30 MiB/30 MiB (r/w)net
W191227 02:56:17.613057 137 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 1.5s [applied=0, batches=0, state_assertions=0]
I191227 02:56:19.508226 176 storage/compactor/compactor.go:370  [n1,s1,compactor] processing compaction #1-6/10 (/Table/55/1/-9223356302416747688-/Table/55/1/-9223356302413488153) for 268 MiB (reasons: size=true used=true avail=false)
I191227 02:56:19.802794 76 gossip/gossip.go:566  [n1] gossip status (ok, 3 nodes)
gossip client (2/3 cur/max conns)
  3: 192.168.80.129:26259 (53s: infos 93/246 sent/received, bytes 20472B/158692B sent/received)
  2: 192.168.80.129:26258 (43s: infos 89/183 sent/received, bytes 73315B/119039B sent/received)
gossip server (0/3 cur/max conns, infos 5993/3718 sent/received, bytes 1408672B/1127743B sent/received)
gossip connectivity
  n1 [sentinel];
  n1 -> n2; n1 -> n3; n2 -> n3;
I191227 02:56:22.814996 198 storage/node_liveness.go:846  [n1,liveness-hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context done during DistSender.Send: context deadline exceeded)
W191227 02:56:23.032477 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 4.7s
W191227 02:56:23.032598 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W191227 02:56:25.123051 108 gossip/gossip.go:1520  [n1] first range unavailable; resolvers exhausted
I191227 02:56:25.843400 19571 internal/client/txn.go:630  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
I191227 02:56:27.402599 80 server/status/runtime.go:498  [n1] runtime stats: 1.2 GiB RSS, 241 goroutines, 220 MiB/404 MiB/642 MiB GO alloc/idle/total, 489 MiB/544 MiB CGO alloc/total, 23.2 CGO/sec, 50.9/26.0 %(u/s)time, 0.0 %gc (0x), 188 KiB/188 KiB (r/w)net
I191227 02:56:27.533489 198 storage/node_liveness.go:846  [n1,liveness-hb] retrying liveness update after storage.errRetryLiveness: result is ambiguous (context done during DistSender.Send: context deadline exceeded)
W191227 02:56:58.835381 198 storage/node_liveness.go:559  [n1,liveness-hb] slow heartbeat took 35.8s
W191227 02:56:58.835486 198 storage/node_liveness.go:484  [n1,liveness-hb] failed node liveness heartbeat: operation "node liveness heartbeat" timed out after 4.5s
W191227 02:56:28.034493 115 storage/closedts/provider/provider.go:150  [ct-closer] unable to move closed timestamp forward: not live
github.com/cockroachdb/cockroach/pkg/storage.init.ializers
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/storage/node_liveness.go:57
runtime.main
	/usr/local/go/src/runtime/proc.go:188
runtime.goexit
	/usr/local/go/src/runtime/asm_amd64.s:1337
I191227 02:56:30.975339 19651 internal/client/txn.go:630  [n1] async rollback failed: aborted during DistSender.Send: context deadline exceeded
I191227 02:56:39.287753 80 server/status/runtime.go:498  [n1] runtime stats: 1.2 GiB RSS, 248 goroutines, 221 MiB/403 MiB/642 MiB GO alloc/idle/total, 489 MiB/544 MiB CGO alloc/total, 5.5 CGO/sec, 0.9/1.3 %(u/s)time, 0.0 %gc (0x), 66 KiB/66 KiB (r/w)net
I191227 02:56:58.852793 80 server/status/runtime.go:498  [n1] runtime stats: 1.2 GiB RSS, 254 goroutines, 223 MiB/403 MiB/642 MiB GO alloc/idle/total, 489 MiB/544 MiB CGO alloc/total, 10.0 CGO/sec, 0.8/0.1 %(u/s)time, 0.0 %gc (0x), 130 KiB/131 KiB (r/w)net
W191227 02:56:39.289151 19657 server/node_engine_health.go:76  [n1] disk stall detected: unable to write to <no-attributes>=/data/node1 within 10s 

** Compaction Stats [default] **
Level    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  L0      1/0    9.54 MB   0.5      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         1    0.001       0      0
  L5      2/0   18.57 MB   0.3      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      2.21              0.00         2    1.103       0      0
  L6     23/0   205.27 MB   0.0      0.0     0.0      0.0       0.0      0.0       0.2   0.0      0.0      0.0      1.85              0.00        23    0.080       0      0
 Sum     26/0   233.38 MB   0.0      0.0     0.0      0.0       0.0      0.0       0.2   0.0      0.0      0.0      4.05              0.00        26    0.156       0      0
 Int      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.1   0.0      0.0      0.0      2.45              0.00         7    0.350       0      0

** Compaction Stats [default] **
Priority    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
User      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.2   0.0      0.0      0.0      4.05              0.00        26    0.156       0      0
Uptime(secs): 979.5 total, 359.3 interval
Flush(GB): cumulative 0.000, interval 0.000
AddFile(GB): cumulative 0.228, interval 0.061
AddFile(Total Files): cumulative 26, interval 7
AddFile(L0 Files): cumulative 1, interval 0
AddFile(Keys): cumulative 5634959, interval 1505835
Cumulative compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 4.1 seconds
Interval compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 2.4 seconds
Stalls(count): 0 level0_slowdown, 0 level0_slowdown_with_compaction, 0 level0_numfiles, 0 level0_numfiles_with_compaction, 0 stop for pending_compaction_bytes, 0 slowdown for pending_compaction_bytes, 0 memtable_compaction, 0 memtable_slowdown, interval 0 total count
W191227 02:56:59.002375 137 storage/store_raft.go:514  [n1,s1,r1/1:/{Min-System/NodeL…}] handle raft ready: 41.4s [applied=0, batches=0, state_assertions=0]
W191227 02:56:59.270993 175 storage/store_rebalancer.go:219  [n1,s1,store-rebalancer] StorePool missing descriptor for local store
W191227 02:56:59.911571 158 storage/store_raft.go:514  [n1,s1,r36/1:/Table/{58/1/-922…-60}] handle raft ready: 50.7s [applied=0, batches=0, state_assertions=0]
W191227 02:56:59.915887 285 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:2}]}
I191227 02:57:01.449236 108 gossip/gossip.go:1531  [n1] node has connected to cluster via gossip
E191227 02:57:02.530674 19770 util/log/crash_reporting.go:537  Reported as error 3563885bd9c746aa8d8c4f010bd18b74
F191227 02:57:02.530678 19770 util/log/clog.go:1272  disk stall detected: unable to sync log files within 30s
goroutine 19770 [running]:
github.com/cockroachdb/cockroach/pkg/util/log.getStacks(0xc00042a300, 0xc00042a300, 0x0, 0xc006344ee8)
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/util/log/clog.go:1017 +0xb1
github.com/cockroachdb/cockroach/pkg/util/log.(*loggingT).outputLogEntry(0x722aae0, 0xc000000004, 0x6be9787, 0x10, 0x4f8, 0xc006b28700, 0x38)
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/util/log/clog.go:871 +0x95b
github.com/cockroachdb/cockroach/pkg/util/log.addStructured(0x49a2c40, 0xc000072090, 0x4, 0x2, 0x0, 0x0, 0xc006481fb0, 0x1, 0x1)
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/util/log/structured.go:66 +0x2cc
github.com/cockroachdb/cockroach/pkg/util/log.logDepth(0x49a2c40, 0xc000072090, 0x1, 0x4, 0x0, 0x0, 0xc000092fb0, 0x1, 0x1)
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/util/log/log.go:69 +0x8c
github.com/cockroachdb/cockroach/pkg/util/log.Shout(0x49a2c40, 0xc000072090, 0xc000000004, 0xc000092fb0, 0x1, 0x1)
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/util/log/log.go:87 +0xb5
github.com/cockroachdb/cockroach/pkg/util/log.(*loggingT).flushAndSync.func1()
	/home/lvhui/cockroach-v19.2.2/src/github.com/cockroachdb/cockroach/pkg/util/log/clog.go:1272 +0x105
created by time.goFunc
	/usr/local/go/src/time/sleep.go:169 +0x44


****************************************************************************

This node experienced a fatal error (printed above), and as a result the
process is terminating.

Fatal errors can occur due to faulty hardware (disks, memory, clocks) or a
problem in CockroachDB. With your help, the support team at Cockroach Labs
will try to determine the root cause, recommend next steps, and we can
improve CockroachDB based on your report.

Please submit a crash report by following the instructions here:

    https://github.com/cockroachdb/cockroach/issues/new/choose

If you would rather not post publicly, please contact us directly at:

    support@cockroachlabs.com

The Cockroach Labs team appreciates your feedback.
